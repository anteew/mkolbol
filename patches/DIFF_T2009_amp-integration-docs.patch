diff --git a/README.md b/README.md
index f3126a8..9397cd4 100644
--- a/README.md
+++ b/README.md
@@ -132,8 +132,21 @@ The repository previously contained an MCP (Model Context Protocol) based microk
 npm test
 # or  
 npm run test:watch
+# For CI environments (Node 20/24)
+npm run test:ci
 ```
 
+**CI Note:** The `test:ci` script uses `--pool=threads` to avoid tinypool concurrency issues on Node 20 and 24. Tested on both LTS versions.
+
+### Test Event Logging
+
+The project includes structured test event logging in JSONL format:
+- **Schema:** [src/logging/TestEvent.ts](src/logging/TestEvent.ts) defines envelope with ts, lvl, case, phase, evt, id, corr, path, payload
+- **Logger:** [src/logging/logger.ts](src/logging/logger.ts) provides `beginCase()`, `endCase()`, `emit()` helpers
+- **Output:** Events written to `reports/<suite>/<case>.jsonl` for test analysis and reporting
+
+**Agent Integration**: When working with agents via ampcode.log, include pointers to `reports/summary.jsonl` and case files in task reports. Keep console output compact; rely on report files for detailed metrics and traces.
+
 ### Sprint 1 Quickstart (Local, In-Process)
 
 ```bash
diff --git a/VEGA/ampcode.md b/VEGA/ampcode.md
index 1419ff7..b40b623 100644
--- a/VEGA/ampcode.md
+++ b/VEGA/ampcode.md
@@ -23,6 +23,7 @@ T140 — Package surface
 Notes
 - Keep diffs small; prefer tests + docs to invasive changes.
 - Kernel remains tiny; push semantics into modules.
+- Include report pointers in ampcode.log: always reference `reports/summary.jsonl` and case files for detailed metrics. Keep console output compact.
 
 Sprint B — Control Plane + Isolation (P0→P1)
 
diff --git a/agent_template/AMPCODE_TEMPLATE.md b/agent_template/AMPCODE_TEMPLATE.md
index 6a43ff1..c3655fc 100644
--- a/agent_template/AMPCODE_TEMPLATE.md
+++ b/agent_template/AMPCODE_TEMPLATE.md
@@ -155,9 +155,13 @@ At completion, aggregate to `ampcode.log` with:
 
 - [metric]: [value] ([delta from baseline if known])
 
+**Reports**: See `reports/summary.jsonl` and case files in `reports/` for detailed metrics and traces
+
 **Notes**: [blockers, follow-ups, or architect attention needed]
 ```
 
+**Note on Report Pointers**: Always include a **Reports** line pointing to `reports/summary.jsonl` and any case-specific files generated during testing. Keep console output compact; rely on report files for depth.
+
 ---
 
 ## Master Agent Notes
diff --git a/package-lock.json b/package-lock.json
index 6d8f48f..2fb32bb 100644
--- a/package-lock.json
+++ b/package-lock.json
@@ -13,6 +13,7 @@
       },
       "devDependencies": {
         "@types/node": "^20.12.12",
+        "fast-check": "^4.3.0",
         "typescript": "^5.6.2",
         "vitest": "^1.6.0"
       }
@@ -1061,6 +1062,29 @@
         "url": "https://github.com/sindresorhus/execa?sponsor=1"
       }
     },
+    "node_modules/fast-check": {
+      "version": "4.3.0",
+      "resolved": "https://registry.npmjs.org/fast-check/-/fast-check-4.3.0.tgz",
+      "integrity": "sha512-JVw/DJSxVKl8uhCb7GrwanT9VWsCIdBkK3WpP37B/Au4pyaspriSjtrY2ApbSFwTg3ViPfniT13n75PhzE7VEQ==",
+      "dev": true,
+      "funding": [
+        {
+          "type": "individual",
+          "url": "https://github.com/sponsors/dubzzz"
+        },
+        {
+          "type": "opencollective",
+          "url": "https://opencollective.com/fast-check"
+        }
+      ],
+      "license": "MIT",
+      "dependencies": {
+        "pure-rand": "^7.0.0"
+      },
+      "engines": {
+        "node": ">=12.17.0"
+      }
+    },
     "node_modules/fsevents": {
       "version": "2.3.3",
       "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
@@ -1413,6 +1437,23 @@
         "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
       }
     },
+    "node_modules/pure-rand": {
+      "version": "7.0.1",
+      "resolved": "https://registry.npmjs.org/pure-rand/-/pure-rand-7.0.1.tgz",
+      "integrity": "sha512-oTUZM/NAZS8p7ANR3SHh30kXB+zK2r2BPcEn/awJIbOvq82WoMN4p62AWWp3Hhw50G0xMsw1mhIBLqHw64EcNQ==",
+      "dev": true,
+      "funding": [
+        {
+          "type": "individual",
+          "url": "https://github.com/sponsors/dubzzz"
+        },
+        {
+          "type": "opencollective",
+          "url": "https://opencollective.com/fast-check"
+        }
+      ],
+      "license": "MIT"
+    },
     "node_modules/react-is": {
       "version": "18.3.1",
       "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
diff --git a/package.json b/package.json
index 161c237..10b093f 100644
--- a/package.json
+++ b/package.json
@@ -27,7 +27,7 @@
   "scripts": {
     "docs": "echo 'See docs/rfcs/stream-kernel/00-index.md for architecture documentation'",
     "build": "tsc -p tsconfig.json",
-    "test": "vitest run --reporter=default",
+    "test": "vitest run",
     "test:watch": "vitest",
     "dev": "node --enable-source-maps dist/examples/basic-topology.js",
     "dev:split": "node --enable-source-maps dist/examples/split-topology.js",
@@ -45,6 +45,7 @@
   },
   "devDependencies": {
     "@types/node": "^20.12.12",
+    "fast-check": "^4.3.0",
     "typescript": "^5.6.2",
     "vitest": "^1.6.0"
   }
diff --git a/tests/property/invariants.spec.ts b/tests/property/invariants.spec.ts
new file mode 100644
index 0000000..6c301c5
--- /dev/null
+++ b/tests/property/invariants.spec.ts
@@ -0,0 +1,345 @@
+import { describe, it, expect } from 'vitest';
+import * as fc from 'fast-check';
+import { Kernel } from '../../src/kernel/Kernel';
+import { Writable } from 'stream';
+import * as fs from 'fs';
+import * as path from 'path';
+
+const SEED = 42;
+
+function logFailure(testName: string, seed: number, error: string) {
+  const summaryPath = 'reports/summary.jsonl';
+  const dir = path.dirname(summaryPath);
+  fs.mkdirSync(dir, { recursive: true });
+  
+  const entry = {
+    status: 'fail',
+    duration: 0,
+    location: `tests/property/invariants.spec.ts:${testName}`,
+    seed,
+    error,
+  };
+  
+  fs.appendFileSync(summaryPath, JSON.stringify(entry) + '\n');
+}
+
+describe('Property-based invariants (seeded)', () => {
+  it('split: all destinations receive identical data', async () => {
+    const testName = 'split-identical-data';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.array(fc.integer({ min: 0, max: 1000 }), { minLength: 1, maxLength: 10 }),
+          async (data) => {
+            const k = new Kernel();
+            const src = k.createPipe({ objectMode: true });
+            const collected: unknown[][] = [[], []];
+            
+            const destinations = collected.map((arr) => 
+              new Writable({
+                objectMode: true,
+                write(chunk, _enc, cb) {
+                  arr.push(chunk);
+                  cb();
+                }
+              })
+            );
+            
+            k.split(src, destinations as any);
+            
+            for (const item of data) {
+              src.write(item);
+            }
+            src.end();
+            
+            await new Promise(r => setImmediate(r));
+            
+            expect(collected[0]).toEqual(data);
+            expect(collected[1]).toEqual(data);
+            expect(collected[0]).toEqual(collected[1]);
+          }
+        ),
+        { seed: SEED, numRuns: 50 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+
+  it('split: order preservation across destinations', async () => {
+    const testName = 'split-order-preservation';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.array(fc.string(), { minLength: 1, maxLength: 15 }),
+          async (data) => {
+            const k = new Kernel();
+            const src = k.createPipe({ objectMode: true });
+            const collected: unknown[][] = [[], [], []];
+            
+            const destinations = collected.map((arr) => 
+              new Writable({
+                objectMode: true,
+                write(chunk, _enc, cb) {
+                  arr.push(chunk);
+                  cb();
+                }
+              })
+            );
+            
+            k.split(src, destinations as any);
+            
+            for (const item of data) {
+              src.write(item);
+            }
+            src.end();
+            
+            await new Promise(r => setImmediate(r));
+            
+            for (let i = 0; i < collected.length; i++) {
+              expect(collected[i]).toEqual(data);
+            }
+          }
+        ),
+        { seed: SEED, numRuns: 50 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+
+  it('merge: all source data reaches destination', async () => {
+    const testName = 'merge-completeness';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.tuple(
+            fc.array(fc.integer({ min: 0, max: 100 }), { minLength: 0, maxLength: 5 }),
+            fc.array(fc.integer({ min: 101, max: 200 }), { minLength: 0, maxLength: 5 })
+          ),
+          async ([data1, data2]) => {
+            const k = new Kernel();
+            const s1 = k.createPipe({ objectMode: true });
+            const s2 = k.createPipe({ objectMode: true });
+            const out: unknown[] = [];
+            
+            const dest = new Writable({
+              objectMode: true,
+              write(chunk, _enc, cb) {
+                out.push(chunk);
+                cb();
+              }
+            });
+            
+            const merged = k.createPipe({ objectMode: true });
+            k.merge([s1, s2], merged);
+            k.connect(merged, dest as any);
+            
+            for (const item of data1) {
+              s1.write(item);
+            }
+            for (const item of data2) {
+              s2.write(item);
+            }
+            s1.end();
+            s2.end();
+            
+            await new Promise(r => setImmediate(r));
+            
+            const expected = [...data1, ...data2];
+            expect(out.sort()).toEqual(expected.sort());
+            expect(out.length).toBe(expected.length);
+          }
+        ),
+        { seed: SEED, numRuns: 50 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+
+  it('merge: no data loss with concurrent writes', async () => {
+    const testName = 'merge-no-loss';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.tuple(
+            fc.array(fc.string(), { minLength: 1, maxLength: 8 }),
+            fc.array(fc.string(), { minLength: 1, maxLength: 8 }),
+            fc.array(fc.string(), { minLength: 1, maxLength: 8 })
+          ),
+          async ([data1, data2, data3]) => {
+            const k = new Kernel();
+            const sources = [
+              k.createPipe({ objectMode: true }),
+              k.createPipe({ objectMode: true }),
+              k.createPipe({ objectMode: true })
+            ];
+            const out: unknown[] = [];
+            
+            const dest = new Writable({
+              objectMode: true,
+              write(chunk, _enc, cb) {
+                out.push(chunk);
+                cb();
+              }
+            });
+            
+            const merged = k.createPipe({ objectMode: true });
+            k.merge(sources, merged);
+            k.connect(merged, dest as any);
+            
+            const allData = [data1, data2, data3];
+            for (let i = 0; i < sources.length; i++) {
+              for (const item of allData[i]) {
+                sources[i].write(item);
+              }
+              sources[i].end();
+            }
+            
+            await new Promise(r => setImmediate(r));
+            
+            const expected = [...data1, ...data2, ...data3];
+            expect(out.length).toBe(expected.length);
+            
+            for (const item of expected) {
+              expect(out).toContain(item);
+            }
+          }
+        ),
+        { seed: SEED, numRuns: 50 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+
+  it('split-then-merge: roundtrip preserves all data', async () => {
+    const testName = 'split-merge-roundtrip';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.array(fc.integer(), { minLength: 1, maxLength: 10 }),
+          async (data) => {
+            const k = new Kernel();
+            const src = k.createPipe({ objectMode: true });
+            
+            const intermediate1 = k.createPipe({ objectMode: true });
+            const intermediate2 = k.createPipe({ objectMode: true });
+            
+            k.split(src, [intermediate1, intermediate2]);
+            
+            const merged = k.createPipe({ objectMode: true });
+            k.merge([intermediate1, intermediate2], merged);
+            
+            const out: unknown[] = [];
+            const dest = new Writable({
+              objectMode: true,
+              write(chunk, _enc, cb) {
+                out.push(chunk);
+                cb();
+              }
+            });
+            k.connect(merged, dest as any);
+            
+            for (const item of data) {
+              src.write(item);
+            }
+            src.end();
+            
+            await new Promise(r => setTimeout(r, 20));
+            
+            expect(out.length).toBe(data.length * 2);
+            
+            const expected: Record<string, number> = {};
+            for (const item of data) {
+              const key = String(item);
+              expected[key] = (expected[key] || 0) + 2;
+            }
+            
+            const actual: Record<string, number> = {};
+            for (const item of out) {
+              const key = String(item);
+              actual[key] = (actual[key] || 0) + 1;
+            }
+            
+            expect(actual).toEqual(expected);
+          }
+        ),
+        { seed: SEED, numRuns: 50 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+
+  it('empty split: source with zero destinations completes', async () => {
+    const testName = 'empty-split';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.integer({ min: 0, max: 10 }),
+          async (numItems) => {
+            const k = new Kernel();
+            const src = k.createPipe({ objectMode: true });
+            
+            k.split(src, []);
+            
+            for (let i = 0; i < numItems; i++) {
+              src.write(i);
+            }
+            src.end();
+            
+            await new Promise(r => setImmediate(r));
+            
+            expect(true).toBe(true);
+          }
+        ),
+        { seed: SEED, numRuns: 30 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+
+  it('empty merge: destination with zero sources completes', async () => {
+    const testName = 'empty-merge';
+    try {
+      await fc.assert(
+        fc.asyncProperty(
+          fc.constant(null),
+          async (_) => {
+            const k = new Kernel();
+            const merged = k.createPipe({ objectMode: true });
+            const out: unknown[] = [];
+            
+            const dest = new Writable({
+              objectMode: true,
+              write(chunk, _enc, cb) {
+                out.push(chunk);
+                cb();
+              }
+            });
+            
+            k.merge([], merged);
+            k.connect(merged, dest as any);
+            
+            await new Promise(r => setImmediate(r));
+            
+            expect(out).toEqual([]);
+          }
+        ),
+        { seed: SEED, numRuns: 10 }
+      );
+    } catch (error: any) {
+      logFailure(testName, SEED, error.message || String(error));
+      throw error;
+    }
+  });
+});
