diff --git a/package.json b/package.json
index f0ee9c4..52ef4c3 100644
--- a/package.json
+++ b/package.json
@@ -31,9 +31,11 @@
     "test:ci": "vitest run --pool=threads --exclude='**/{ptyServerWrapper,multiModalOutput}.spec.ts' --reporter=./dist/test/reporter/jsonlReporter.js",
     "test:pty": "vitest run --pool=forks --poolOptions.forks.singleFork=true tests/wrappers/ptyServerWrapper.spec.ts tests/integration/multiModalOutput.spec.ts --reporter=./dist/test/reporter/jsonlReporter.js",
     "test:watch": "vitest",
+    "lam": "tsx scripts/lam.ts",
     "logq": "tsx scripts/logq.ts",
     "repro": "tsx scripts/repro.ts",
     "laminar:run": "tsx scripts/laminar-run.ts",
+    "laminar:digest": "tsx scripts/digest.ts",
     "dev": "node --enable-source-maps dist/examples/basic-topology.js",
     "dev:split": "node --enable-source-maps dist/examples/split-topology.js",
     "dev:merge": "node --enable-source-maps dist/examples/merge-topology.js",
diff --git a/scripts/digest.ts b/scripts/digest.ts
new file mode 100644
index 0000000..de020c7
--- /dev/null
+++ b/scripts/digest.ts
@@ -0,0 +1,30 @@
+#!/usr/bin/env tsx
+import { generateAllDigests, generateDigestsForCases } from '../src/digest/generator.js';
+
+async function main() {
+  console.log('Laminar Digest Generator');
+  console.log('========================\n');
+
+  const args = process.argv.slice(2);
+  const casesIndex = args.indexOf('--cases');
+  const configPath = 'laminar.config.json';
+  
+  let count: number;
+  if (casesIndex !== -1 && args[casesIndex + 1]) {
+    const cases = args[casesIndex + 1].split(',').map(c => c.trim());
+    count = await generateDigestsForCases(cases, configPath);
+  } else {
+    count = await generateAllDigests(configPath);
+  }
+  
+  if (count === 0) {
+    console.log('\nNo failing test cases found.');
+  } else {
+    console.log(`\nGenerated ${count} digest(s).`);
+  }
+}
+
+main().catch((err) => {
+  console.error('Error:', err);
+  process.exit(1);
+});
diff --git a/scripts/lam.ts b/scripts/lam.ts
new file mode 100644
index 0000000..2766944
--- /dev/null
+++ b/scripts/lam.ts
@@ -0,0 +1,137 @@
+#!/usr/bin/env node
+import { spawnSync } from 'node:child_process';
+import * as fs from 'node:fs';
+
+function sh(cmd: string, args: string[], env: Record<string, string> = {}) {
+  const res = spawnSync(cmd, args, { stdio: 'inherit', env: { ...process.env, ...env } });
+  return res.status ?? 0;
+}
+
+function printHelp() {
+  console.log(`Laminar CLI
+
+Usage:
+  lam run [--lane ci|pty|auto] [--filter <vitest-pattern>]
+  lam summary
+  lam show --case <suite/case> [--around <pattern>] [--window <n>]
+  lam digest [--cases <case1,case2,...>]
+  lam rules get
+  lam rules set --file <path> | --inline '<json>'
+
+Examples:
+  lam run --lane auto
+  lam summary
+  lam show --case kernel.spec/connect_moves_data_1_1 --around assert.fail --window 50
+  lam digest
+  lam digest --cases kernel.spec/connect_moves_data_1_1,kernel.spec/another_case
+  lam rules get
+  lam rules set --inline '{"budget":{"kb":2}}'
+`);
+}
+
+function readSummary(): any[] {
+  const p = 'reports/summary.jsonl';
+  if (!fs.existsSync(p)) return [];
+  return fs.readFileSync(p, 'utf-8').trim().split(/\n+/).map(l => { try { return JSON.parse(l); } catch { return undefined; } }).filter(Boolean);
+}
+
+async function main() {
+  const [,, cmd, ...rest] = process.argv;
+  const args = new Map<string,string|true>();
+  for (let i=0; i<rest.length; i++) {
+    const a = rest[i];
+    if (a.startsWith('--')) {
+      const k = a.slice(2);
+      const v = rest[i+1] && !rest[i+1].startsWith('--') ? (rest[i+1]) : true;
+      if (v !== true) i++;
+      args.set(k, v as any);
+    }
+  }
+
+  switch (cmd) {
+    case 'run': {
+      const lane = (args.get('lane') as string) || 'auto';
+      const filter = args.get('filter') as (string|undefined);
+      if (lane === 'auto') {
+        if (filter) {
+          // auto with filter: run threaded, then debug rerun single file
+          sh('vitest', ['run', '--pool=threads', '--reporter=./dist/test/reporter/jsonlReporter.js', '--filter', filter]);
+          sh('npm', ['run','laminar:run']);
+        } else {
+          sh('npm', ['run','laminar:run']);
+        }
+      } else if (lane === 'ci') {
+        const a = ['run','test:ci'];
+        if (filter) a.push('--', '--filter', filter);
+        sh('npm', a);
+      } else if (lane === 'pty') {
+        sh('npm', ['run','test:pty']);
+      } else {
+        console.error('Unknown lane. Use ci|pty|auto');
+        process.exit(1);
+      }
+      break;
+    }
+    case 'summary': {
+      const entries = readSummary();
+      if (!entries.length) { console.log('No summary found. Run `lam run` first.'); break; }
+      for (const e of entries) {
+        console.log(`${e.status.toUpperCase()} ${e.duration}ms ${e.location} â†’ ${e.artifactURI||''}`);
+      }
+      break;
+    }
+    case 'show': {
+      const caseId = args.get('case') as string;
+      if (!caseId) { console.error('lam show --case <suite/case> [--around <pattern>] [--window <n>]'); process.exit(1); }
+      const around = (args.get('around') as string) || 'assert.fail';
+      const window = (args.get('window') as string) || '50';
+      
+      const digestPath = `reports/${caseId}.digest.md`;
+      if (fs.existsSync(digestPath)) {
+        console.log('=== DIGEST ===');
+        console.log(fs.readFileSync(digestPath, 'utf-8'));
+        console.log('\n=== FULL LOG ===');
+      }
+      
+      sh('npm', ['run','logq','--','case', caseId, '--around', around, '--window', window]);
+      break;
+    }
+    case 'digest': {
+      const casesArg = args.get('cases') as string | undefined;
+      if (casesArg) {
+        const cases = casesArg.split(',').map(c => c.trim());
+        sh('npm', ['run', 'laminar:digest', '--', '--cases', cases.join(',')]);
+      } else {
+        sh('npm', ['run', 'laminar:digest']);
+      }
+      break;
+    }
+    case 'rules': {
+      const sub = rest[0];
+      if (sub === 'get') {
+        if (fs.existsSync('laminar.config.json')) {
+          process.stdout.write(fs.readFileSync('laminar.config.json','utf-8'));
+        } else {
+          console.log('{}');
+        }
+      } else if (sub === 'set') {
+        const file = args.get('file') as string|undefined;
+        const inline = args.get('inline') as string|undefined;
+        if (!file && !inline) { console.error('lam rules set --file <path> | --inline \"{...}\"'); process.exit(1); }
+        const content = file ? fs.readFileSync(file,'utf-8') : inline!;
+        JSON.parse(content); // validate
+        fs.writeFileSync('laminar.config.json', content);
+        console.log('Updated laminar.config.json');
+      } else {
+        printHelp();
+        process.exit(1);
+      }
+      break;
+    }
+    default:
+      printHelp();
+  }
+}
+
+main().catch(e => { console.error(e); process.exit(1); });
+
diff --git a/src/digest/generator.ts b/src/digest/generator.ts
new file mode 100644
index 0000000..b713597
--- /dev/null
+++ b/src/digest/generator.ts
@@ -0,0 +1,500 @@
+import * as fs from 'node:fs';
+import * as path from 'node:path';
+
+export interface DigestConfig {
+  budget?: {
+    kb?: number;
+    lines?: number;
+  };
+  rules?: DigestRule[];
+  enabled?: boolean;
+}
+
+export interface DigestRule {
+  match: {
+    evt?: string | string[];
+    lvl?: string | string[];
+    phase?: string | string[];
+    case?: string | string[];
+    path?: string | string[];
+  };
+  actions: DigestAction[];
+  priority?: number;
+}
+
+export interface DigestAction {
+  type: 'include' | 'slice' | 'redact';
+  window?: number;
+  field?: string | string[];
+}
+
+export interface DigestEvent {
+  ts: number;
+  lvl: string;
+  case: string;
+  phase?: string;
+  evt: string;
+  id?: string;
+  corr?: string;
+  path?: string;
+  payload?: unknown;
+}
+
+export interface SuspectEvent extends DigestEvent {
+  score: number;
+  reasons: string[];
+}
+
+export interface DigestOutput {
+  case: string;
+  status: 'fail';
+  duration: number;
+  location: string;
+  error?: string;
+  summary: {
+    totalEvents: number;
+    includedEvents: number;
+    redactedFields: number;
+    budgetUsed: number;
+    budgetLimit: number;
+  };
+  suspects?: SuspectEvent[];
+  events: DigestEvent[];
+}
+
+const DEFAULT_CONFIG: DigestConfig = {
+  budget: {
+    kb: 10,
+    lines: 200,
+  },
+  enabled: true,
+  rules: [
+    {
+      match: { lvl: 'error' },
+      actions: [{ type: 'include' }],
+      priority: 10,
+    },
+    {
+      match: { evt: 'assert.fail' },
+      actions: [{ type: 'include' }, { type: 'slice', window: 10 }],
+      priority: 9,
+    },
+  ],
+};
+
+export class DigestGenerator {
+  private config: DigestConfig;
+
+  constructor(config?: DigestConfig) {
+    this.config = config || DEFAULT_CONFIG;
+  }
+
+  static loadConfig(configPath: string = 'laminar.config.json'): DigestConfig {
+    if (fs.existsSync(configPath)) {
+      try {
+        const content = fs.readFileSync(configPath, 'utf-8');
+        return JSON.parse(content);
+      } catch (e) {
+        console.warn(`Failed to load ${configPath}, using defaults:`, e);
+      }
+    }
+    return DEFAULT_CONFIG;
+  }
+
+  async generateDigest(
+    caseName: string,
+    status: 'pass' | 'fail' | 'skip',
+    duration: number,
+    location: string,
+    artifactURI: string,
+    error?: string
+  ): Promise<DigestOutput | null> {
+    if (status !== 'fail') {
+      return null;
+    }
+
+    if (!this.config.enabled) {
+      return null;
+    }
+
+    const events = this.loadEvents(artifactURI);
+    const processedEvents = this.applyRules(events);
+    const budgetedEvents = this.enforceBudget(processedEvents);
+    const suspects = this.identifySuspects(events);
+
+    const budgetLimit = (this.config.budget?.kb || 10) * 1024;
+    const budgetUsed = JSON.stringify(budgetedEvents).length;
+
+    return {
+      case: caseName,
+      status: 'fail',
+      duration,
+      location,
+      error,
+      summary: {
+        totalEvents: events.length,
+        includedEvents: budgetedEvents.length,
+        redactedFields: 0,
+        budgetUsed,
+        budgetLimit,
+      },
+      suspects,
+      events: budgetedEvents,
+    };
+  }
+
+  private loadEvents(artifactURI: string): DigestEvent[] {
+    if (!fs.existsSync(artifactURI)) {
+      return [];
+    }
+
+    const content = fs.readFileSync(artifactURI, 'utf-8');
+    const lines = content.trim().split('\n').filter(Boolean);
+    const events: DigestEvent[] = [];
+
+    for (const line of lines) {
+      try {
+        events.push(JSON.parse(line));
+      } catch (e) {
+        console.warn('Failed to parse event:', line);
+      }
+    }
+
+    return events;
+  }
+
+  private applyRules(events: DigestEvent[]): DigestEvent[] {
+    if (!this.config.rules || this.config.rules.length === 0) {
+      return events;
+    }
+
+    const included = new Set<number>();
+    const redactedFields = new Map<number, Set<string>>();
+    const rules = [...this.config.rules].sort((a, b) => (b.priority || 0) - (a.priority || 0));
+
+    for (const rule of rules) {
+      for (let i = 0; i < events.length; i++) {
+        if (this.matchEvent(events[i], rule.match)) {
+          for (const action of rule.actions) {
+            if (action.type === 'include') {
+              included.add(i);
+            } else if (action.type === 'slice' && action.window) {
+              const window = action.window;
+              for (let j = Math.max(0, i - window); j < Math.min(events.length, i + window + 1); j++) {
+                included.add(j);
+              }
+            } else if (action.type === 'redact' && action.field) {
+              const fields = Array.isArray(action.field) ? action.field : [action.field];
+              if (!redactedFields.has(i)) {
+                redactedFields.set(i, new Set());
+              }
+              fields.forEach(f => redactedFields.get(i)!.add(f));
+            }
+          }
+        }
+      }
+    }
+
+    if (included.size === 0) {
+      return events;
+    }
+
+    const result = Array.from(included)
+      .sort((a, b) => a - b)
+      .map(idx => {
+        const event = { ...events[idx] };
+        if (redactedFields.has(idx)) {
+          const fieldsToRedact = redactedFields.get(idx)!;
+          for (const field of fieldsToRedact) {
+            if (field === 'payload' && event.payload) {
+              event.payload = '[REDACTED]';
+            } else if (field in event) {
+              (event as any)[field] = '[REDACTED]';
+            }
+          }
+        }
+        return event;
+      });
+
+    return result;
+  }
+
+  private matchEvent(event: DigestEvent, match: DigestRule['match']): boolean {
+    if (match.evt) {
+      const evtMatch = Array.isArray(match.evt) ? match.evt : [match.evt];
+      if (!this.matchPattern(event.evt, evtMatch)) return false;
+    }
+
+    if (match.lvl) {
+      const lvlMatch = Array.isArray(match.lvl) ? match.lvl : [match.lvl];
+      if (!this.matchPattern(event.lvl, lvlMatch)) return false;
+    }
+
+    if (match.phase) {
+      const phaseMatch = Array.isArray(match.phase) ? match.phase : [match.phase];
+      if (!event.phase || !this.matchPattern(event.phase, phaseMatch)) return false;
+    }
+
+    if (match.case) {
+      const caseMatch = Array.isArray(match.case) ? match.case : [match.case];
+      if (!this.matchPattern(event.case, caseMatch)) return false;
+    }
+
+    if (match.path) {
+      const pathMatch = Array.isArray(match.path) ? match.path : [match.path];
+      if (!event.path || !this.matchPattern(event.path, pathMatch)) return false;
+    }
+
+    return true;
+  }
+
+  private matchPattern(value: string, patterns: string[]): boolean {
+    return patterns.some(pattern => {
+      if (pattern.includes('*')) {
+        const regex = new RegExp('^' + pattern.replace(/\*/g, '.*') + '$');
+        return regex.test(value);
+      }
+      return value === pattern;
+    });
+  }
+
+  private enforceBudget(events: DigestEvent[]): DigestEvent[] {
+    const budgetKb = this.config.budget?.kb || 10;
+    const budgetLines = this.config.budget?.lines || 200;
+    const budgetBytes = budgetKb * 1024;
+
+    if (events.length <= budgetLines) {
+      const size = JSON.stringify(events).length;
+      if (size <= budgetBytes) {
+        return events;
+      }
+    }
+
+    let currentEvents = events.slice(0, Math.min(events.length, budgetLines));
+    while (currentEvents.length > 0) {
+      const size = JSON.stringify(currentEvents).length;
+      if (size <= budgetBytes) {
+        break;
+      }
+      currentEvents = currentEvents.slice(0, currentEvents.length - 1);
+    }
+
+    return currentEvents;
+  }
+
+  private identifySuspects(events: DigestEvent[]): SuspectEvent[] {
+    if (events.length === 0) {
+      return [];
+    }
+
+    const failureEvents = events.filter(e => e.lvl === 'error' || e.evt.includes('fail'));
+    if (failureEvents.length === 0) {
+      return [];
+    }
+
+    const lastFailureTime = Math.max(...failureEvents.map(e => e.ts));
+    const failureCorrelations = new Set(failureEvents.filter(e => e.corr).map(e => e.corr!));
+
+    const scoredEvents: SuspectEvent[] = events.map(event => {
+      const score = this.calculateSuspectScore(event, events, lastFailureTime, failureCorrelations);
+      const reasons: string[] = [];
+
+      if (event.lvl === 'error') {
+        reasons.push('error level');
+      }
+      if (event.evt.includes('fail')) {
+        reasons.push('failure event');
+      }
+      if (event.corr && failureCorrelations.has(event.corr)) {
+        reasons.push('correlated with failure');
+      }
+      if (Math.abs(event.ts - lastFailureTime) < 1000) {
+        reasons.push('close proximity to failure');
+      }
+
+      return { ...event, score, reasons };
+    });
+
+    return scoredEvents
+      .filter(e => e.score > 0)
+      .sort((a, b) => b.score - a.score)
+      .slice(0, 5);
+  }
+
+  private calculateSuspectScore(
+    event: DigestEvent,
+    allEvents: DigestEvent[],
+    failureTime: number,
+    failureCorrelations: Set<string>
+  ): number {
+    let score = 0;
+
+    if (event.lvl === 'error') {
+      score += 50;
+    } else if (event.lvl === 'warn') {
+      score += 20;
+    }
+
+    const timeDiff = Math.abs(event.ts - failureTime);
+    const proximityScore = Math.max(0, 30 - (timeDiff / 1000) * 10);
+    score += proximityScore;
+
+    if (event.corr && failureCorrelations.has(event.corr)) {
+      score += 40;
+    }
+
+    const similarEvents = allEvents.filter(e => 
+      e.evt === event.evt && Math.abs(e.ts - event.ts) < 5000
+    );
+    if (similarEvents.length > 3) {
+      score += Math.min(20, similarEvents.length * 2);
+    }
+
+    return score;
+  }
+
+  async writeDigest(digest: DigestOutput, outputDir: string = 'reports'): Promise<void> {
+    const digestJsonPath = path.join(outputDir, `${digest.case}.digest.json`);
+    const digestMdPath = path.join(outputDir, `${digest.case}.digest.md`);
+
+    fs.mkdirSync(outputDir, { recursive: true });
+
+    fs.writeFileSync(digestJsonPath, JSON.stringify(digest, null, 2));
+
+    const md = this.formatMarkdown(digest);
+    fs.writeFileSync(digestMdPath, md);
+  }
+
+  private formatMarkdown(digest: DigestOutput): string {
+    const lines: string[] = [];
+
+    lines.push(`# Digest: ${digest.case}`);
+    lines.push('');
+    lines.push(`**Status**: ${digest.status}`);
+    lines.push(`**Duration**: ${digest.duration}ms`);
+    lines.push(`**Location**: ${digest.location}`);
+    if (digest.error) {
+      lines.push(`**Error**: ${digest.error}`);
+    }
+    lines.push('');
+
+    lines.push('## Summary');
+    lines.push(`- Total Events: ${digest.summary.totalEvents}`);
+    lines.push(`- Included Events: ${digest.summary.includedEvents}`);
+    lines.push(`- Budget Used: ${digest.summary.budgetUsed} / ${digest.summary.budgetLimit} bytes`);
+    lines.push('');
+
+    if (digest.suspects && digest.suspects.length > 0) {
+      lines.push('## Suspects');
+      for (const suspect of digest.suspects) {
+        lines.push(`- **Score: ${suspect.score.toFixed(1)}** - ${suspect.evt} (${suspect.lvl})`);
+        lines.push(`  - Reasons: ${suspect.reasons.join(', ')}`);
+        lines.push(`  - Time: ${new Date(suspect.ts).toISOString()}`);
+        if (suspect.corr) {
+          lines.push(`  - Correlation: ${suspect.corr}`);
+        }
+      }
+      lines.push('');
+    }
+
+    if (digest.events.length > 0) {
+      lines.push('## Events');
+      lines.push('```json');
+      for (const evt of digest.events) {
+        lines.push(JSON.stringify(evt));
+      }
+      lines.push('```');
+    }
+
+    return lines.join('\n');
+  }
+}
+
+export async function generateAllDigests(configPath?: string): Promise<number> {
+  const summaryPath = 'reports/summary.jsonl';
+  if (!fs.existsSync(summaryPath)) {
+    console.log('No summary.jsonl found');
+    return 0;
+  }
+
+  const config = DigestGenerator.loadConfig(configPath);
+  const generator = new DigestGenerator(config);
+
+  const content = fs.readFileSync(summaryPath, 'utf-8');
+  const lines = content.trim().split('\n').filter(Boolean);
+
+  let count = 0;
+  for (const line of lines) {
+    try {
+      const entry = JSON.parse(line);
+      if (entry.status === 'fail' && entry.artifactURI) {
+        const caseName = path.basename(entry.artifactURI, '.jsonl');
+        const digest = await generator.generateDigest(
+          caseName,
+          entry.status,
+          entry.duration,
+          entry.location,
+          entry.artifactURI,
+          entry.error
+        );
+
+        if (digest) {
+          const outputDir = path.dirname(entry.artifactURI);
+          await generator.writeDigest(digest, outputDir);
+          console.log(`âœ“ Generated digest for ${caseName}`);
+          count++;
+        }
+      }
+    } catch (e) {
+      console.warn('Failed to process entry:', line, e);
+    }
+  }
+
+  return count;
+}
+
+export async function generateDigestsForCases(cases: string[], configPath?: string): Promise<number> {
+  const summaryPath = 'reports/summary.jsonl';
+  if (!fs.existsSync(summaryPath)) {
+    console.log('No summary.jsonl found');
+    return 0;
+  }
+
+  const config = DigestGenerator.loadConfig(configPath);
+  const generator = new DigestGenerator(config);
+
+  const content = fs.readFileSync(summaryPath, 'utf-8');
+  const lines = content.trim().split('\n').filter(Boolean);
+
+  const caseSet = new Set(cases);
+  let count = 0;
+
+  for (const line of lines) {
+    try {
+      const entry = JSON.parse(line);
+      const caseName = entry.artifactURI ? path.basename(entry.artifactURI, '.jsonl') : '';
+      
+      if (caseSet.has(caseName) && entry.status === 'fail' && entry.artifactURI) {
+        const digest = await generator.generateDigest(
+          caseName,
+          entry.status,
+          entry.duration,
+          entry.location,
+          entry.artifactURI,
+          entry.error
+        );
+
+        if (digest) {
+          const outputDir = path.dirname(entry.artifactURI);
+          await generator.writeDigest(digest, outputDir);
+          console.log(`âœ“ Generated digest for ${caseName}`);
+          count++;
+        }
+      }
+    } catch (e) {
+      console.warn('Failed to process entry:', line, e);
+    }
+  }
+
+  return count;
+}
