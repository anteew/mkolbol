diff --git a/.github/ISSUE_TEMPLATE/devex_bug.md b/.github/ISSUE_TEMPLATE/devex_bug.md
index eb09d59..396b7f6 100644
--- a/.github/ISSUE_TEMPLATE/devex_bug.md
+++ b/.github/ISSUE_TEMPLATE/devex_bug.md
@@ -1,7 +1,7 @@
 ---
 name: DevEx Bug Report
 about: Report a bug or issue you encountered while using mkolbol
-title: "[BUG] "
+title: '[BUG] '
 labels: devex, bug
 assignees: ''
 ---
@@ -49,6 +49,7 @@ assignees: ''
 **Branch**:
 
 **Steps to reproduce from repo**:
+
 ```bash
 git clone <your-repo-url>
 cd <repo-directory>
@@ -65,6 +66,7 @@ npm install
 ```
 
 **Configuration files** (if relevant):
+
 ```yaml
 # vitest.config.ts, laminar.config.json, package.json snippets, etc.
 ```
@@ -92,6 +94,7 @@ Paste error output here
 <!-- If you ran tests with Laminar, please attach or link the following: -->
 
 - **Summary Output**:
+
   ```bash
   # Run: npx lam summary
   # Paste output here OR attach reports/summary.jsonl
diff --git a/.github/ISSUE_TEMPLATE/devex_request.md b/.github/ISSUE_TEMPLATE/devex_request.md
index 6142300..11c2732 100644
--- a/.github/ISSUE_TEMPLATE/devex_request.md
+++ b/.github/ISSUE_TEMPLATE/devex_request.md
@@ -1,7 +1,7 @@
 ---
 name: DevEx Feature Request
 about: Suggest an improvement or new feature for mkolbol
-title: "[REQUEST] "
+title: '[REQUEST] '
 labels: devex, feature-request
 assignees: ''
 ---
@@ -15,12 +15,15 @@ assignees: ''
 <!-- WHY is this feature needed? What problem does it solve? -->
 
 **Problem Statement**:
+
 <!-- Describe the pain point or limitation you're facing -->
 
 **Use Case**:
+
 <!-- Describe your specific use case or scenario -->
 
 **Impact**:
+
 <!-- Who would benefit from this? How would it improve workflows? -->
 
 ## Proposed Solution
@@ -28,6 +31,7 @@ assignees: ''
 <!-- If you have a specific idea for how this should work, describe it here -->
 
 **API/Interface**:
+
 <!-- What would the API or user interface look like? -->
 
 ```typescript
@@ -35,6 +39,7 @@ assignees: ''
 ```
 
 **Configuration**:
+
 <!-- Any new configuration options? -->
 
 ```yaml
@@ -42,6 +47,7 @@ assignees: ''
 ```
 
 **Behavior**:
+
 <!-- Describe how this feature would behave -->
 
 ## Alternatives Considered
@@ -94,13 +100,17 @@ assignees: ''
 <!-- Optional: If you have thoughts on implementation complexity or challenges -->
 
 **Complexity Estimate**:
+
 <!-- Low / Medium / High / Unknown -->
 
 **Potential Challenges**:
+
 <!-- Any technical challenges you foresee? -->
 
 **Breaking Changes**:
+
 <!-- Would this require breaking changes to existing APIs? -->
+
 - [ ] Yes (describe):
 - [ ] No
 - [ ] Unknown
@@ -110,6 +120,7 @@ assignees: ''
 <!-- Add any other context, screenshots, or examples about the feature request here -->
 
 **Example Workflow**:
+
 <!-- How would you use this feature in practice? -->
 
 ```bash
@@ -117,6 +128,7 @@ assignees: ''
 ```
 
 **Benefits**:
+
 <!-- Summarize the key benefits -->
 
 1.
diff --git a/.github/pull_request_template.md b/.github/pull_request_template.md
index 25911b3..9a14f68 100644
--- a/.github/pull_request_template.md
+++ b/.github/pull_request_template.md
@@ -5,6 +5,7 @@
 ## Installation & Distribution Note
 
 If your PR involves changes to installation, packaging, or distribution:
+
 - **Prefer tarball path** (see [Distribution Matrix](docs/devex/distribution.md))
 - Test installation via: `npm install ./mkolbol-X.Y.Z.tar.gz`
 - Document in [Releases Guide](docs/devex/releases.md) if creating a release
@@ -53,6 +54,7 @@ Please review the [Developer Experience Style Guide](../../docs/devex/mk-dx-styl
 - [ ] **CI/CD**: All CI checks pass; no new warnings
 
 **DX Resources:**
+
 - 📖 [First Five Minutes](../../docs/devex/first-five-minutes.md) — New to mkolbol?
 - 🔧 [Using mkolbol in Your Repo](../../docs/devex/using-mkolbol-in-your-repo.md) — Integrating mkolbol
 - 🎓 [Hello Calculator Tutorial](../../docs/devex/hello-calculator.md) — Build your first topology
@@ -70,4 +72,3 @@ Please review the [Developer Experience Style Guide](../../docs/devex/mk-dx-styl
 - [ ] Commit messages follow conventional commits (feat:, fix:, docs:, etc.)
 - [ ] No unrelated changes included
 - [ ] No debug code or console.logs left behind
-
diff --git a/.github/workflows/release.yml b/.github/workflows/release.yml
index 2bac61a..c2f0351 100644
--- a/.github/workflows/release.yml
+++ b/.github/workflows/release.yml
@@ -12,36 +12,36 @@ jobs:
   release:
     name: Create Release with Tarball
     runs-on: ubuntu-latest
-    
+
     steps:
       - name: Checkout
         uses: actions/checkout@v4
-      
+
       - name: Setup Node.js
         uses: actions/setup-node@v4
         with:
           node-version: 24
           cache: 'npm'
-      
+
       - name: Install dependencies
         run: npm ci
-      
+
       - name: Build
         run: npm run build
-      
+
       - name: Pack
         run: npm pack
-      
+
       - name: Extract version from tag
         id: version
         run: echo "VERSION=${GITHUB_REF#refs/tags/v}" >> $GITHUB_OUTPUT
-      
+
       - name: Get tarball filename
         id: tarball
         run: |
           TARBALL=$(ls mkolbol-*.tgz)
           echo "FILENAME=$TARBALL" >> $GITHUB_OUTPUT
-      
+
       - name: Create GitHub Release
         id: create_release
         uses: actions/github-script@v7
@@ -50,7 +50,7 @@ jobs:
             const fs = require('fs');
             const tag = context.ref.replace('refs/tags/', '');
             const version = tag.replace('v', '');
-            
+
             let releaseNotes = `## mkolbol ${version}\n\n`;
             releaseNotes += `Stream-based microkernel for AI agent systems\n\n`;
             releaseNotes += `### Installation\n\n`;
@@ -60,7 +60,7 @@ jobs:
             releaseNotes += '```\n\n';
             releaseNotes += `### Changes\n\n`;
             releaseNotes += `See commit history for details.`;
-            
+
             const release = await github.rest.repos.createRelease({
               owner: context.repo.owner,
               repo: context.repo.repo,
@@ -70,11 +70,11 @@ jobs:
               draft: false,
               prerelease: version.includes('-') || version.includes('alpha') || version.includes('beta') || version.includes('rc')
             });
-            
+
             core.setOutput('upload_url', release.data.upload_url);
             core.setOutput('release_id', release.data.id);
             core.notice(`✅ Created GitHub release v${version}`);
-      
+
       - name: Upload tarball to release
         uses: actions/upload-release-asset@v1
         env:
diff --git a/.github/workflows/smoke.yml b/.github/workflows/smoke.yml
index ab030ab..871ceff 100644
--- a/.github/workflows/smoke.yml
+++ b/.github/workflows/smoke.yml
@@ -2,38 +2,38 @@ name: Smoke Test
 
 on:
   push:
-    branches: [ main ]
+    branches: [main]
   pull_request:
-    branches: [ main ]
+    branches: [main]
 
 jobs:
   smoke:
     name: Smoke Test (Node ${{ matrix.node-version }})
     runs-on: ubuntu-latest
-    
+
     strategy:
       matrix:
         node-version: [24]
-    
+
     steps:
       - name: Checkout
         uses: actions/checkout@v4
-      
+
       - name: Setup Node.js ${{ matrix.node-version }}
         uses: actions/setup-node@v4
         with:
           node-version: ${{ matrix.node-version }}
           cache: 'npm'
-      
+
       - name: Install dependencies
         run: npm ci
-      
+
       - name: Build
         run: npm run build
-      
+
       - name: Create package tarball
         run: npm pack
-      
+
       - name: Verify tarball contents
         run: |
           # List first 200 entries to avoid log overflows; ignore SIGPIPE exits
@@ -46,19 +46,19 @@ jobs:
           echo "=== Checking excluded files ==="
           ! tar -tzf mkolbol-*.tgz | grep -q 'package/src/' && echo "✓ src/ excluded" || (echo "✗ src/ should be excluded" && exit 1)
           ! tar -tzf mkolbol-*.tgz | grep -q 'package/node_modules/' && echo "✓ node_modules/ excluded" || (echo "✗ node_modules/ should be excluded" && exit 1)
-      
+
       - name: Test installation in clean directory
         run: |
           mkdir -p /tmp/smoke-test
           cd /tmp/smoke-test
           npm install $GITHUB_WORKSPACE/mkolbol-*.tgz
-      
+
       - name: Verify CLI works
         run: |
           cd /tmp/smoke-test
           npx lam --help
           echo "✓ CLI executable"
-      
+
       - name: Verify package structure
         run: |
           cd /tmp/smoke-test
diff --git a/.github/workflows/tests.yml b/.github/workflows/tests.yml
index 9c86862..21ec800 100644
--- a/.github/workflows/tests.yml
+++ b/.github/workflows/tests.yml
@@ -2,9 +2,9 @@ name: Tests
 
 on:
   push:
-    branches: [ main ]
+    branches: [main]
   pull_request:
-    branches: [ main ]
+    branches: [main]
 
 jobs:
   test:
@@ -228,7 +228,7 @@ jobs:
           MK_LOCAL_NODE: '1'
         run: |
           echo "▶ Running TTL soak test under load..."
-          
+
           # Create topology for soak test
           mkdir -p reports
           cat > reports/ttl-soak-topology.yml << 'EOF'
@@ -261,13 +261,13 @@ jobs:
             - from: meter.output
               to: sink.input
           EOF
-          
+
           # Run topology for 10 seconds with high message volume
           timeout 12 node dist/scripts/mkctl.js run \
             --file reports/ttl-soak-topology.yml \
             --duration 10 \
             > /tmp/ttl-soak.log 2>&1 || true
-          
+
           # Validate throughput
           if [ -f reports/ttl-soak.jsonl ]; then
             SOAK_LINES=$(wc -l < reports/ttl-soak.jsonl)
@@ -279,7 +279,7 @@ jobs:
           else
             echo "⚠️  TTL soak test: No output file created"
           fi
-          
+
           # Check router heartbeat metadata
           if [ -f reports/router-endpoints.json ]; then
             echo "✅ Router endpoints snapshot available for TTL tracking"
diff --git a/.prettierignore b/.prettierignore
index e5f2b6e..34cca7a 100644
--- a/.prettierignore
+++ b/.prettierignore
@@ -1,6 +1,7 @@
 dist/
 node_modules/
 reports/
+archives/
 *.tgz
 *.log
 examples/configs/bad-invalid-yaml.yml
diff --git a/BOOTSTRAP_SUMMARY.md b/BOOTSTRAP_SUMMARY.md
index 48cdaf4..370c340 100644
--- a/BOOTSTRAP_SUMMARY.md
+++ b/BOOTSTRAP_SUMMARY.md
@@ -9,6 +9,7 @@ Created a complete `mk bootstrap` command for out-of-tree project scaffolding, a
 ### 1. Core Module: `src/mk/bootstrap.ts`
 
 **Key Functions:**
+
 - `bootstrapProject(appDir, options)` - Main bootstrap logic
   - Creates project directory structure
   - Copies template files
@@ -19,6 +20,7 @@ Created a complete `mk bootstrap` command for out-of-tree project scaffolding, a
 - `listTemplates()` - Returns available project templates
 
 **Features:**
+
 - **Multiple installation sources:**
   - `local` - Use local mkolbol repository path
   - `tarball` - Use packaged tarball (auto-detects or explicit path)
@@ -41,11 +43,13 @@ Created a complete `mk bootstrap` command for out-of-tree project scaffolding, a
 ### 2. CLI Integration: `scripts/mk.ts`
 
 **Command:**
+
 ```bash
 mk bootstrap <app-dir> [options]
 ```
 
 **Options:**
+
 - `--yes, -y` - Auto-install dependencies
 - `--verbose` - Show detailed progress
 - `--template <name>` - Choose template (default: hello-calculator)
@@ -54,6 +58,7 @@ mk bootstrap <app-dir> [options]
 - `--tarball <path>` - Explicit tarball path
 
 **Example Usage:**
+
 ```bash
 # Basic local development
 mk bootstrap my-app --yes
@@ -74,6 +79,7 @@ mk bootstrap my-app --yes --verbose
 ### 3. Tests: `tests/cli/mkBootstrap.spec.ts`
 
 **Test Coverage:**
+
 - ✅ Project creation from template
 - ✅ Package.json name update
 - ✅ mkolbol dependency configuration (local, git, tarball)
@@ -93,6 +99,7 @@ mk bootstrap my-app --yes --verbose
 ### 4. Templates: `examples/mk/init-templates/`
 
 **Current Templates:**
+
 - `hello-calculator/` - HTTP calculator with TTY rendering and logging
   - Includes mk.json, package.json, tsconfig.json
   - Sample src/index.ts
@@ -101,6 +108,7 @@ mk bootstrap my-app --yes --verbose
   - .mk/options.json for configuration
 
 **Template Structure:**
+
 ```
 hello-calculator/
 ├── .mk/
@@ -120,6 +128,7 @@ hello-calculator/
 ### Manual Testing
 
 ✅ **Basic Bootstrap (Local Source):**
+
 ```bash
 $ npm run build && node dist/scripts/mk.js bootstrap /tmp/mk-calc --yes
 
@@ -133,18 +142,21 @@ Next steps:
 ```
 
 ✅ **Git Source:**
+
 ```bash
 $ node dist/scripts/mk.js bootstrap /tmp/mk-test-git --source git --git-tag v0.2.0
 # package.json: "mkolbol": "github:anteew/mkolbol#v0.2.0"
 ```
 
 ✅ **Tarball Source:**
+
 ```bash
 $ node dist/scripts/mk.js bootstrap /tmp/mk-test-tarball --source tarball
 # package.json: "mkolbol": "/srv/repos0/mkolbol/mkolbol-0.2.0-rfc.tgz"
 ```
 
 ✅ **Verify mk Command:**
+
 ```bash
 $ cd /tmp/mk-calc
 $ npm run build
@@ -169,6 +181,7 @@ $ npx mk --version
 ## Template Structure Requirements
 
 Templates must have:
+
 - `package.json` - Will be personalized with project name
 - Valid npm package structure
 - (Optional) `README.md` - Will be personalized
@@ -186,6 +199,7 @@ Templates must have:
 ### Custom Template Variables
 
 Future enhancement: Support template variables beyond project name:
+
 ```typescript
 interface TemplateVars {
   projectName: string;
@@ -198,13 +212,16 @@ interface TemplateVars {
 ## Files Modified/Created
 
 **Created:**
+
 - `src/mk/bootstrap.ts` - Core bootstrap logic
 - `tests/cli/mkBootstrap.spec.ts` - Comprehensive test suite
 
 **Modified:**
+
 - `scripts/mk.ts` - Added bootstrap command handler
 
 **Used (Existing):**
+
 - `examples/mk/init-templates/hello-calculator/` - Default template
 
 ## Patch File
@@ -212,12 +229,14 @@ interface TemplateVars {
 **Location:** `patches/DIFF_T9703_mk-bootstrap.patch`
 
 **Contents:**
+
 - New bootstrap module (190 lines)
 - CLI integration (~50 lines)
 - Test suite (280+ lines)
 - Build artifacts (dist/)
 
 **Stats:**
+
 - 4,450 total lines in patch
 - 3 source files created/modified
 - 1 test file created
@@ -243,5 +262,6 @@ To use the bootstrap command:
 4. Start developing: `npm run build && npx mk run mk.json`
 
 For out-of-repo use:
+
 - Install from tarball: `npm pack && npm i -g mkolbol-*.tgz`
 - Or use git: `npm i -g github:anteew/mkolbol#v0.2.0`
diff --git a/CONTRIBUTING-DEVEX.md b/CONTRIBUTING-DEVEX.md
index 45d417a..513c052 100644
--- a/CONTRIBUTING-DEVEX.md
+++ b/CONTRIBUTING-DEVEX.md
@@ -38,6 +38,7 @@ Thank you for being an early adopter! Your feedback is invaluable in shaping mko
 ### What Makes Good Feedback
 
 **Good feedback is:**
+
 - **Specific** - "The lam summary command fails with Error X" vs. "Laminar doesn't work"
 - **Reproducible** - Include steps or a repo link so we can reproduce the issue
 - **Contextual** - Include environment details (OS, Node version, etc.)
@@ -58,6 +59,7 @@ A **minimal reproducible example** (repro) is the fastest way to get your issue
 ### When to Create a GitHub Repo
 
 Create a separate GitHub repository if:
+
 - The issue requires multiple files or a specific directory structure
 - You're using custom configuration files (vitest.config.ts, laminar.config.json, etc.)
 - The issue involves build/compilation steps
@@ -78,6 +80,7 @@ your-mkolbol-repro/
 **Steps to create:**
 
 1. **Initialize a new repo:**
+
    ```bash
    mkdir mkolbol-issue-123
    cd mkolbol-issue-123
@@ -86,11 +89,13 @@ your-mkolbol-repro/
    ```
 
 2. **Install minimal dependencies:**
+
    ```bash
    npm install mkolbol vitest
    ```
 
 3. **Add a single test file** that reproduces the issue:
+
    ```typescript
    // tests/repro.spec.ts
    import { describe, it, expect } from 'vitest';
@@ -105,19 +110,24 @@ your-mkolbol-repro/
    ```
 
 4. **Add a README** with repro steps:
+
    ```markdown
    # Repro for mkolbol issue #123
 
    ## Setup
+
    npm install
 
    ## Reproduce
+
    npm test
 
    ## Expected
+
    Test should pass
 
    ## Actual
+
    Test fails with error: [paste error]
    ```
 
@@ -126,6 +136,7 @@ your-mkolbol-repro/
 ### When to Use an Inline Example
 
 Use an inline code snippet if:
+
 - The issue can be reproduced with <20 lines of code
 - No custom configuration is needed
 - The issue is a simple API misuse or unexpected behavior
@@ -139,7 +150,7 @@ const kernel = new Kernel();
 const pipe = kernel.createPipe();
 
 // This throws an unexpected error
-pipe.write('test');  // TypeError: Cannot read property 'write' of undefined
+pipe.write('test'); // TypeError: Cannot read property 'write' of undefined
 ```
 
 ### What to Include
@@ -147,18 +158,23 @@ pipe.write('test');  // TypeError: Cannot read property 'write' of undefined
 Your minimal repro should include:
 
 #### Code
+
 - **Only the code necessary to reproduce the issue** - Remove unrelated logic
 - **Use default configurations** - Avoid custom configs unless they're part of the issue
 - **Isolate the problem** - One test case that fails, not an entire test suite
 
 #### Configuration
+
 Include configuration files only if they're relevant:
+
 - `package.json` - Only dependencies needed for the repro
 - `vitest.config.ts` - Only if custom config triggers the issue
 - `laminar.config.json` - Only if digest rules or config affect the issue
 
 #### Commands
+
 Document the exact commands to reproduce:
+
 ```bash
 # Install
 npm install
@@ -183,6 +199,7 @@ npx lam run --lane auto
 5. **Remove external dependencies** - Avoid databases, APIs, or third-party services
 
 **Before (not minimal):**
+
 ```typescript
 describe('Complex integration test suite', () => {
   let db, cache, api, kernel, executor, stateManager;
@@ -206,6 +223,7 @@ describe('Complex integration test suite', () => {
 ```
 
 **After (minimal):**
+
 ```typescript
 import { Executor, Kernel } from 'mkolbol';
 
@@ -214,7 +232,7 @@ it('fails when loading invalid topology', async () => {
   const executor = new Executor(kernel);
 
   const topology = { nodes: [], connections: [{ from: 'invalid', to: 'invalid' }] };
-  await executor.load(topology);  // Throws error
+  await executor.load(topology); // Throws error
 });
 ```
 
@@ -245,12 +263,14 @@ reports/
 **When to attach**: Always
 
 **What it contains**:
+
 - Pass/fail status for all tests
 - Durations
 - Error messages (if failed)
 - Artifact URIs (paths to detailed logs)
 
 **How to generate**:
+
 ```bash
 npx lam summary > summary.txt
 ```
@@ -262,6 +282,7 @@ Paste the output in your issue or attach `reports/summary.jsonl`.
 **When to attach**: For failing tests
 
 **What it contains**:
+
 - Full event stream for the test case
 - Setup, run, and teardown phases
 - stdout/stderr output
@@ -269,6 +290,7 @@ Paste the output in your issue or attach `reports/summary.jsonl`.
 - Error stack traces
 
 **How to find**:
+
 ```bash
 # List all case logs
 ls reports/*/*.jsonl
@@ -278,6 +300,7 @@ cat reports/kernel.spec/connect_moves_data_1_1.jsonl
 ```
 
 **What to include in issue**:
+
 - Attach the `.jsonl` file as a file attachment, OR
 - Paste relevant excerpts (first 50 lines, or events around the failure)
 
@@ -286,12 +309,14 @@ cat reports/kernel.spec/connect_moves_data_1_1.jsonl
 **When to attach**: Always
 
 **What it contains**:
+
 - Raw console output from your command
 - Error messages in their original format
 - Stack traces
 - Warnings and debug output
 
 **How to capture**:
+
 ```bash
 # Redirect both stdout and stderr to a file
 npm test > test-output.log 2>&1
@@ -306,9 +331,10 @@ Paste the full output in a `<details>` block:
 ```markdown
 <details>
 <summary>Full Terminal Output</summary>
-
 ```
+
 [paste output here]
+
 ```
 
 </details>
@@ -319,11 +345,13 @@ Paste the full output in a `<details>` block:
 **When to attach**: If you ran `npx lam digest`
 
 **What it contains**:
+
 - Filtered/sliced view of the failing test
 - Events around assertion failures
 - Structured failure summary
 
 **How to generate**:
+
 ```bash
 npx lam digest
 ```
@@ -336,6 +364,7 @@ Attach the `.digest.json` file(s) for failing tests.
 **When to attach**: Always
 
 **What to include**:
+
 ```bash
 # Node.js version
 node --version
@@ -360,18 +389,22 @@ Paste this information in the "Environment" section of the bug report.
 **What to attach**:
 
 1. **Summary**:
+
    ```bash
    npx lam summary > reports/SUMMARY.txt
    ```
+
    Attach `reports/SUMMARY.txt`
 
 2. **Case log**:
    Attach `reports/kernel.spec/connect_moves_data_1_1.jsonl`
 
 3. **Terminal output**:
+
    ```bash
    npx lam run --lane auto > lam-run.log 2>&1
    ```
+
    Paste `lam-run.log` in a `<details>` block
 
 4. **System info**:
@@ -390,6 +423,7 @@ Paste this information in the "Environment" section of the bug report.
 4. **Use gists** - For very large logs, create a GitHub Gist and link it
 
 **Tips**:
+
 - Compress large files: `tar czf reports.tar.gz reports/`
 - Use `.txt` extension for better GitHub preview: `mv output.log output.txt`
 
@@ -405,6 +439,7 @@ Follow these best practices to ensure your feedback is actionable:
 ![screenshot of error message]
 
 **✅ Do this:**
+
 ```
 Error: Cannot find module 'mkolbol'
   at Function.Module._resolveFilename (internal/modules/cjs/loader.js:889:15)
@@ -419,11 +454,13 @@ Error: Cannot find module 'mkolbol'
 ### 2. Include Full Error Messages
 
 **❌ Partial error:**
+
 ```
 Error: Invalid config
 ```
 
 **✅ Full stack trace:**
+
 ```
 Error: Invalid config: 'nodes' is required
   at Executor.load (/srv/repos0/mkolbol/dist/src/executor/Executor.js:42:15)
@@ -439,16 +476,19 @@ Error: Invalid config: 'nodes' is required
 When creating an issue, use labels to categorize it:
 
 **Bug reports:**
+
 - `devex` - DevEx-related issue
 - `bug` - Confirmed bug
 - `needs-repro` - Waiting for reproducible example
 
 **Feature requests:**
+
 - `devex` - DevEx-related request
 - `feature-request` - New feature
 - `enhancement` - Improvement to existing feature
 
 **Documentation:**
+
 - `docs` - Documentation issue/request
 - `examples` - Example code request
 
@@ -469,6 +509,7 @@ Fixes #18
 ### 5. Provide Context
 
 Don't just say "it doesn't work" - explain:
+
 - What you were trying to accomplish
 - What you expected to happen
 - What actually happened
@@ -491,6 +532,7 @@ If you're stuck or need help before filing an issue, here are your options:
 **How to access**: [GitHub Discussions](https://github.com/anteew/mkolbol/discussions)
 
 **Topics**:
+
 - **Q&A** - Ask questions about usage, APIs, or best practices
 - **Show and Tell** - Share what you've built with mkolbol
 - **Ideas** - Propose features or improvements (before creating a formal issue)
@@ -498,6 +540,7 @@ If you're stuck or need help before filing an issue, here are your options:
 ### FAQ and Documentation
 
 **Check these resources first:**
+
 - [Early Adopter Guide](docs/devex/early-adopter-guide.md) - 5-minute intro
 - [Quickstart](README.md#quickstart) - Installation and first steps
 - [Laminar Workflow Guide](docs/devex/laminar-workflow.md) - Test observability
@@ -505,6 +548,7 @@ If you're stuck or need help before filing an issue, here are your options:
 - [Testing CI Guide](docs/testing/ci.md) - CI integration
 
 **Common questions:**
+
 - **Installation issues** → [README Installation](README.md#installation)
 - **Test failures** → [Laminar Workflow](docs/devex/laminar-workflow.md)
 - **PTY/process mode** → [Process Mode CI](docs/testing/process-mode-ci.md)
@@ -519,6 +563,7 @@ If a community chat is added in the future, it will be linked in the README.
 ### Direct Issue Filing
 
 If you've:
+
 - Checked existing issues and docs
 - Have a reproducible bug or clear feature request
 - Can provide the necessary logs/context
@@ -557,7 +602,7 @@ If you're contributing code (PRs), here's what to expect:
 ### Tips for Faster Reviews
 
 - **Keep PRs small** - <300 lines of code change when possible
-- **Write clear commit messages** - Explain *why*, not just *what*
+- **Write clear commit messages** - Explain _why_, not just _what_
 - **Add tests** - Reviewers prioritize tested code
 - **Link to issues** - Reference the issue your PR addresses
 - **Respond to feedback** - Engage constructively with reviewer comments
@@ -566,22 +611,27 @@ If you're contributing code (PRs), here's what to expect:
 
 ```markdown
 ## Summary
+
 Fixes #123 - Add support for custom ANSI escape sequences in AnsiParser
 
 ## Changes
+
 - Extended AnsiParserModule to handle custom CSI sequences
 - Added configurable parser hooks for unknown sequences
 - Updated tests to cover new functionality
 
 ## Test Plan
+
 - [x] Added unit tests for custom sequence handling
 - [x] Verified existing tests still pass
 - [x] Tested with real PTY output (attached example in issue #123)
 
 ## Breaking Changes
+
 None
 
 ## Documentation
+
 - Updated AnsiParserModule JSDoc
 - Added example in examples/ansi-parser-custom.ts
 ```
@@ -589,6 +639,7 @@ None
 ### How to Follow Up
 
 If your PR hasn't received feedback in the expected timeframe:
+
 1. **Add a polite comment** - "Friendly ping - any feedback on this PR?"
 2. **Check CI status** - Ensure all checks are passing
 3. **Be patient** - Maintainers may be busy; they'll get to it
@@ -602,6 +653,7 @@ We provide two issue templates to streamline feedback:
 ### When to Use `devex_bug.md`
 
 Use this template when:
+
 - You encountered an error or unexpected behavior
 - Tests are failing
 - Installation or setup failed
@@ -609,6 +661,7 @@ Use this template when:
 - Performance is degraded
 
 **Required fields:**
+
 - Bug description
 - Steps to reproduce
 - Expected vs. actual behavior
@@ -618,18 +671,21 @@ Use this template when:
 - Full error messages and logs
 
 **Optional fields:**
+
 - Laminar reports (if using Laminar)
 - Additional context
 
 ### When to Use `devex_request.md`
 
 Use this template when:
+
 - You want a new feature
 - You have an idea for improvement
 - Documentation is missing or unclear
 - Integration with another tool would be helpful
 
 **Required fields:**
+
 - Feature summary
 - Motivation (why is this needed?)
 - Proposed solution (if you have one)
@@ -638,6 +694,7 @@ Use this template when:
 - Related documentation/RFCs
 
 **Optional fields:**
+
 - Implementation considerations
 - Related issues
 - Example workflow
@@ -647,6 +704,7 @@ Use this template when:
 #### Bug Report (`devex_bug.md`)
 
 **Required** (issue may be closed if missing):
+
 - [x] Bug description
 - [x] Steps to reproduce
 - [x] Expected vs. actual behavior
@@ -656,12 +714,14 @@ Use this template when:
 - [x] Full error message
 
 **Optional** (nice to have):
+
 - [ ] Laminar summary output
 - [ ] Laminar per-case logs
 - [ ] Digest output
 - [ ] Additional context
 
 **Checklist items** (required):
+
 - [x] Read Early Adopter Guide
 - [x] Checked for duplicates
 - [x] Provided minimal repro
@@ -670,11 +730,13 @@ Use this template when:
 #### Feature Request (`devex_request.md`)
 
 **Required**:
+
 - [x] Feature summary
 - [x] Motivation (why needed?)
 - [x] Pain point addressed
 
 **Optional**:
+
 - [ ] Proposed solution
 - [ ] Alternatives considered
 - [ ] Related docs/RFCs
@@ -682,6 +744,7 @@ Use this template when:
 - [ ] Related issues
 
 **Checklist items** (required):
+
 - [x] Read Early Adopter Guide
 - [x] Checked for duplicates
 - [x] Described motivation clearly
@@ -691,6 +754,7 @@ Use this template when:
 ## Final Tips for Early Adopters
 
 ### Do:
+
 - ✅ Read the Early Adopter Guide before diving in
 - ✅ Try the Quickstart examples to understand the basics
 - ✅ Provide minimal, reproducible examples
@@ -699,6 +763,7 @@ Use this template when:
 - ✅ Use the issue templates
 
 ### Don't:
+
 - ❌ File duplicate issues (search first!)
 - ❌ Provide vague descriptions ("doesn't work")
 - ❌ Skip the reproducible example
@@ -706,6 +771,7 @@ Use this template when:
 - ❌ Expect instant responses (maintainers are humans too!)
 
 ### Remember:
+
 Your feedback shapes mkolbol's future. Even "small" bugs or suggestions are valuable. We appreciate your time and effort in helping us improve!
 
 ---
diff --git a/ERROR_CATALOG.md b/ERROR_CATALOG.md
index e0b2d0d..4ee4105 100644
--- a/ERROR_CATALOG.md
+++ b/ERROR_CATALOG.md
@@ -5,6 +5,7 @@ This document provides the canonical error codes, messages, and remediations for
 ## Error Format
 
 ### Text Format (Human-Readable)
+
 ```
 [ERR] <CODE> [at <location>] — <message>
   [Expected: <values>]
@@ -14,6 +15,7 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 ### JSON Format (Machine-Parseable)
+
 ```json
 {
   "code": "ERROR_CODE",
@@ -35,11 +37,13 @@ This document provides the canonical error codes, messages, and remediations for
 ## Error Codes
 
 ### CONFIG_NOT_FOUND
+
 **Message:** Configuration file not found  
 **Remediation:** Run: mk init --preset tty  
 **Docs:** https://mkolbol.dev/docs/config#locations
 
 **Example (Text):**
+
 ```
 [ERR] CONFIG_NOT_FOUND — Configuration file not found
   Fix: Run: mk init --preset tty
@@ -47,6 +51,7 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 **Example (JSON):**
+
 ```json
 {
   "code": "CONFIG_NOT_FOUND",
@@ -58,16 +63,19 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 ### CONFIG_INVALID
+
 **Message:** Configuration file is invalid  
 **Remediation:** Check the configuration file syntax  
 **Docs:** https://mkolbol.dev/docs/config
 
 ### CONFIG_PARSE
+
 **Message:** Failed to parse configuration file  
 **Remediation:** Run: mk format --to json --dry-run  
 **Docs:** https://mkolbol.dev/docs/config#yaml-indentation
 
 **Example (Text):**
+
 ```
 [ERR] CONFIG_PARSE at bad.yaml:12:7 — Failed to parse configuration file
   Fix: Run: mk format --to json --dry-run
@@ -75,6 +83,7 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 **Example (JSON):**
+
 ```json
 {
   "code": "CONFIG_PARSE",
@@ -90,21 +99,25 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 ### MODULE_NOT_FOUND
+
 **Message:** Required module not found  
 **Remediation:** Run: npm install  
 **Docs:** https://mkolbol.dev/docs/modules
 
 ### HEALTH_CHECK_FAILED
+
 **Message:** Health check failed  
 **Remediation:** Run: mk doctor --verbose  
 **Docs:** https://mkolbol.dev/docs/troubleshooting#health-checks
 
 ### SCHEMA_INVALID
+
 **Message:** Schema validation failed  
 **Remediation:** Check the schema documentation for valid values  
 **Docs:** https://mkolbol.dev/docs/schema
 
 **Example (Text):**
+
 ```
 [ERR] SCHEMA_INVALID at $.topology.nodes[0].runMode — Schema validation failed
   Expected: inproc, worker, process
@@ -113,6 +126,7 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 **Example (JSON):**
+
 ```json
 {
   "code": "SCHEMA_INVALID",
@@ -127,34 +141,41 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 ### TOPOLOGY_INVALID
+
 **Message:** Topology definition is invalid  
 **Remediation:** Run: mk graph <topology-file> to validate  
 **Docs:** https://mkolbol.dev/docs/topology
 
 ### RUNTIME_ERROR
+
 **Message:** Runtime error occurred  
 **Remediation:** Check logs for more details  
 **Docs:** https://mkolbol.dev/docs/troubleshooting
 
 ### FILE_NOT_FOUND
+
 **Message:** File not found  
 **Remediation:** Verify the file path exists
 
 ### INVALID_ARGUMENT
+
 **Message:** Invalid command line argument  
 **Remediation:** Run: mk <command> --help
 
 ### UNKNOWN_COMMAND
+
 **Message:** Unknown command  
 **Remediation:** Run: mk --help
 
 **Example (Text):**
+
 ```
 [ERR] UNKNOWN_COMMAND — Unknown command: {"command":"nonexistent"}
   Fix: Run: mk --help
 ```
 
 **Example (JSON):**
+
 ```json
 {
   "code": "UNKNOWN_COMMAND",
@@ -167,25 +188,30 @@ This document provides the canonical error codes, messages, and remediations for
 ```
 
 ### PERMISSION_DENIED
+
 **Message:** Permission denied  
 **Remediation:** Check file permissions or run with appropriate privileges
 
 ### DEPENDENCY_ERROR
+
 **Message:** Dependency error  
 **Remediation:** Run: npm install  
 **Docs:** https://mkolbol.dev/docs/installation
 
 ### NETWORK_ERROR
+
 **Message:** Network error occurred  
 **Remediation:** Check network connectivity and try again
 
 ### TIMEOUT
+
 **Message:** Operation timed out  
 **Remediation:** Increase timeout value or check system resources
 
 ## Usage
 
 ### In Code
+
 ```typescript
 import { createError, formatError } from './src/mk/errors.js';
 
@@ -199,6 +225,7 @@ console.error(formatError(error, 'json'));
 ```
 
 ### CLI Flag
+
 ```bash
 # Get JSON error output
 mk run invalid-file.yaml --json
@@ -207,6 +234,7 @@ mk run invalid-file.yaml --json
 ## Implementation
 
 See:
+
 - [src/mk/errors.ts](file:///srv/repos0/mkolbol/src/mk/errors.ts) - Error definitions and formatting
 - [scripts/mk.ts](file:///srv/repos0/mkolbol/scripts/mk.ts) - CLI integration
 - [tests/cli/mkdxErrors.spec.ts](file:///srv/repos0/mkolbol/tests/cli/mkdxErrors.spec.ts) - Error tests
diff --git a/agent_template/AMPCODE_TEMPLATE.md b/agent_template/AMPCODE_TEMPLATE.md
index 0b1cb32..a0e4e85 100644
--- a/agent_template/AMPCODE_TEMPLATE.md
+++ b/agent_template/AMPCODE_TEMPLATE.md
@@ -200,18 +200,20 @@ At completion, aggregate to `ampcode.log` with:
 - [Any tricky parts the architect wants to flag upfront]
 
 Orchestration Log (amp)
+
 - amp should write a JSON Lines log to `reports/amp.log.jsonl` with entries:
   `ts`, `waveId`, `taskId`, `agent`, `state` (queued|running|pass|fail),
   `message`, and `exception`/`error` when applicable.
 - Keep the human-readable `ampcode.log` if desired; JSONL is the source of truth for tools.
 
-
 ## Lint Debt Clean Sweep (Pattern)
+
 - Branch name: `mkolbol-devex-pXX-lint-cleanup`
 - Goals: remove unused vars/args; drop obsolete eslint-disable comments; run Prettier; keep warnings policy as warn-only.
 - Exclude generated artifacts from formatting: add `dist/`, `reports/`, `patches/` to `.prettierignore` if not present.
 - Local gate: `npm run lint && npm run ci:local:fast` before push.
 
 ## Large File Archiving (Docs & Logs)
+
 - Rotate large logs (e.g., `ampcode.log`) into `archives/ampcode.log.<UTC>` and replace with a short pointer file.
 - When `devex.md` grows beyond ~10k lines, move completed sprint blocks into `archives/devex-<date>-archive.md` and leave links.
diff --git a/agent_template/README.md b/agent_template/README.md
index c556786..9ee398e 100644
--- a/agent_template/README.md
+++ b/agent_template/README.md
@@ -3,16 +3,19 @@
 This folder defines how we collaborate with agents on the Xenomorph repo.
 
 Roles
+
 - amp (master): persistent coordinator. Reads tasks, plans waves, supervises workers, writes status.
 - Workers (ephemeral): e.g., claude, gemini. They live only for their task, produce patches/logs, and exit.
 
 Canonical Files
+
 - amp tasks: `ampcode.md` (use agent_template/AMPCODE_TEMPLATE.md as the source-of-truth template). amp reads this, executes waves, and writes `ampcode.log`.
 - amp oracle: `ampcode-oracle.msg` (optional gate). amp asks an oracle LLM for advice, writes the message here, and waits for the Architect’s approval.
 - logs: keep `ampcode.log` at repo root; store worker logs under `reports/` (e.g., `reports/claude.log`, `reports/gemini.log`).
 - patches: workers should emit unified diffs named `DIFF_<AGENT>_Txxxx_<slug>.patch` under `patches/` and also apply changes in-tree.
 
 Waves & Tasks
+
 - Use waves to group parallelizable tasks: each wave lists `tasks: [T1234, ...]`, `parallel: true|false`, `depends_on` when needed.
 - Each task must include:
   - Title + brief “why”
@@ -23,50 +26,57 @@ Waves & Tasks
   - Deliverables (code, tests, docs, patches)
 
 Expected Outputs
+
 - amp: updates `ampcode.log` with wave/task results (PASS/FAIL, timings, summaries). If using oracle, writes `ampcode-oracle.msg` before dispatch.
 - workers: create code changes + `patches/DIFF_*.patch`, run Verify Commands, and write a concise log (stdout → `reports/<agent>.log`).
 
 Conventions
+
 - IDs: `Txxxx` for tasks, `Dxx` for design docs/sprints, `Wave A/B/...` for grouping.
 - Provenance: builds should embed version info where applicable (e.g., `-ldflags` for Go version strings), and perf runs should record seeds.
 - Binaries: never commit compiled binaries or build caches. `.gitignore` should cover `*.pprof`, `trace.out`, and Go `.gocache`.
 - Determinism: prefer seeded runs for reproducible ordering; don’t assert bitwise-equal timings.
 
 Go/Perf Quick Commands
+
 - Build (per module): `go build ./...`
 - Test (all): `go test ./...`
 - Perf bundle (example): `bash scripts/xpf-make-bundle.sh /tmp/xr real_report-big.scm`
 - Profiler report: `tools/xeno-prof/xeno-prof --bundle /tmp/xr`
 
 Guardrails
+
 - New features require tests and docs. Do not degrade first-time user experience.
 - Keep changes minimal, cohesive, and reversible.
 - If a wave is risky, require the oracle checkpoint and Architect approval before dispatch.
 
 How to Use
-1) Architect authors `ampcode.md` from `agent_template/AMPCODE_TEMPLATE.md`.
-2) amp validates, obtains `ampcode-oracle.msg` if required, then dispatches waves.
-3) Workers apply patches, run Verify Commands, and write logs. amp aggregates in `ampcode.log`.
-4) Architect validates changes, then iteration continues.
 
+1. Architect authors `ampcode.md` from `agent_template/AMPCODE_TEMPLATE.md`.
+2. amp validates, obtains `ampcode-oracle.msg` if required, then dispatches waves.
+3. Workers apply patches, run Verify Commands, and write logs. amp aggregates in `ampcode.log`.
+4. Architect validates changes, then iteration continues.
 
 Tooling
-- Use tools/xeno-validate to lint agent files: `GOWORK=off go build ./tools/xeno-validate` then `./xeno-validate file.md`
 
+- Use tools/xeno-validate to lint agent files: `GOWORK=off go build ./tools/xeno-validate` then `./xeno-validate file.md`
 
 Canonical Plan
+
 - Prefer `ampcode.json` at repo root (pure JSON).
 - `ampcode.md` is optional; if used, begin with a fenced ```json block containing the same plan.
 - Validators: `tools/xeno-validate` parses either and emits a normalized plan.
-Logging Standard
+  Logging Standard
 - Format: JSON Lines (one JSON object per line).
 - Files: write to `reports/<agent>.log.jsonl` (e.g., `reports/claude.log.jsonl`).
 - Required keys per entry:
   - `ts` (RFC3339 UTC), `agent`, `taskId`, `waveId` (optional), `event` (e.g., step|cmd|result), `level` (info|warn|error), `message`.
   - `exception` (boolean) and `error` (object) when an exception occurs; include `type`, `detail`, optional `stack`.
 - Example:
+
 ```json
 {"ts":"2025-10-09T15:40:00Z","agent":"claude","taskId":"T3001","event":"cmd","level":"info","message":"go test ./xenolang/...","exception":false}
 {"ts":"2025-10-09T15:41:02Z","agent":"claude","taskId":"T3001","event":"result","level":"error","message":"tests failed","exception":true,"error":{"type":"TestFailure","detail":"2 failing"}}
 ```
+
 - Discovery: scan exceptions via `jq 'select(.exception==true)' reports/*.log.jsonl` or the `xeno-logscan` tool.
diff --git a/ampcode.md b/ampcode.md
index a7f96f5..1a0d27d 100644
--- a/ampcode.md
+++ b/ampcode.md
@@ -2,34 +2,64 @@
 {
   "ampcode": "v1",
   "waves": [
-    { "id": "MKD-P4-A",  "parallel": true,  "tasks": ["T9401","T9402","T9403"] },
-    { "id": "MKD-P4-B",  "parallel": true,  "depends_on": ["MKD-P4-A"], "tasks": ["T9404","T9405"] }
+    { "id": "MKD-P4-A", "parallel": true, "tasks": ["T9401", "T9402", "T9403"] },
+    { "id": "MKD-P4-B", "parallel": true, "depends_on": ["MKD-P4-A"], "tasks": ["T9404", "T9405"] }
   ],
   "tasks": [
-    {"id": "T9401", "agent": "susan", "title": "mk init: scaffold minimal project (+tests, .mk/options)",
-      "allowedFiles": ["scripts/mk.ts", "src/mk/init.ts", "templates/init/**", "tests/cli/mkInit.spec.ts"],
+    {
+      "id": "T9401",
+      "agent": "susan",
+      "title": "mk init: scaffold minimal project (+tests, .mk/options)",
+      "allowedFiles": [
+        "scripts/mk.ts",
+        "src/mk/init.ts",
+        "templates/init/**",
+        "tests/cli/mkInit.spec.ts"
+      ],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9401_mk-init.patch"]},
+      "deliverables": ["patches/DIFF_T9401_mk-init.patch"]
+    },
 
-    {"id": "T9402", "agent": "susan", "title": "mk build: bundle via esbuild + provenance metadata",
+    {
+      "id": "T9402",
+      "agent": "susan",
+      "title": "mk build: bundle via esbuild + provenance metadata",
       "allowedFiles": ["scripts/mk.ts", "src/mk/build.ts", "package.json"],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9402_mk-build.patch"]},
+      "deliverables": ["patches/DIFF_T9402_mk-build.patch"]
+    },
 
-    {"id": "T9403", "agent": "susan", "title": "mk package: capsule v0 (unsigned, deterministic)",
+    {
+      "id": "T9403",
+      "agent": "susan",
+      "title": "mk package: capsule v0 (unsigned, deterministic)",
       "allowedFiles": ["scripts/mk.ts", "src/mk/package.ts", "tests/cli/mkPackage.spec.ts"],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9403_mk-package-capsule.patch"]},
+      "deliverables": ["patches/DIFF_T9403_mk-package-capsule.patch"]
+    },
 
-    {"id": "T9404", "agent": "susan", "title": "mk ci plan: emit CI matrix + cache keys (Laminar hooks)",
+    {
+      "id": "T9404",
+      "agent": "susan",
+      "title": "mk ci plan: emit CI matrix + cache keys (Laminar hooks)",
       "allowedFiles": ["scripts/mk.ts", "src/mk/ciPlan.ts", "docs/devex/ci-acceptance-smoke.md"],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9404_mk-ci-plan.patch"]},
+      "deliverables": ["patches/DIFF_T9404_mk-ci-plan.patch"]
+    },
 
-    {"id": "T9405", "agent": "susan", "title": "Did‑you‑mean suggestions for commands/flags (DX)",
-      "allowedFiles": ["scripts/mk.ts", "src/mk/errors.ts", "docs/devex/mk-dx-style.md", "tests/cli/mkdxHelp.spec.ts"],
+    {
+      "id": "T9405",
+      "agent": "susan",
+      "title": "Did‑you‑mean suggestions for commands/flags (DX)",
+      "allowedFiles": [
+        "scripts/mk.ts",
+        "src/mk/errors.ts",
+        "docs/devex/mk-dx-style.md",
+        "tests/cli/mkdxHelp.spec.ts"
+      ],
       "verify": ["npm run build", "npm run test:ci"],
-      "deliverables": ["patches/DIFF_T9405_mk-did-you-mean.patch"]}
+      "deliverables": ["patches/DIFF_T9405_mk-did-you-mean.patch"]
+    }
   ]
 }
 ```
@@ -38,33 +68,54 @@
 {
   "ampcode": "v1",
   "waves": [
-    { "id": "P17-A_ORCH_V1",  "parallel": true,  "tasks": ["T9701","T9702","T9703","T9705"] },
-    { "id": "P17-B_ROUTER_P2", "parallel": true,  "depends_on": ["P17-A_ORCH_V1"], "tasks": ["T9711","T9712","T9713"] }
+    { "id": "P17-A_ORCH_V1", "parallel": true, "tasks": ["T9701", "T9702", "T9703", "T9705"] },
+    {
+      "id": "P17-B_ROUTER_P2",
+      "parallel": true,
+      "depends_on": ["P17-A_ORCH_V1"],
+      "tasks": ["T9711", "T9712", "T9713"]
+    }
   ],
   "tasks": [
-    {"id": "T9701", "agent": "susan", "title": "mk self install: where/uninstall/switch + --copy; Windows shims; doctor checks",
+    {
+      "id": "T9701",
+      "agent": "susan",
+      "title": "mk self install: where/uninstall/switch + --copy; Windows shims; doctor checks",
       "why": "Complete RFC v1 shim model so mk works anywhere without npm publish; add visibility and safe removal.",
       "allowedFiles": [
-        "scripts/mk.ts", "src/mk/selfInstall.ts", "src/mk/doctor.ts",
-        "tests/cli/mkSelf.spec.ts", "tests/cli/mkDoctor.spec.ts"
+        "scripts/mk.ts",
+        "src/mk/selfInstall.ts",
+        "src/mk/doctor.ts",
+        "tests/cli/mkSelf.spec.ts",
+        "tests/cli/mkDoctor.spec.ts"
       ],
       "verify": [
         "npm run build",
         "node dist/scripts/mk.js self install --bin-dir ./.mk/bin --from repo",
         "node dist/scripts/mk.js self where --json"
       ],
-      "deliverables": ["patches/DIFF_T9701_mk-self-install-complete.patch"]},
+      "deliverables": ["patches/DIFF_T9701_mk-self-install-complete.patch"]
+    },
 
-    {"id": "T9702", "agent": "susan", "title": "mk fetch <tag>: download toolchain tarball → ~/.mk/toolchains with SHA-256 verify",
+    {
+      "id": "T9702",
+      "agent": "susan",
+      "title": "mk fetch <tag>: download toolchain tarball → ~/.mk/toolchains with SHA-256 verify",
       "why": "Enable offline & reproducible installs; prepares bootstrap to use cached tarballs.",
       "allowedFiles": ["scripts/mk.ts", "src/mk/fetch.ts", "tests/cli/mkFetch.spec.ts"],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9702_mk-fetch.patch"]},
+      "deliverables": ["patches/DIFF_T9702_mk-fetch.patch"]
+    },
 
-    {"id": "T9703", "agent": "susan", "title": "mk bootstrap <app-dir>: out-of-tree scaffold using file: tarball or git tag",
+    {
+      "id": "T9703",
+      "agent": "susan",
+      "title": "mk bootstrap <app-dir>: out-of-tree scaffold using file: tarball or git tag",
       "why": "Let apps live outside the repo and still run mk quickly.",
       "allowedFiles": [
-        "scripts/mk.ts", "src/mk/bootstrap.ts", "examples/mk/init-templates/**",
+        "scripts/mk.ts",
+        "src/mk/bootstrap.ts",
+        "examples/mk/init-templates/**",
         "tests/cli/mkBootstrap.spec.ts"
       ],
       "verify": [
@@ -72,31 +123,63 @@
         "node dist/scripts/mk.js bootstrap /tmp/mk-calc --yes",
         "node /tmp/mk-calc/node_modules/.bin/ts-node -v || true"
       ],
-      "deliverables": ["patches/DIFF_T9703_mk-bootstrap.patch"]},
+      "deliverables": ["patches/DIFF_T9703_mk-bootstrap.patch"]
+    },
 
-    {"id": "T9705", "agent": "susan", "title": "mk doctor: toolchain/shim PATH + integrity checks",
+    {
+      "id": "T9705",
+      "agent": "susan",
+      "title": "mk doctor: toolchain/shim PATH + integrity checks",
       "why": "Fast diagnosis for naive users; surfaces exact remediation.",
       "allowedFiles": ["src/mk/doctor.ts", "tests/cli/mkDoctor.spec.ts", "docs/devex/doctor.md"],
       "verify": ["npm run build", "node dist/scripts/mk.js doctor --section toolchain --json"],
-      "deliverables": ["patches/DIFF_T9705_mk-doctor-toolchain.patch"]},
+      "deliverables": ["patches/DIFF_T9705_mk-doctor-toolchain.patch"]
+    },
 
-    {"id": "T9711", "agent": "susan", "title": "RoutingServer TTL/heartbeat expiry + stale withdraw; snapshot expiresAt",
+    {
+      "id": "T9711",
+      "agent": "susan",
+      "title": "RoutingServer TTL/heartbeat expiry + stale withdraw; snapshot expiresAt",
       "why": "Router P2 from RFC: liveness semantics for endpoints.",
-      "allowedFiles": ["src/router/RoutingServer.ts", "src/executor/Executor.ts", "tests/integration/router.ttl.spec.ts"],
+      "allowedFiles": [
+        "src/router/RoutingServer.ts",
+        "src/executor/Executor.ts",
+        "tests/integration/router.ttl.spec.ts"
+      ],
       "verify": ["npm run build", "npm run test:ci"],
-      "deliverables": ["patches/DIFF_T9711_router-ttl.patch"]},
+      "deliverables": ["patches/DIFF_T9711_router-ttl.patch"]
+    },
 
-    {"id": "T9712", "agent": "susan", "title": "mkctl endpoints --watch shows liveness/TTL; supports --json with status",
+    {
+      "id": "T9712",
+      "agent": "susan",
+      "title": "mkctl endpoints --watch shows liveness/TTL; supports --json with status",
       "why": "Expose liveness to users and scripts; aligns with snapshots.",
-      "allowedFiles": ["scripts/mkctl.ts", "tests/cli/mkctlEndpoints.spec.ts", "docs/devex/mkctl-cookbook.md"],
-      "verify": ["npm run build", "node dist/scripts/mkctl.js endpoints --watch --runtime-dir . --json | head -n 1"],
-      "deliverables": ["patches/DIFF_T9712_mkctl-endpoints-liveness.patch"]},
+      "allowedFiles": [
+        "scripts/mkctl.ts",
+        "tests/cli/mkctlEndpoints.spec.ts",
+        "docs/devex/mkctl-cookbook.md"
+      ],
+      "verify": [
+        "npm run build",
+        "node dist/scripts/mkctl.js endpoints --watch --runtime-dir . --json | head -n 1"
+      ],
+      "deliverables": ["patches/DIFF_T9712_mkctl-endpoints-liveness.patch"]
+    },
 
-    {"id": "T9713", "agent": "susan", "title": "Acceptance soak: TTL expiry under load (best-effort, non-gating)",
+    {
+      "id": "T9713",
+      "agent": "susan",
+      "title": "Acceptance soak: TTL expiry under load (best-effort, non-gating)",
       "why": "Sanity check for leaks/backpressure with liveness updates.",
-      "allowedFiles": ["docs/devex/ci-acceptance-smoke.md", ".github/workflows/tests.yml", "scripts/mk-acceptance.ts"],
+      "allowedFiles": [
+        "docs/devex/ci-acceptance-smoke.md",
+        ".github/workflows/tests.yml",
+        "scripts/mk-acceptance.ts"
+      ],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9713_router-ttl-soak.patch"]}
+      "deliverables": ["patches/DIFF_T9713_router-ttl-soak.patch"]
+    }
   ]
 }
 ```
@@ -104,12 +187,15 @@
 # Ampcode — P17: Orchestrator v1 (mk Anywhere) + Router P2 TTL
 
 Goal
+
 - Deliver mk “anywhere” without npm publish (shim + fetch + bootstrap) and add router liveness semantics with a minimal watch UX.
 
 Constraints
+
 - Keep Node 24 only. No network transports beyond what’s needed for fetch (HTTP GET). TTL is local-only; no gossip yet.
 
 Verification (quick)
+
 ```bash
 export MK_LOCAL_NODE=1
 npm run build && npm run test:ci
@@ -121,33 +207,52 @@ node dist/scripts/mkctl.js endpoints --runtime-dir . --json | jq '.[0].status'
 ```json
 {
   "ampcode": "v1",
-  "waves": [
-    { "id": "P18A-TCP", "parallel": false, "tasks": ["N1801","N1802","N1803"] }
-  ],
+  "waves": [{ "id": "P18A-TCP", "parallel": false, "tasks": ["N1801", "N1802", "N1803"] }],
   "branch": "mkolbol-net-p18a-tcp-pipe",
   "tasks": [
-    {"id":"N1801","agent":"susan","title":"FrameCodec + Transport interface (pre-step)",
-      "why":"Shared base for TCP/WS pipes; length-prefixed framing + ping/pong.",
-      "allowedFiles":["src/net/frame.ts","src/net/transport.ts","tests/net/frame.spec.ts"],
-      "verify":["npm run build","npm run test:ci"],
-      "deliverables":["patches/DIFF_N1801_frame-transport.patch"]},
-
-    {"id":"N1802","agent":"susan","title":"TCPPipe adapter + Remote Viewer example",
-      "why":"Enable cross-process streams over TCP; simplest remote demo.",
-      "allowedFiles":["src/pipes/adapters/TCPPipe.ts","examples/network/remote-viewer/**","tests/integration/tcpPipe.spec.ts"],
-      "verify":["npm run build","npm run test:ci"],
-      "deliverables":["patches/DIFF_N1802_tcp-pipe.patch"]},
-
-    {"id":"N1803","agent":"susan","title":"Acceptance: PTY in proc A → TCP → viewer proc B (ephemeral ports)",
-      "why":"Prove end-to-end with port collision safety and Laminar artifacts.",
-      "allowedFiles":["docs/devex/network-quickstart.md",".github/workflows/tests.yml","scripts/ci-local.ts"],
-      "verify":["npm run build","npm run ci:local:fast"],
-      "deliverables":["patches/DIFF_N1803_tcp-acceptance.patch"]}
+    {
+      "id": "N1801",
+      "agent": "susan",
+      "title": "FrameCodec + Transport interface (pre-step)",
+      "why": "Shared base for TCP/WS pipes; length-prefixed framing + ping/pong.",
+      "allowedFiles": ["src/net/frame.ts", "src/net/transport.ts", "tests/net/frame.spec.ts"],
+      "verify": ["npm run build", "npm run test:ci"],
+      "deliverables": ["patches/DIFF_N1801_frame-transport.patch"]
+    },
+
+    {
+      "id": "N1802",
+      "agent": "susan",
+      "title": "TCPPipe adapter + Remote Viewer example",
+      "why": "Enable cross-process streams over TCP; simplest remote demo.",
+      "allowedFiles": [
+        "src/pipes/adapters/TCPPipe.ts",
+        "examples/network/remote-viewer/**",
+        "tests/integration/tcpPipe.spec.ts"
+      ],
+      "verify": ["npm run build", "npm run test:ci"],
+      "deliverables": ["patches/DIFF_N1802_tcp-pipe.patch"]
+    },
+
+    {
+      "id": "N1803",
+      "agent": "susan",
+      "title": "Acceptance: PTY in proc A → TCP → viewer proc B (ephemeral ports)",
+      "why": "Prove end-to-end with port collision safety and Laminar artifacts.",
+      "allowedFiles": [
+        "docs/devex/network-quickstart.md",
+        ".github/workflows/tests.yml",
+        "scripts/ci-local.ts"
+      ],
+      "verify": ["npm run build", "npm run ci:local:fast"],
+      "deliverables": ["patches/DIFF_N1803_tcp-acceptance.patch"]
+    }
   ]
 }
 ```
 
 Branch Instructions
+
 - IMPORTANT: This sprint runs ONLY on branch `mkolbol-net-p18a-tcp-pipe`.
 - Do not change branches or merge; commit patches and logs as usual. I will handle PRs/merges.
 - Use ephemeral ports from 30010–30019 for tests. Avoid hard-coded 3000.
@@ -155,12 +260,15 @@ Branch Instructions
 # Ampcode — MKD RC Sweep: Acceptance + Release Prep
 
 Goal
+
 - Perform an end‑to‑end RC sweep to validate mk’s first‑run experience and release path; finalize any small UX gaps.
 
 Constraints
+
 - Bundle uses esbuild; capsule is unsigned (deterministic filename); CI plan mirrors local behavior and Laminar hooks.
 
 Verification
+
 ```bash
 export MK_LOCAL_NODE=1
 npm run build
@@ -171,34 +279,67 @@ npm run test:ci
 {
   "ampcode": "v1",
   "waves": [
-    { "id": "MKD-RC-A",  "parallel": true,  "tasks": ["T9501","T9502"] },
-    { "id": "MKD-RC-B",  "parallel": true,  "depends_on": ["MKD-RC-A"], "tasks": ["T9503","T9504","T9505"] }
+    { "id": "MKD-RC-A", "parallel": true, "tasks": ["T9501", "T9502"] },
+    {
+      "id": "MKD-RC-B",
+      "parallel": true,
+      "depends_on": ["MKD-RC-A"],
+      "tasks": ["T9503", "T9504", "T9505"]
+    }
   ],
   "tasks": [
-    {"id": "T9501", "agent": "susan", "title": "Acceptance script: mk init → run → doctor → format → run --yaml (one-shot)",
-      "allowedFiles": ["scripts/mk-acceptance.ts", "tests/devex/acceptance/local-node-v1.md", "package.json"],
+    {
+      "id": "T9501",
+      "agent": "susan",
+      "title": "Acceptance script: mk init → run → doctor → format → run --yaml (one-shot)",
+      "allowedFiles": [
+        "scripts/mk-acceptance.ts",
+        "tests/devex/acceptance/local-node-v1.md",
+        "package.json"
+      ],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9501_mk-acceptance-script.patch"]},
+      "deliverables": ["patches/DIFF_T9501_mk-acceptance-script.patch"]
+    },
 
-    {"id": "T9502", "agent": "susan", "title": "CI smoke: mk init/build/package (non‑gating job)",
+    {
+      "id": "T9502",
+      "agent": "susan",
+      "title": "CI smoke: mk init/build/package (non‑gating job)",
       "allowedFiles": [".github/workflows/tests.yml", "docs/devex/ci-acceptance-smoke.md"],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9502_ci-mk-rc-smoke.patch"]},
+      "deliverables": ["patches/DIFF_T9502_ci-mk-rc-smoke.patch"]
+    },
 
-    {"id": "T9503", "agent": "susan", "title": "mk build/package output polish (provenance path + friendly summary)",
+    {
+      "id": "T9503",
+      "agent": "susan",
+      "title": "mk build/package output polish (provenance path + friendly summary)",
       "allowedFiles": ["src/mk/build.ts", "src/mk/package.ts", "docs/devex/packaging.md"],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9503_build-package-polish.patch"]},
+      "deliverables": ["patches/DIFF_T9503_build-package-polish.patch"]
+    },
 
-    {"id": "T9504", "agent": "susan", "title": "mk ci plan: add --env output for export; doc examples",
-      "allowedFiles": ["src/mk/ciPlan.ts", "tests/fixtures/mkdx/mk-ci-plan.help.txt", "docs/devex/ci-acceptance-smoke.md"],
+    {
+      "id": "T9504",
+      "agent": "susan",
+      "title": "mk ci plan: add --env output for export; doc examples",
+      "allowedFiles": [
+        "src/mk/ciPlan.ts",
+        "tests/fixtures/mkdx/mk-ci-plan.help.txt",
+        "docs/devex/ci-acceptance-smoke.md"
+      ],
       "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_T9504_ci-plan-env.patch"]},
+      "deliverables": ["patches/DIFF_T9504_ci-plan-env.patch"]
+    },
 
-    {"id": "T9505", "agent": "susan", "title": "Help snapshots & did‑you‑mean finalization",
+    {
+      "id": "T9505",
+      "agent": "susan",
+      "title": "Help snapshots & did‑you‑mean finalization",
       "allowedFiles": ["tests/cli/mkdxHelp.spec.ts", "docs/devex/mk-dx-style.md"],
       "verify": ["npm run build", "npm run test:ci"],
-      "deliverables": ["patches/DIFF_T9505_help-snapshots-final.patch"]}
+      "deliverables": ["patches/DIFF_T9505_help-snapshots-final.patch"]
+    }
   ]
 }
 ```
diff --git a/ampcode_next.md b/ampcode_next.md
index cede22e..def1fb8 100644
--- a/ampcode_next.md
+++ b/ampcode_next.md
@@ -3,8 +3,8 @@
   "ampcode": "v1",
   "notes": "Do not branch/commit/push — VEGA handles git. Next sprint draft only.",
   "waves": [
-    { "id": "HINTS-A", "parallel": true,  "tasks": ["T4301", "T4302"] },
-    { "id": "HINTS-B", "parallel": true,  "depends_on": ["HINTS-A"], "tasks": ["T4303", "T4304"] },
+    { "id": "HINTS-A", "parallel": true, "tasks": ["T4301", "T4302"] },
+    { "id": "HINTS-B", "parallel": true, "depends_on": ["HINTS-A"], "tasks": ["T4303", "T4304"] },
     { "id": "HINTS-C", "parallel": false, "depends_on": ["HINTS-B"], "tasks": ["T4305"] }
   ],
   "tasks": [
@@ -57,6 +57,7 @@
 Goal: Add compact “what to do next” hints for each failing test, both in console (one line per fail when enabled) and as per-case artifacts (.hints.json/.md). Keep output tiny and agent-friendly.
 
 Scope
+
 - Detect common triage patterns from digest + minimal log context:
   - missing-include: Expected domain event absent in digest window
   - redaction-mismatch: Rule pack expects pattern (e.g., jwt) but redactedFields==0
@@ -71,11 +72,12 @@ Scope
   - Env override: `LAMINAR_HINTS=1`
 
 Acceptance
+
 - When a digested failure is present, enabling hints shows exactly one concise line per fail with: cause tag, one key signal (evt/field), and 1–2 suggested commands.
 - Per-case hints artifacts exist and reference the exact files/commands.
 - No change to default console output when disabled.
 
 Non-goals
+
 - Do not rewrite digest or event schema.
 - No network calls or heavy log scans; only digest + small local window from the case file.
-
diff --git a/archived/mcp-kernel/KERNEL_RFC.md b/archived/mcp-kernel/KERNEL_RFC.md
index d545f2d..b957b8e 100644
--- a/archived/mcp-kernel/KERNEL_RFC.md
+++ b/archived/mcp-kernel/KERNEL_RFC.md
@@ -1,9 +1,11 @@
 # Obol Kernel RFC (Draft)
 
 Purpose
+
 - Define a microkernel for the Obol MCP server that is testable in isolation, easy-install (Node + TypeScript + SQLite), and supports future process/network splits without API changes.
 
 Scope and responsibilities
+
 - In-kernel only:
   - JSON-RPC/MCP router (request/response and notifications)
   - Transport adapters (in-proc bus; stdio; HTTP/SSE), pluggable
@@ -17,17 +19,19 @@ Scope and responsibilities
   - All business logic exposed via MCP tools/resources
 
 Protocol and IPC
+
 - Protocol: JSON-RPC 2.0 with MCP conventions
   - Methods: initialize, tools/list, tools/call, resources/list, resources/read, resources/subscribe
   - Notifications: notifications/resources/updated, notifications/resources/list_changed, notifications/progress, ping
 - Boundary rule: all inter-module calls are MCP messages over the kernel bus; no direct function calls across module boundaries.
 
 Transports
+
 - In-proc bus (default): zero-IO message dispatcher with deterministic ordering.
 - Stdio adapter: framing + env identity for local adapters.
 - HTTP/SSE adapter: HTTP JSON-RPC for calls; SSE for push streams.
 - Migration path: in-proc → Unix domain sockets → TCP/WebSocket (no API changes; swap adapters).
-Middleware and filters (bus pipeline)
+  Middleware and filters (bus pipeline)
 - Purpose: composable, transparent cross-cutting concerns without changing servers.
 - Placement: pre- and post-dispatch handlers in the kernel bus; applicable per-transport and per-connection.
 - Examples:
@@ -46,24 +50,25 @@ Middleware and filters (bus pipeline)
   - Conflicts resolved by explicit order; kernel validates compatible stage ordering.
 
 Plugin model
+
 - Plugin = user-space “server” exposing MCP:
   - tools: array of {name, description, inputSchema, outputSchema}
   - resources: array of {uri, description, contentSchema, subscribable}
 - Manifest (JSON, semver):
   {
-    "name": "tickets",
-    "version": "1.0.0",
-    "tools": [...],
-    "resources": [...],
-    "capabilities": ["tickets.read","tickets.write"]
+  "name": "tickets",
+  "version": "1.0.0",
+  "tools": [...],
+  "resources": [...],
+  "capabilities": ["tickets.read","tickets.write"]
   }
 - Lifecycle:
   - load(manifest) → register tools/resources → tools/list reflects → emit notifications/tools/list_changed
   - unload(name@version) → deregister → emit list_changed
 - Isolation:
   - Optional per-plugin worker/thread/process; kernel enforces timeouts, concurrency caps, circuit breakers.
-Control plane (sideband)
-- Separate from data path; exposed as MCP tools/resources under mcp://kernel/*
+    Control plane (sideband)
+- Separate from data path; exposed as MCP tools/resources under mcp://kernel/\*
 - Tools:
   - kernel.middleware.list | enable | disable | configure
   - kernel.transport.list | configure
@@ -77,14 +82,16 @@ Control plane (sideband)
 - Behavior:
   - Runtime reconfiguration without restarting; atomic pipeline swaps.
   - Capability-gated (admin-only) and auditable via the event log.
-  - Sideband changes emit notifications/resources/updated on corresponding mcp://kernel/* URIs.
+  - Sideband changes emit notifications/resources/updated on corresponding mcp://kernel/\* URIs.
 
 Auth and identity
+
 - HTTP: Authorization: Bearer <token> → binds to agent_id; scopes map to capabilities.
 - Stdio: environment variables (MCP_AGENT_ID, MCP_TOKEN) provide identity.
 - Kernel enforces per-tool/resource capability checks; deny-by-default.
 
 Subscriptions and notifications
+
 - resources/subscribe(uri) → server pushes:
   - notifications/resources/updated on content change
   - notifications/resources/list_changed for collection membership changes
@@ -92,31 +99,36 @@ Subscriptions and notifications
 - Ordering: per-resource ordering preserved; coalescing merges burst updates.
 
 Backpressure and coalescing
+
 - Bounded queues per subscriber and per plugin.
 - Coalesce by resource URI; throttle slow consumers; drop-duplicate counters and metrics.
 - SSE: detect slow clients; apply coalescing; never unbounded RAM growth.
 
 Event log and replay
+
 - Append-only events table:
   - seq (monotonic), type, aggregate_id, payload, created_at
 - On tool success, append event(s); on restart or audit, replay to reconstruct state and verify resource/queue membership.
 - Golden transcript support for deterministic replays.
 
 Presence and liveness
+
 - Accept ping from clients; record last_ping_at and status; timeouts mark offline.
 - Presence changes reflected in mcp://agents/directory.json (plugin-provided resource); kernel provides hooks and notifications.
 
 Supervision and failure handling
+
 - Per-call timeouts; plugin error transforms → structured JSON-RPC errors.
 - Circuit breaker on repeated plugin faults with backoff.
 - Health metrics per plugin and per transport.
 
 Testing strategy
+
 - Kernel-only harness:
   - In-proc bus; stdio/HTTP/SSE stubs; in-memory store or SQLite tmp DB (Drizzle migrations).
   - Tests: initialize → list → subscribe → updates; progress streaming; auth binding; backpressure/coalescing; event-log replay.
   - Middleware: deterministic pre/post execution order; compression round-trip (size decreases, payload equality); ACL denies; tracing/metrics emission; idempotent retries.
-  - Control plane: kernel.middleware.enable/disable/configure affects only targeted scopes; atomic pipeline swap with no message loss; mcp://kernel/* resources update and notify.
+  - Control plane: kernel.middleware.enable/disable/configure affects only targeted scopes; atomic pipeline swap with no message loss; mcp://kernel/\* resources update and notify.
 - Plugin harness (in-proc):
   - Manifest validation, dynamic load/unload; tools/resources registration; tickets plugin CRUD + FSM errors; notifications and persistence.
   - Middleware compatibility: plugins observe original payloads; no code changes required when middleware toggles on/off.
@@ -125,28 +137,33 @@ Testing strategy
   - Middleware + backpressure under load: bounded memory, preserved per-resource ordering.
 
 Migration path
+
 - Start single process, in-proc bus, SQLite file (easy install).
 - For isolation: move select plugins to Unix domain sockets with identical MCP interface.
 - For distribution: switch transports to TCP/WebSocket/HTTP; kernel API unchanged.
 
 Operational observability
+
 - Structured logs with trace_id, agent_id, ticket_id, progressToken.
 - Metrics: queue sizes, fanout latency p95/p99, dropped/coalesced counters, plugin error rates.
 - Traces across RPC hops (propagate correlation ids).
 
 Alignment with existing RFC
+
 - 1.2 Architecture: JSON-RPC over stdio and HTTP/SSE; modules list maps to plugins.
 - Notifications: resources/updated, resources/list_changed, progress.
 - Initialize + presence/heartbeat; tools/resources discovery; status FSM and queue resources.
 - Events: append-only audit/replay table.
 
 Defaults and constraints
+
 - Implementation: Node + TypeScript
 - DB: SQLite (Drizzle ORM) for easy install; schema compatible with future Postgres
 - Package: pnpm
 - Security: capability tokens; admin-only tools gated
 
 Deliverables (for M0–M2)
+
 - Kernel package with router, transports (in-proc, stdio, HTTP/SSE), auth binding, notifier, event log.
 - Plugin loader + manifest schema and validator.
 - Tickets plugin v0: minimal CRUD + queues + notifications.
diff --git a/archived/mcp-kernel/MILESTONE_M0.md b/archived/mcp-kernel/MILESTONE_M0.md
index ae8bd89..33c8e5c 100644
--- a/archived/mcp-kernel/MILESTONE_M0.md
+++ b/archived/mcp-kernel/MILESTONE_M0.md
@@ -1,6 +1,7 @@
 # Milestone M0 — Kernel Skeleton (Easy Install, TS + SQLite)
 
 Goals
+
 - Run a minimal, testable kernel in-process.
 - Expose MCP/JSON-RPC surface: initialize, tools/list, resources/list/read/subscribe, ping.
 - Provide pluggable transports (in-proc bus baseline; stdio and HTTP/SSE stubs).
@@ -8,7 +9,9 @@ Goals
 - No external services; SQLite file under /data (gitignored), but DB optional in M0.
 
 Deliverables
-1) Kernel package (TypeScript)
+
+1. Kernel package (TypeScript)
+
 - Router (JSON-RPC/MCP): methods initialize, tools/list, tools/call (no-op), resources/list, resources/read, resources/subscribe, ping.
 - Transports:
   - In-proc bus (default).
@@ -32,25 +35,29 @@ Deliverables
   - Append-only in-memory event collector; shape matches RFC (seq, type, aggregate_id, payload, created_at).
   - Wire up on tool success.
 
-2) Plugin model (stubs)
+2. Plugin model (stubs)
+
 - Manifest loader and validator (JSON Schema).
 - Minimal Fake “Tickets” plugin manifest with 1 resource (mcp://tickets/example.json) and 1 tool (ticket.ping).
 - Dynamic load/unload at startup only (no hot reload yet).
 
-3) Dev ergonomics
+3. Dev ergonomics
+
 - pnpm scripts: dev (run in-proc), test (unit + integration), build.
 - .env.example; /data/.gitignore for future SQLite file.
 - README quickstart; example curl commands or Node client snippet.
 
-4) Tests (kernel-only harness)
+4. Tests (kernel-only harness)
+
 - Unit: router contracts, middleware order, control-plane tool calls, auth binding (token → agent_id).
 - Integration: initialize → tools/resources listing → subscribe to a resource → trigger an update → receive notifications via in-proc and SSE stub.
 - Backpressure/coalescing smoke: bounded queue config present; counters exposed (stubbed).
 - Golden transcript skeleton: record a short init/subscribe/update flow and replay to assert equality.
 
 Acceptance criteria
+
 - pnpm dev starts the kernel; prints available transports and endpoints.
-- tools/list returns kernel.* tools and fake plugin tool.
+- tools/list returns kernel.\* tools and fake plugin tool.
 - resources/list returns kernel and fake plugin resources; resources/read works for example JSON.
 - resources/subscribe on example resource yields notifications/resources/updated when a simulated change occurs.
 - Middleware pipeline present: enabling compression yields smaller payloads on the wire in the stub path while preserving content equality; disabling restores original behavior; servers unchanged.
@@ -59,6 +66,7 @@ Acceptance criteria
 - Tests pass with pnpm test.
 
 Out of scope for M0 (deferred to M1+)
+
 - Real SQLite persistence and migrations (Drizzle).
 - Real tickets CRUD, queues, status FSM.
 - Presence timeouts, autorouter, circuit breakers.
diff --git a/archived/mcp-kernel/README.md b/archived/mcp-kernel/README.md
index 466a60f..f644c8c 100644
--- a/archived/mcp-kernel/README.md
+++ b/archived/mcp-kernel/README.md
@@ -11,6 +11,7 @@ This directory contains the original MCP (Model Context Protocol) based microker
 ## Why It Was Archived
 
 The project has evolved to adopt a **Stream Kernel** architecture (~100 lines) based on pure stream plumbing primitives. The new architecture provides:
+
 - Protocol-agnostic design (not tied to JSON-RPC/MCP)
 - Greater deployment flexibility (single process → distributed)
 - Simpler, more minimal kernel (~100 lines vs ~200 lines)
@@ -21,6 +22,7 @@ The project has evolved to adopt a **Stream Kernel** architecture (~100 lines) b
 This archived implementation includes:
 
 ### Source Code (`src/`)
+
 - **kernel/** - Router, Bus, EventLog (JSON-RPC/MCP focused)
 - **transports/** - HTTP and stdio adapters
 - **middleware/** - Compression, metrics pipeline
@@ -28,18 +30,22 @@ This archived implementation includes:
 - **plugins/** - Plugin manifest system
 
 ### Compiled Output (`dist/`)
+
 - TypeScript compilation artifacts (.js, .d.ts, .map files)
 
 ### Documentation
+
 - **KERNEL_RFC.md** - Original MCP kernel architecture RFC
 - **MILESTONE_M0.md** - Original milestone plan
 
 ### Tests (`tests/`)
+
 - **router.test.ts** - Router test suite
 
 ## New Architecture
 
 The current project direction is documented in the **Stream Kernel RFC**:
+
 - **Main RFC:** [/STREAM_KERNEL_RFC.md](/STREAM_KERNEL_RFC.md)
 - **Modular RFC:** [/docs/rfcs/stream-kernel/00-index.md](/docs/rfcs/stream-kernel/00-index.md)
 
diff --git a/archived/mcp-kernel/src/control/controlPlane.ts b/archived/mcp-kernel/src/control/controlPlane.ts
index 643b227..f522f66 100644
--- a/archived/mcp-kernel/src/control/controlPlane.ts
+++ b/archived/mcp-kernel/src/control/controlPlane.ts
@@ -1,35 +1,41 @@
-import { Router } from "../kernel/router";
-import { Json } from "../types";
+import { Router } from '../kernel/router';
+import { Json } from '../types';
 
 export type MiddlewareState = { name: string; enabled: boolean };
 
 export class ControlPlane {
   private state: MiddlewareState[] = [
-    { name: "metrics", enabled: true },
-    { name: "compression", enabled: false }
+    { name: 'metrics', enabled: true },
+    { name: 'compression', enabled: false },
   ];
-  constructor(private router: Router, private onChange: () => void) {
+  constructor(
+    private router: Router,
+    private onChange: () => void,
+  ) {
     this.register();
   }
   private current(): Json {
-    return { pipeline: this.state.map(s => ({ name: s.name, enabled: s.enabled })) };
+    return { pipeline: this.state.map((s) => ({ name: s.name, enabled: s.enabled })) };
   }
   private setEnabled(name: string, enabled: boolean) {
-    const entry = this.state.find(s => s.name === name);
-    if (!entry) throw new Error("unknown middleware");
+    const entry = this.state.find((s) => s.name === name);
+    if (!entry) throw new Error('unknown middleware');
     entry.enabled = enabled;
     this.onChange();
   }
   private register() {
-    this.router.registerTool({ name: "kernel.middleware.list" }, async () => this.current());
-    this.router.registerTool({ name: "kernel.middleware.enable" }, async (params: any) => {
+    this.router.registerTool({ name: 'kernel.middleware.list' }, async () => this.current());
+    this.router.registerTool({ name: 'kernel.middleware.enable' }, async (params: any) => {
       this.setEnabled(params?.name, true);
       return this.current();
     });
-    this.router.registerTool({ name: "kernel.middleware.disable" }, async (params: any) => {
+    this.router.registerTool({ name: 'kernel.middleware.disable' }, async (params: any) => {
       this.setEnabled(params?.name, false);
       return this.current();
     });
-    this.router.registerResource({ uri: "mcp://kernel/middleware.json", subscribable: true }, async () => this.current());
+    this.router.registerResource(
+      { uri: 'mcp://kernel/middleware.json', subscribable: true },
+      async () => this.current(),
+    );
   }
 }
diff --git a/archived/mcp-kernel/src/control/index.ts b/archived/mcp-kernel/src/control/index.ts
index d4b271c..cd74dc8 100644
--- a/archived/mcp-kernel/src/control/index.ts
+++ b/archived/mcp-kernel/src/control/index.ts
@@ -1 +1 @@
-export * from "./controlPlane";
+export * from './controlPlane';
diff --git a/archived/mcp-kernel/src/index.ts b/archived/mcp-kernel/src/index.ts
index 1d6564f..c647df4 100644
--- a/archived/mcp-kernel/src/index.ts
+++ b/archived/mcp-kernel/src/index.ts
@@ -1,4 +1,4 @@
-export * from "./types";
-export * from "./kernel/bus";
-export * from "./kernel/router";
-export * from "./kernel/eventlog";
+export * from './types';
+export * from './kernel/bus';
+export * from './kernel/router';
+export * from './kernel/eventlog';
diff --git a/archived/mcp-kernel/src/kernel/bus.ts b/archived/mcp-kernel/src/kernel/bus.ts
index c575f53..0bc2634 100644
--- a/archived/mcp-kernel/src/kernel/bus.ts
+++ b/archived/mcp-kernel/src/kernel/bus.ts
@@ -1,4 +1,4 @@
-import { DispatchContext, Middleware, JsonRpcRequest, McpNotification } from "../types";
+import { DispatchContext, Middleware, JsonRpcRequest, McpNotification } from '../types';
 
 export class InProcBus {
   private middlewares: Middleware[] = [];
@@ -7,11 +7,15 @@ export class InProcBus {
     this.middlewares.push(mw);
   }
 
-  async dispatch(session: DispatchContext["session"], msg: JsonRpcRequest | McpNotification, handler: (ctx: DispatchContext) => Promise<void>) {
+  async dispatch(
+    session: DispatchContext['session'],
+    msg: JsonRpcRequest | McpNotification,
+    handler: (ctx: DispatchContext) => Promise<void>,
+  ) {
     const ctx: DispatchContext = { session, request: msg, timestamp: Date.now(), meta: {} };
     let i = -1;
     const run = async (idx: number): Promise<void> => {
-      if (idx <= i) throw new Error("next() called multiple times");
+      if (idx <= i) throw new Error('next() called multiple times');
       i = idx;
       const mw = this.middlewares[idx];
       if (mw) {
diff --git a/archived/mcp-kernel/src/kernel/eventlog.ts b/archived/mcp-kernel/src/kernel/eventlog.ts
index 2e4b9c9..1bffc1c 100644
--- a/archived/mcp-kernel/src/kernel/eventlog.ts
+++ b/archived/mcp-kernel/src/kernel/eventlog.ts
@@ -1,4 +1,10 @@
-type EventRow = { seq: number; type: string; aggregate_id: string; payload: any; created_at: number };
+type EventRow = {
+  seq: number;
+  type: string;
+  aggregate_id: string;
+  payload: any;
+  created_at: number;
+};
 
 export class EventLog {
   private seq = 0;
diff --git a/archived/mcp-kernel/src/kernel/index.ts b/archived/mcp-kernel/src/kernel/index.ts
index c871a01..00531e0 100644
--- a/archived/mcp-kernel/src/kernel/index.ts
+++ b/archived/mcp-kernel/src/kernel/index.ts
@@ -1,3 +1,3 @@
-export * from "./bus";
-export * from "./router";
-export * from "./eventlog";
+export * from './bus';
+export * from './router';
+export * from './eventlog';
diff --git a/archived/mcp-kernel/src/kernel/router.ts b/archived/mcp-kernel/src/kernel/router.ts
index d3e62f1..aee462c 100644
--- a/archived/mcp-kernel/src/kernel/router.ts
+++ b/archived/mcp-kernel/src/kernel/router.ts
@@ -1,4 +1,12 @@
-import { JsonRpcRequest, JsonRpcResponse, McpNotification, ToolDescriptor, ResourceDescriptor, SessionIdentity, Json } from "../types";
+import {
+  JsonRpcRequest,
+  JsonRpcResponse,
+  McpNotification,
+  ToolDescriptor,
+  ResourceDescriptor,
+  SessionIdentity,
+  Json,
+} from '../types';
 
 type ToolHandler = (params: any, session: SessionIdentity) => Promise<Json>;
 type ResourceReader = (uri: string, session: SessionIdentity) => Promise<Json>;
@@ -9,7 +17,7 @@ function toJsonTool(desc: ToolDescriptor): Json {
     description: desc.description ?? null,
     inputSchema: desc.inputSchema ?? null,
     outputSchema: desc.outputSchema ?? null,
-    capability: desc.capability ?? null
+    capability: desc.capability ?? null,
   };
 }
 
@@ -19,7 +27,7 @@ function toJsonResource(desc: ResourceDescriptor): Json {
     description: desc.description ?? null,
     contentSchema: desc.contentSchema ?? null,
     subscribable: desc.subscribable ?? null,
-    capability: desc.capability ?? null
+    capability: desc.capability ?? null,
   };
 }
 
@@ -37,61 +45,81 @@ export class Router {
   }
 
   listTools(): ToolDescriptor[] {
-    return Array.from(this.tools.values()).map(t => t.desc);
+    return Array.from(this.tools.values()).map((t) => t.desc);
   }
 
   listResources(): ResourceDescriptor[] {
-    return Array.from(this.resources.values()).map(r => r.desc);
+    return Array.from(this.resources.values()).map((r) => r.desc);
   }
 
   async handle(session: SessionIdentity, req: JsonRpcRequest): Promise<JsonRpcResponse> {
     const { method, id } = req;
     try {
       switch (method) {
-        case "initialize":
-          return { jsonrpc: "2.0", id: id ?? null, result: { serverInfo: { name: "obol-kernel", version: "0.1.0" } } as Json };
-        case "tools/list": {
+        case 'initialize':
+          return {
+            jsonrpc: '2.0',
+            id: id ?? null,
+            result: { serverInfo: { name: 'obol-kernel', version: '0.1.0' } } as Json,
+          };
+        case 'tools/list': {
           const tools = this.listTools().map(toJsonTool);
-          return { jsonrpc: "2.0", id: id ?? null, result: { tools } as Json };
+          return { jsonrpc: '2.0', id: id ?? null, result: { tools } as Json };
         }
-        case "resources/list": {
+        case 'resources/list': {
           const resources = this.listResources().map(toJsonResource);
-          return { jsonrpc: "2.0", id: id ?? null, result: { resources } as Json };
+          return { jsonrpc: '2.0', id: id ?? null, result: { resources } as Json };
         }
-        case "resources/read": {
+        case 'resources/read': {
           const { uri } = (req.params as any) ?? {};
           const res = this.resources.get(uri);
-          if (!res) throw new Error("Resource not found");
+          if (!res) throw new Error('Resource not found');
           const content = await res.read(uri, session);
-          return { jsonrpc: "2.0", id: id ?? null, result: { contents: content } as Json };
+          return { jsonrpc: '2.0', id: id ?? null, result: { contents: content } as Json };
         }
-        case "resources/subscribe": {
+        case 'resources/subscribe': {
           const { uri } = (req.params as any) ?? {};
-          if (!this.resources.has(uri)) throw new Error("Resource not found");
+          if (!this.resources.has(uri)) throw new Error('Resource not found');
           const set = this.subscribers.get(uri) ?? new Set<string>();
           set.add(session.sessionId);
           this.subscribers.set(uri, set);
-          return { jsonrpc: "2.0", id: id ?? null, result: { ok: true } as Json };
+          return { jsonrpc: '2.0', id: id ?? null, result: { ok: true } as Json };
         }
-        case "tools/call": {
+        case 'tools/call': {
           const { name, arguments: args } = (req.params as any) ?? {};
           const tool = this.tools.get(name);
-          if (!tool) throw new Error("Tool not found");
+          if (!tool) throw new Error('Tool not found');
           const out = await tool.handler(args, session);
-          return { jsonrpc: "2.0", id: id ?? null, result: { content: out } as Json };
+          return { jsonrpc: '2.0', id: id ?? null, result: { content: out } as Json };
         }
-        case "ping":
-          return { jsonrpc: "2.0", id: id ?? null, result: { pong: true, now: Date.now() } as Json };
+        case 'ping':
+          return {
+            jsonrpc: '2.0',
+            id: id ?? null,
+            result: { pong: true, now: Date.now() } as Json,
+          };
         default:
-          return { jsonrpc: "2.0", id: id ?? null, error: { code: -32601, message: "Method not found" } };
+          return {
+            jsonrpc: '2.0',
+            id: id ?? null,
+            error: { code: -32601, message: 'Method not found' },
+          };
       }
     } catch (e: any) {
-      return { jsonrpc: "2.0", id: id ?? null, error: { code: -32000, message: e?.message ?? "Internal error" } };
+      return {
+        jsonrpc: '2.0',
+        id: id ?? null,
+        error: { code: -32000, message: e?.message ?? 'Internal error' },
+      };
     }
   }
 
   makeUpdatedNotification(uri: string): McpNotification {
-    return { jsonrpc: "2.0", method: "notifications/resources/updated", params: { uri, at: Date.now() } };
+    return {
+      jsonrpc: '2.0',
+      method: 'notifications/resources/updated',
+      params: { uri, at: Date.now() },
+    };
   }
 
   getSubscribers(uri: string): string[] {
diff --git a/archived/mcp-kernel/src/middleware/compression.ts b/archived/mcp-kernel/src/middleware/compression.ts
index bf390ab..fa8a5f3 100644
--- a/archived/mcp-kernel/src/middleware/compression.ts
+++ b/archived/mcp-kernel/src/middleware/compression.ts
@@ -1,5 +1,5 @@
-import { Middleware } from "../types";
+import { Middleware } from '../types';
 
 export const compressionMiddleware: Middleware = async (ctx, next) => {
   await next();
-}
+};
diff --git a/archived/mcp-kernel/src/middleware/index.ts b/archived/mcp-kernel/src/middleware/index.ts
index cc2edf4..36d5523 100644
--- a/archived/mcp-kernel/src/middleware/index.ts
+++ b/archived/mcp-kernel/src/middleware/index.ts
@@ -1,6 +1,6 @@
-import { Middleware } from "../types";
-import { metricsMiddleware } from "./metrics";
-import { compressionMiddleware } from "./compression";
+import { Middleware } from '../types';
+import { metricsMiddleware } from './metrics';
+import { compressionMiddleware } from './compression';
 
 export { metricsMiddleware, compressionMiddleware };
 
@@ -9,7 +9,10 @@ export type PipelineConfig = {
   compression: boolean;
 };
 
-export function defaultPipeline(config?: Partial<PipelineConfig>): { middlewares: Middleware[]; config: PipelineConfig } {
+export function defaultPipeline(config?: Partial<PipelineConfig>): {
+  middlewares: Middleware[];
+  config: PipelineConfig;
+} {
   const cfg: PipelineConfig = { metrics: true, compression: false, ...(config ?? {}) };
   const mws: Middleware[] = [];
   if (cfg.metrics) mws.push(metricsMiddleware);
diff --git a/archived/mcp-kernel/src/middleware/metrics.ts b/archived/mcp-kernel/src/middleware/metrics.ts
index 152e50a..d22d2ba 100644
--- a/archived/mcp-kernel/src/middleware/metrics.ts
+++ b/archived/mcp-kernel/src/middleware/metrics.ts
@@ -1,4 +1,4 @@
-import { Middleware } from "../types";
+import { Middleware } from '../types';
 
 export const metricsMiddleware: Middleware = async (ctx, next) => {
   const start = Date.now();
diff --git a/archived/mcp-kernel/src/plugins/index.ts b/archived/mcp-kernel/src/plugins/index.ts
index c1e3977..ab5e0e1 100644
--- a/archived/mcp-kernel/src/plugins/index.ts
+++ b/archived/mcp-kernel/src/plugins/index.ts
@@ -1 +1 @@
-export * from "./manifest";
+export * from './manifest';
diff --git a/archived/mcp-kernel/src/plugins/manifest.ts b/archived/mcp-kernel/src/plugins/manifest.ts
index 1c32da5..f5aa243 100644
--- a/archived/mcp-kernel/src/plugins/manifest.ts
+++ b/archived/mcp-kernel/src/plugins/manifest.ts
@@ -1,10 +1,14 @@
-import { PluginManifest, ToolDescriptor, ResourceDescriptor } from "../types";
-import { Router } from "../kernel/router";
+import { PluginManifest, ToolDescriptor, ResourceDescriptor } from '../types';
+import { Router } from '../kernel/router';
 
-export function registerManifest(router: Router, manifest: PluginManifest, impl: {
-  tools?: Record<string, (params: any, session: any) => Promise<any>>,
-  resources?: Record<string, (uri: string, session: any) => Promise<any>>
-}) {
+export function registerManifest(
+  router: Router,
+  manifest: PluginManifest,
+  impl: {
+    tools?: Record<string, (params: any, session: any) => Promise<any>>;
+    resources?: Record<string, (uri: string, session: any) => Promise<any>>;
+  },
+) {
   for (const t of manifest.tools ?? []) {
     const h = impl.tools?.[t.name];
     if (!h) continue;
diff --git a/archived/mcp-kernel/src/transports/http.ts b/archived/mcp-kernel/src/transports/http.ts
index 13d5ab1..1ca42ab 100644
--- a/archived/mcp-kernel/src/transports/http.ts
+++ b/archived/mcp-kernel/src/transports/http.ts
@@ -1,7 +1,7 @@
-import http from "node:http";
-import { Router } from "../kernel/router";
-import { JsonRpcRequest, SessionIdentity, McpNotification } from "../types";
-import { URL } from "node:url";
+import http from 'node:http';
+import { Router } from '../kernel/router';
+import { JsonRpcRequest, SessionIdentity, McpNotification } from '../types';
+import { URL } from 'node:url';
 
 type Client = { id: string; res: http.ServerResponse };
 
@@ -30,43 +30,43 @@ export class SSEHub {
 export function startHttp(router: Router, port: number, sse: SSEHub) {
   const server = http.createServer(async (req, res) => {
     try {
-      const url = new URL(req.url || "/", `http://${req.headers.host}`);
-      if (req.method === "POST" && url.pathname === "/rpc") {
+      const url = new URL(req.url || '/', `http://${req.headers.host}`);
+      if (req.method === 'POST' && url.pathname === '/rpc') {
         const body = await parseJson(req);
         const session: SessionIdentity = {
-          agentId: (req.headers["x-agent-id"] as string) || "http",
-          token: parseAuth(req.headers["authorization"] as string),
-          transport: "http",
-          sessionId: genSessionId()
+          agentId: (req.headers['x-agent-id'] as string) || 'http',
+          token: parseAuth(req.headers['authorization'] as string),
+          transport: 'http',
+          sessionId: genSessionId(),
         };
         const out = await router.handle(session, body as JsonRpcRequest);
-        res.writeHead(200, { "Content-Type": "application/json" });
+        res.writeHead(200, { 'Content-Type': 'application/json' });
         res.end(JSON.stringify(out));
         return;
       }
-      if (req.method === "GET" && url.pathname === "/events") {
+      if (req.method === 'GET' && url.pathname === '/events') {
         const id = genSessionId();
         res.writeHead(200, {
-          "Content-Type": "text/event-stream",
-          "Cache-Control": "no-cache",
-          Connection: "keep-alive",
-          "X-Accel-Buffering": "no"
+          'Content-Type': 'text/event-stream',
+          'Cache-Control': 'no-cache',
+          Connection: 'keep-alive',
+          'X-Accel-Buffering': 'no',
         });
         sse.add({ id, res });
-        req.on("close", () => sse.remove(id));
+        req.on('close', () => sse.remove(id));
         res.write(`event: open\ndata: ${id}\n\n`);
         return;
       }
-      res.writeHead(404, { "Content-Type": "application/json" });
-      res.end(JSON.stringify({ error: "not found" }));
+      res.writeHead(404, { 'Content-Type': 'application/json' });
+      res.end(JSON.stringify({ error: 'not found' }));
     } catch (e: any) {
-      res.writeHead(500, { "Content-Type": "application/json" });
-      res.end(JSON.stringify({ error: "internal" }));
+      res.writeHead(500, { 'Content-Type': 'application/json' });
+      res.end(JSON.stringify({ error: 'internal' }));
     }
   });
 
   const timer = setInterval(() => sse.heartbeat(), 15000);
-  server.on("close", () => clearInterval(timer));
+  server.on('close', () => clearInterval(timer));
   server.listen(port);
   return server;
 }
@@ -77,13 +77,13 @@ function genSessionId() {
 
 function parseAuth(h?: string) {
   if (!h) return undefined;
-  const [, token] = (h || "").split(" ");
+  const [, token] = (h || '').split(' ');
   return token;
 }
 
 async function parseJson(req: http.IncomingMessage) {
   const chunks: Uint8Array[] = [];
   for await (const chunk of req) chunks.push(chunk as Uint8Array);
-  const s = Buffer.concat(chunks).toString("utf8");
+  const s = Buffer.concat(chunks).toString('utf8');
   return JSON.parse(s);
 }
diff --git a/archived/mcp-kernel/src/transports/index.ts b/archived/mcp-kernel/src/transports/index.ts
index d3b4e16..47690cb 100644
--- a/archived/mcp-kernel/src/transports/index.ts
+++ b/archived/mcp-kernel/src/transports/index.ts
@@ -1,2 +1,2 @@
-export * from "./stdio";
-export * from "./http";
+export * from './stdio';
+export * from './http';
diff --git a/archived/mcp-kernel/src/transports/stdio.ts b/archived/mcp-kernel/src/transports/stdio.ts
index 9384c70..95bd39c 100644
--- a/archived/mcp-kernel/src/transports/stdio.ts
+++ b/archived/mcp-kernel/src/transports/stdio.ts
@@ -1,27 +1,35 @@
-import readline from "node:readline";
-import { Router } from "../kernel/router";
-import { JsonRpcRequest, JsonRpcResponse, SessionIdentity } from "../types";
+import readline from 'node:readline';
+import { Router } from '../kernel/router';
+import { JsonRpcRequest, JsonRpcResponse, SessionIdentity } from '../types';
 
 export function startStdio(router: Router) {
-  const rl = readline.createInterface({ input: process.stdin, output: process.stdout, terminal: false });
+  const rl = readline.createInterface({
+    input: process.stdin,
+    output: process.stdout,
+    terminal: false,
+  });
   const session: SessionIdentity = {
-    agentId: process.env.MCP_AGENT_ID || "stdio",
+    agentId: process.env.MCP_AGENT_ID || 'stdio',
     token: process.env.MCP_TOKEN,
-    transport: "stdio",
-    sessionId: "stdio-" + Date.now()
+    transport: 'stdio',
+    sessionId: 'stdio-' + Date.now(),
   };
-  rl.on("line", async line => {
+  rl.on('line', async (line) => {
     try {
       const req = JSON.parse(line) as JsonRpcRequest;
       const res = await router.handle(session, req);
       write(res);
     } catch (e: any) {
-      const err: JsonRpcResponse = { jsonrpc: "2.0", id: null, error: { code: -32700, message: "Parse error" } };
+      const err: JsonRpcResponse = {
+        jsonrpc: '2.0',
+        id: null,
+        error: { code: -32700, message: 'Parse error' },
+      };
       write(err);
     }
   });
 }
 
 function write(obj: any) {
-  process.stdout.write(JSON.stringify(obj) + "\n");
+  process.stdout.write(JSON.stringify(obj) + '\n');
 }
diff --git a/archived/mcp-kernel/src/types.ts b/archived/mcp-kernel/src/types.ts
index adeedc8..3a3baf8 100644
--- a/archived/mcp-kernel/src/types.ts
+++ b/archived/mcp-kernel/src/types.ts
@@ -3,21 +3,21 @@ export type Json = null | boolean | number | string | Json[] | { [k: string]: Js
 export type JsonRpcId = string | number | null;
 
 export interface JsonRpcRequest {
-  jsonrpc: "2.0";
+  jsonrpc: '2.0';
   id?: JsonRpcId;
   method: string;
   params?: Json;
 }
 
 export interface JsonRpcResponse {
-  jsonrpc: "2.0";
+  jsonrpc: '2.0';
   id: JsonRpcId;
   result?: Json;
   error?: { code: number; message: string; data?: Json };
 }
 
 export interface McpNotification {
-  jsonrpc: "2.0";
+  jsonrpc: '2.0';
   method: string;
   params?: Json;
 }
@@ -25,7 +25,7 @@ export interface McpNotification {
 export interface SessionIdentity {
   agentId: string;
   token?: string;
-  transport: "inproc" | "stdio" | "http";
+  transport: 'inproc' | 'stdio' | 'http';
   sessionId: string;
 }
 
diff --git a/archived/mcp-kernel/tests/router.test.ts b/archived/mcp-kernel/tests/router.test.ts
index d85f645..605d453 100644
--- a/archived/mcp-kernel/tests/router.test.ts
+++ b/archived/mcp-kernel/tests/router.test.ts
@@ -1,26 +1,36 @@
-import { describe, it, expect } from "vitest";
-import { Router } from "../src/kernel/router";
-import { JsonRpcRequest, SessionIdentity } from "../src/types";
+import { describe, it, expect } from 'vitest';
+import { Router } from '../src/kernel/router';
+import { JsonRpcRequest, SessionIdentity } from '../src/types';
 
-const session: SessionIdentity = { agentId: "test", transport: "inproc", token: "t", sessionId: "s1" };
+const session: SessionIdentity = {
+  agentId: 'test',
+  transport: 'inproc',
+  token: 't',
+  sessionId: 's1',
+};
 
-describe("router basics", () => {
-  it("initialize", async () => {
+describe('router basics', () => {
+  it('initialize', async () => {
     const r = new Router();
-    const req: JsonRpcRequest = { jsonrpc: "2.0", id: 1, method: "initialize" };
+    const req: JsonRpcRequest = { jsonrpc: '2.0', id: 1, method: 'initialize' };
     const res = await r.handle(session, req);
     expect(res.result).toBeTruthy();
   });
 
-  it("tools/resources list read", async () => {
+  it('tools/resources list read', async () => {
     const r = new Router();
-    r.registerTool({ name: "x.echo" }, async (p) => p ?? null);
-    r.registerResource({ uri: "mcp://x/a.json" }, async () => ({ a: 1 }));
-    let res = await r.handle(session, { jsonrpc: "2.0", id: 1, method: "tools/list" });
+    r.registerTool({ name: 'x.echo' }, async (p) => p ?? null);
+    r.registerResource({ uri: 'mcp://x/a.json' }, async () => ({ a: 1 }));
+    let res = await r.handle(session, { jsonrpc: '2.0', id: 1, method: 'tools/list' });
     expect(res.result).toBeTruthy();
-    res = await r.handle(session, { jsonrpc: "2.0", id: 2, method: "resources/list" });
+    res = await r.handle(session, { jsonrpc: '2.0', id: 2, method: 'resources/list' });
     expect(res.result).toBeTruthy();
-    res = await r.handle(session, { jsonrpc: "2.0", id: 3, method: "resources/read", params: { uri: "mcp://x/a.json" } });
+    res = await r.handle(session, {
+      jsonrpc: '2.0',
+      id: 3,
+      method: 'resources/read',
+      params: { uri: 'mcp://x/a.json' },
+    });
     expect(res.result).toBeTruthy();
   });
 });
diff --git a/devex.md b/devex.md
index f7e244f..8db26f4 100644
--- a/devex.md
+++ b/devex.md
@@ -1,4 +1,4 @@
-```json
+````json
 
 ```json
 {
@@ -39,9 +39,10 @@
       "deliverables":["patches/DIFF_D1905_lint-acceptance.patch"]}
   ]
 }
-```
+````
 
 Branch Instructions
+
 - IMPORTANT: Run this sprint only on branch `mkolbol-devex-p19-lint-cleanup`.
 - Do not change branches or merge; commit patches and logs as usual. The architect will handle PRs/merges.
 - Use `npm run lint:fix` first; then address remaining warnings with targeted edits.
@@ -49,88 +50,89 @@ Branch Instructions
 - Keep policy: warnings allowed; do not flip CI to fail-on-warn.
 
 {
-  "ampcode": "v1",
-  "waves": [
-    { "id": "DX-11A", "parallel": true,  "tasks": ["LAM-1101", "LAM-1102", "LAM-1103"] },
-    { "id": "DX-11B", "parallel": true,  "tasks": ["DEVEX-111", "DEVEX-112", "DEVEX-113"] },
-    { "id": "DX-12A", "parallel": true,  "tasks": ["DEVEX-1201", "DEVEX-1202", "DEVEX-1203"] }
-  ],
-  "tasks": [
-    {
-      "id": "LAM-1101",
-      "agent": "devex",
-      "title": "Laminar cache keys per node+branch; aggregate PR comment",
-      "allowedFiles": [".github/workflows/tests.yml", "scripts/post-laminar-pr-comment.js"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_LAM-1101_cache-keys-aggregate.patch"]
-    },
-    {
-      "id": "LAM-1102",
-      "agent": "devex",
-      "title": "Flake budget summary in PR (last 5 runs)",
-      "allowedFiles": ["scripts/post-laminar-pr-comment.js", "scripts/append-laminar-history.js"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_LAM-1102_flake-budget.patch"]
-    },
-    {
-      "id": "LAM-1103",
-      "agent": "devex",
-      "title": "Acceptance smoke job: run mkctl http-logs-local-file.yml in CI (best-effort)",
-      "allowedFiles": [".github/workflows/tests.yml", "examples/configs/http-logs-local-file.yml"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_LAM-1103_acceptance-smoke.patch"]
-    },
-    {
-      "id": "DEVEX-111",
-      "agent": "devex",
-      "title": "Acceptance doc: expand FileSink walkthrough end-to-end",
-      "allowedFiles": ["tests/devex/acceptance/local-node-v1.md", "docs/devex/quickstart.md"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_DEVEX-111_filesink-walkthrough.patch"]
-    },
-    {
-      "id": "DEVEX-112",
-      "agent": "devex",
-      "title": "First Five Minutes: polish and add troubleshooting anchors",
-      "allowedFiles": ["docs/devex/first-five-minutes.md", "README.md"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_DEVEX-112_first-five-minutes-polish.patch"]
-    },
-    {
-      "id": "DEVEX-113",
-      "agent": "devex",
-      "title": "mkctl cookbook: add endpoints --json + filters + health error mapping",
-      "allowedFiles": ["docs/devex/mkctl-cookbook.md"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_DEVEX-113_mkctl-cookbook-updates.patch"]
-    },
-    {
-      "id": "DEVEX-1201",
-      "agent": "devex",
-      "title": "Doctor page: common mkctl errors, dry-run, health checks, file perms",
-      "allowedFiles": ["docs/devex/doctor.md"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_DEVEX-1201_doctor.patch"]
-    },
-    {
-      "id": "DEVEX-1202",
-      "agent": "devex",
-      "title": "Authoring a module: constructor(kernel, options), registry, tests",
-      "allowedFiles": ["docs/devex/authoring-a-module.md"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_DEVEX-1202_authoring-module.patch"]
-    },
-    {
-      "id": "DEVEX-1203",
-      "agent": "devex",
-      "title": "Acceptance smoke: non‑gating mkctl run + endpoints assert (aggregate PR comment)",
-      "allowedFiles": [".github/workflows/tests.yml", "scripts/post-laminar-pr-comment.js"],
-      "verify": ["npm run build"],
-      "deliverables": ["patches/DIFF_DEVEX-1203_acceptance-smoke-aggregate.patch"]
-    }
-  ]
+"ampcode": "v1",
+"waves": [
+{ "id": "DX-11A", "parallel": true, "tasks": ["LAM-1101", "LAM-1102", "LAM-1103"] },
+{ "id": "DX-11B", "parallel": true, "tasks": ["DEVEX-111", "DEVEX-112", "DEVEX-113"] },
+{ "id": "DX-12A", "parallel": true, "tasks": ["DEVEX-1201", "DEVEX-1202", "DEVEX-1203"] }
+],
+"tasks": [
+{
+"id": "LAM-1101",
+"agent": "devex",
+"title": "Laminar cache keys per node+branch; aggregate PR comment",
+"allowedFiles": [".github/workflows/tests.yml", "scripts/post-laminar-pr-comment.js"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_LAM-1101_cache-keys-aggregate.patch"]
+},
+{
+"id": "LAM-1102",
+"agent": "devex",
+"title": "Flake budget summary in PR (last 5 runs)",
+"allowedFiles": ["scripts/post-laminar-pr-comment.js", "scripts/append-laminar-history.js"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_LAM-1102_flake-budget.patch"]
+},
+{
+"id": "LAM-1103",
+"agent": "devex",
+"title": "Acceptance smoke job: run mkctl http-logs-local-file.yml in CI (best-effort)",
+"allowedFiles": [".github/workflows/tests.yml", "examples/configs/http-logs-local-file.yml"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_LAM-1103_acceptance-smoke.patch"]
+},
+{
+"id": "DEVEX-111",
+"agent": "devex",
+"title": "Acceptance doc: expand FileSink walkthrough end-to-end",
+"allowedFiles": ["tests/devex/acceptance/local-node-v1.md", "docs/devex/quickstart.md"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_DEVEX-111_filesink-walkthrough.patch"]
+},
+{
+"id": "DEVEX-112",
+"agent": "devex",
+"title": "First Five Minutes: polish and add troubleshooting anchors",
+"allowedFiles": ["docs/devex/first-five-minutes.md", "README.md"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_DEVEX-112_first-five-minutes-polish.patch"]
+},
+{
+"id": "DEVEX-113",
+"agent": "devex",
+"title": "mkctl cookbook: add endpoints --json + filters + health error mapping",
+"allowedFiles": ["docs/devex/mkctl-cookbook.md"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_DEVEX-113_mkctl-cookbook-updates.patch"]
+},
+{
+"id": "DEVEX-1201",
+"agent": "devex",
+"title": "Doctor page: common mkctl errors, dry-run, health checks, file perms",
+"allowedFiles": ["docs/devex/doctor.md"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_DEVEX-1201_doctor.patch"]
+},
+{
+"id": "DEVEX-1202",
+"agent": "devex",
+"title": "Authoring a module: constructor(kernel, options), registry, tests",
+"allowedFiles": ["docs/devex/authoring-a-module.md"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_DEVEX-1202_authoring-module.patch"]
+},
+{
+"id": "DEVEX-1203",
+"agent": "devex",
+"title": "Acceptance smoke: non‑gating mkctl run + endpoints assert (aggregate PR comment)",
+"allowedFiles": [".github/workflows/tests.yml", "scripts/post-laminar-pr-comment.js"],
+"verify": ["npm run build"],
+"deliverables": ["patches/DIFF_DEVEX-1203_acceptance-smoke-aggregate.patch"]
+}
+]
 }
-```
+
+````
 
 # DevEx — RC Sweep Docs (Hello in 10 Minutes + Release Notes)
 
@@ -168,43 +170,60 @@ Branch Instructions
       "deliverables":["patches/DIFF_D10105_docs-release-notes-rc.patch"]}
   ]
 }
-```
+````
 
 ```json
 {
   "ampcode": "v1",
-  "waves": [
-    { "id": "P18B-WS", "parallel": false, "tasks": ["D1801","D1802","D1803"] }
-  ],
+  "waves": [{ "id": "P18B-WS", "parallel": false, "tasks": ["D1801", "D1802", "D1803"] }],
   "branch": "mkolbol-net-p18b-ws-pipe",
   "tasks": [
-    {"id":"D1801","agent":"devex","title":"WebSocketPipe: headless smoke + examples + docs",
-      "allowedFiles":["src/pipes/adapters/WebSocketPipe.ts","tests/integration/wsPipe.spec.ts","examples/network/ws-smoke/**","docs/devex/network-quickstart.md"],
-      "verify":["npm run build","npm run test:ci"],
-      "deliverables":["patches/DIFF_D1801_ws-pipe.patch"]},
+    {
+      "id": "D1801",
+      "agent": "devex",
+      "title": "WebSocketPipe: headless smoke + examples + docs",
+      "allowedFiles": [
+        "src/pipes/adapters/WebSocketPipe.ts",
+        "tests/integration/wsPipe.spec.ts",
+        "examples/network/ws-smoke/**",
+        "docs/devex/network-quickstart.md"
+      ],
+      "verify": ["npm run build", "npm run test:ci"],
+      "deliverables": ["patches/DIFF_D1801_ws-pipe.patch"]
+    },
 
-    {"id":"D1802","agent":"devex","title":"mkctl notes: future --connect ws://... (doc placeholders only)",
-      "allowedFiles":["docs/devex/mkctl-cookbook.md"],
-      "verify":["npm run build"],
-      "deliverables":["patches/DIFF_D1802_mkctl-ws-docs.patch"]},
+    {
+      "id": "D1802",
+      "agent": "devex",
+      "title": "mkctl notes: future --connect ws://... (doc placeholders only)",
+      "allowedFiles": ["docs/devex/mkctl-cookbook.md"],
+      "verify": ["npm run build"],
+      "deliverables": ["patches/DIFF_D1802_mkctl-ws-docs.patch"]
+    },
 
-    {"id":"D1803","agent":"devex","title":"Remote Host Setup (2nd machine) — quickstart",
-      "allowedFiles":["docs/devex/remote-host-setup.md"],
-      "verify":["npm run build"],
-      "deliverables":["patches/DIFF_D1803_remote-host-docs.patch"]}
+    {
+      "id": "D1803",
+      "agent": "devex",
+      "title": "Remote Host Setup (2nd machine) — quickstart",
+      "allowedFiles": ["docs/devex/remote-host-setup.md"],
+      "verify": ["npm run build"],
+      "deliverables": ["patches/DIFF_D1803_remote-host-docs.patch"]
+    }
   ]
 }
 ```
 
 Branch Instructions
+
 - IMPORTANT: This sprint runs ONLY on branch `mkolbol-net-p18b-ws-pipe`.
 - Do not change branches or merge; commit patches and logs as usual. The architect will handle PRs/merges.
 - Use ephemeral WS ports 30012–30019 in tests to avoid collisions.
-Autonomy & Direction
+  Autonomy & Direction
 - Keep everything copy‑paste runnable; prefer tarball/git‑tag paths (no npm registry).
 - Use the template; keep a concise log in `Vex/devex.log`.
 
 Verification Commands
+
 ```bash
 export MK_LOCAL_NODE=1
 npm run build
@@ -212,6 +231,7 @@ npm run test:ci
 ```
 
 Success Criteria
+
 - First‑Five‑Minutes shows a single “Hello in 10 Minutes” path end‑to‑end.
 - CI plan doc provides a working Actions snippet with Laminar hooks.
 - Release Notes (RC) published; style/links consistent; help snapshots pass.
@@ -222,34 +242,71 @@ Success Criteria
 {
   "ampcode": "v1",
   "waves": [
-    { "id": "P17-DOCS-A_MK_ANYWHERE", "parallel": true,  "tasks": ["D11001","D11002","D11004"] },
-    { "id": "P17-DOCS-B_ROUTER_P2",  "parallel": true,  "depends_on": ["P17-DOCS-A_MK_ANYWHERE"], "tasks": ["D11003","D11005"] }
+    { "id": "P17-DOCS-A_MK_ANYWHERE", "parallel": true, "tasks": ["D11001", "D11002", "D11004"] },
+    {
+      "id": "P17-DOCS-B_ROUTER_P2",
+      "parallel": true,
+      "depends_on": ["P17-DOCS-A_MK_ANYWHERE"],
+      "tasks": ["D11003", "D11005"]
+    }
   ],
   "tasks": [
-    {"id":"D11001","agent":"devex","title":"Quickstart/README: mk self install + mk anywhere (no npm registry)",
-      "allowedFiles":["README.md","docs/devex/first-five-minutes.md","docs/devex/installation.md"],
-      "verify":["npm run build"],
-      "deliverables":["patches/DIFF_D11001_docs-mk-anywhere-quickstart.patch"]},
+    {
+      "id": "D11001",
+      "agent": "devex",
+      "title": "Quickstart/README: mk self install + mk anywhere (no npm registry)",
+      "allowedFiles": [
+        "README.md",
+        "docs/devex/first-five-minutes.md",
+        "docs/devex/installation.md"
+      ],
+      "verify": ["npm run build"],
+      "deliverables": ["patches/DIFF_D11001_docs-mk-anywhere-quickstart.patch"]
+    },
 
-    {"id":"D11002","agent":"devex","title":"Tutorial: mk bootstrap out-of-tree app (Hello Calculator)",
-      "allowedFiles":["docs/devex/using-mkolbol-in-your-repo.md","docs/devex/hello-calculator.md","examples/mk/init-templates/**"],
-      "verify":["npm run build"],
-      "deliverables":["patches/DIFF_D11002_docs-bootstrap-tutorial.patch"]},
+    {
+      "id": "D11002",
+      "agent": "devex",
+      "title": "Tutorial: mk bootstrap out-of-tree app (Hello Calculator)",
+      "allowedFiles": [
+        "docs/devex/using-mkolbol-in-your-repo.md",
+        "docs/devex/hello-calculator.md",
+        "examples/mk/init-templates/**"
+      ],
+      "verify": ["npm run build"],
+      "deliverables": ["patches/DIFF_D11002_docs-bootstrap-tutorial.patch"]
+    },
 
-    {"id":"D11003","agent":"devex","title":"Doctor guide: toolchain/shim checks with exact remediation snippets",
-      "allowedFiles":["docs/devex/doctor.md"],
-      "verify":["npm run build"],
-      "deliverables":["patches/DIFF_D11003_docs-doctor-toolchain.patch"]},
+    {
+      "id": "D11003",
+      "agent": "devex",
+      "title": "Doctor guide: toolchain/shim checks with exact remediation snippets",
+      "allowedFiles": ["docs/devex/doctor.md"],
+      "verify": ["npm run build"],
+      "deliverables": ["patches/DIFF_D11003_docs-doctor-toolchain.patch"]
+    },
 
-    {"id":"D11004","agent":"devex","title":"CLI reference + help snapshots for self install/fetch/bootstrap",
-      "allowedFiles":["tests/cli/mkdxHelp.spec.ts","docs/devex/mk-dx-style.md","docs/devex/cli-reference.md"],
-      "verify":["npm run build","npm run test:ci"],
-      "deliverables":["patches/DIFF_D11004_docs-help-snapshots-mk-anywhere.patch"]},
+    {
+      "id": "D11004",
+      "agent": "devex",
+      "title": "CLI reference + help snapshots for self install/fetch/bootstrap",
+      "allowedFiles": [
+        "tests/cli/mkdxHelp.spec.ts",
+        "docs/devex/mk-dx-style.md",
+        "docs/devex/cli-reference.md"
+      ],
+      "verify": ["npm run build", "npm run test:ci"],
+      "deliverables": ["patches/DIFF_D11004_docs-help-snapshots-mk-anywhere.patch"]
+    },
 
-    {"id":"D11005","agent":"devex","title":"mkctl endpoints liveness: cookbook updates + watch examples",
-      "allowedFiles":["docs/devex/mkctl-cookbook.md"],
-      "verify":["npm run build"],
-      "deliverables":["patches/DIFF_D11005_docs-mkctl-liveness.patch"]}
+    {
+      "id": "D11005",
+      "agent": "devex",
+      "title": "mkctl endpoints liveness: cookbook updates + watch examples",
+      "allowedFiles": ["docs/devex/mkctl-cookbook.md"],
+      "verify": ["npm run build"],
+      "deliverables": ["patches/DIFF_D11005_docs-mkctl-liveness.patch"]
+    }
   ]
 }
 ```
@@ -257,8 +314,10 @@ Success Criteria
 # DevEx — P17 Docs: mk Anywhere + Router Liveness
 
 Intent
+
 - Teach users how to install mk as a global shim, bootstrap out‑of‑tree apps, and observe endpoint liveness via mkctl.
 
 Notes
+
 - Keep distribution paths to tarball/git tag only; no npm registry references.
 - Include explicit PATH instructions for POSIX and Windows; no auto‑mutation.
diff --git a/dist/src/pipes/adapters/WebSocketPipe.js b/dist/src/pipes/adapters/WebSocketPipe.js
index 56fc7a2..c16f1d9 100644
--- a/dist/src/pipes/adapters/WebSocketPipe.js
+++ b/dist/src/pipes/adapters/WebSocketPipe.js
@@ -130,7 +130,7 @@ export class WebSocketPipeServer {
             });
             this.server.on('listening', () => {
                 const address = this.server.address();
-                const actualPort = (address && typeof address === 'object') ? address.port : port;
+                const actualPort = address && typeof address === 'object' ? address.port : port;
                 debug.emit('ws-pipe', 'server.listen', { port: actualPort }, 'info');
                 resolve(actualPort);
             });
diff --git a/dist/src/pipes/adapters/WebSocketPipe.js.map b/dist/src/pipes/adapters/WebSocketPipe.js.map
index 85c50f1..1fc7ec1 100644
--- a/dist/src/pipes/adapters/WebSocketPipe.js.map
+++ b/dist/src/pipes/adapters/WebSocketPipe.js.map
@@ -1 +1 @@
-{"version":3,"file":"WebSocketPipe.js","sourceRoot":"","sources":["../../../../src/pipes/adapters/WebSocketPipe.ts"],"names":[],"mappings":"AAAA,OAAO,EAAE,MAAM,EAAE,MAAM,QAAQ,CAAC;AAChC,OAAO,SAAS,EAAE,EAAE,eAAe,EAAE,MAAM,IAAI,CAAC;AAChD,OAAO,EAAE,UAAU,EAAE,MAAM,oBAAoB,CAAC;AAEhD,OAAO,EAAE,KAAK,EAAE,MAAM,oBAAoB,CAAC;AAU3C,MAAM,OAAO,mBAAoB,SAAQ,MAAM;IAKzB;IAJZ,EAAE,CAAa;IACf,MAAM,GAAW,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IACjC,UAAU,GAAG,CAAC,CAAC;IAEvB,YAAoB,OAA6B;QAC/C,KAAK,CAAC,EAAE,UAAU,EAAE,OAAO,CAAC,UAAU,IAAI,KAAK,EAAE,CAAC,CAAC;QADjC,YAAO,GAAP,OAAO,CAAsB;IAEjD,CAAC;IAED,OAAO;QACL,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACrC,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,WAAW,CAAC;YAC9C,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;YAC/B,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,GAAG,CAAC;YACtC,MAAM,GAAG,GAAG,QAAQ,IAAI,IAAI,IAAI,GAAG,IAAI,EAAE,CAAC;YAE1C,IAAI,CAAC,EAAE,GAAG,IAAI,SAAS,CAAC,GAAG,CAAC,CAAC;YAE7B,IAAI,IAAI,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC;gBACzB,MAAM,OAAO,GAAG,UAAU,CAAC,GAAG,EAAE;oBAC9B,IAAI,CAAC,EAAE,EAAE,SAAS,EAAE,CAAC;oBACrB,MAAM,CAAC,IAAI,KAAK,CAAC,oBAAoB,CAAC,CAAC,CAAC;gBAC1C,CAAC,EAAE,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;gBAEzB,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,GAAG,EAAE;oBACtB,YAAY,CAAC,OAAO,CAAC,CAAC;gBACxB,CAAC,CAAC,CAAC;YACL,CAAC;YAED,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,GAAG,EAAE;gBACtB,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,gBAAgB,EAAE,EAAE,GAAG,EAAE,EAAE,MAAM,CAAC,CAAC;gBACzD,OAAO,EAAE,CAAC;YACZ,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,SAAS,EAAE,CAAC,IAAY,EAAE,EAAE;gBACrC,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,CAAC;YAChC,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,GAAG,EAAE,EAAE;gBAC1B,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,KAAK,EAAE,GAAG,CAAC,OAAO,EAAE,EAAE,OAAO,CAAC,CAAC;gBACvE,MAAM,CAAC,GAAG,CAAC,CAAC;YACd,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,GAAG,EAAE;gBACvB,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,EAAE,MAAM,CAAC,CAAC;gBAClD,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAClB,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC;IAED,MAAM,CAAC,KAAU,EAAE,QAAwB,EAAE,QAAwC;QACnF,IAAI,CAAC,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YACtD,QAAQ,CAAC,IAAI,KAAK,CAAC,yBAAyB,CAAC,CAAC,CAAC;YAC/C,OAAO;QACT,CAAC;QAED,IAAI,CAAC;YACH,MAAM,KAAK,GAAG,UAAU,CAAC,eAAe,CAAC,KAAK,EAAE,IAAI,CAAC,UAAU,EAAE,CAAC,CAAC;YACnE,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;YACzC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC;QAClC,CAAC;QAAC,OAAO,GAAG,EAAE,CAAC;YACb,QAAQ,CAAC,GAAY,CAAC,CAAC;QACzB,CAAC;IACH,CAAC;IAED,KAAK,CAAC,IAAY;QAChB,oCAAoC;IACtC,CAAC;IAEO,kBAAkB,CAAC,IAAY;QACrC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC,CAAC;QAEjD,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YAC9B,MAAM,MAAM,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAE9C,IAAI,CAAC,MAAM,EAAE,CAAC;gBACZ,MAAM;YACR,CAAC;YAED,MAAM,EAAE,KAAK,EAAE,aAAa,EAAE,GAAG,MAAM,CAAC;YACxC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;YAE/C,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;YAC3B,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBAC1C,IAAI,CAAC,QAAQ,EAAE,CAAC;YAClB,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,OAAO,EAAE,CAAC;gBAC3C,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAClB,CAAC;QACH,CAAC;IACH,CAAC;IAEO,QAAQ;QACd,IAAI,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YACrD,MAAM,IAAI,GAAG,UAAU,CAAC,eAAe,EAAE,CAAC;YAC1C,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;YACxC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QACxB,CAAC;IACH,CAAC;IAED,KAAK;QACH,IAAI,IAAI,CAAC,EAAE,EAAE,CAAC;YACZ,MAAM,UAAU,GAAG,UAAU,CAAC,gBAAgB,EAAE,CAAC;YACjD,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAC9C,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,GAAG,EAAE;gBACzB,IAAI,CAAC,EAAE,EAAE,KAAK,EAAE,CAAC;YACnB,CAAC,CAAC,CAAC;QACL,CAAC;IACH,CAAC;IAED,MAAM,CAAC,QAAwC;QAC7C,IAAI,CAAC,KAAK,EAAE,CAAC;QACb,QAAQ,EAAE,CAAC;IACb,CAAC;CACF;AAED,MAAM,OAAO,mBAAmB;IAIV;IAHZ,MAAM,CAAmB;IACzB,WAAW,GAAmB,IAAI,GAAG,EAAE,CAAC;IAEhD,YAAoB,OAA6B;QAA7B,YAAO,GAAP,OAAO,CAAsB;IAAG,CAAC;IAErD,MAAM,CAAC,QAAkC;QACvC,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACrC,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;YAC/B,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,GAAG,CAAC;YAEtC,IAAI,CAAC,MAAM,GAAG,IAAI,eAAe,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC;YAElD,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,YAAY,EAAE,CAAC,EAAE,EAAE,EAAE;gBAClC,MAAM,aAAa,GAAI,EAAU,CAAC,OAAO,EAAE,aAAa,IAAI,SAAS,CAAC;gBACtE,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,mBAAmB,EAAE,EAAE,aAAa,EAAE,EAAE,MAAM,CAAC,CAAC;gBACtE,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;gBAEzB,MAAM,IAAI,GAAG,IAAI,mBAAmB,CAAC,EAAE,CAAC,CAAC;gBACzC,QAAQ,CAAC,IAAI,CAAC,CAAC;gBAEf,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,GAAG,EAAE;oBAClB,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;gBAC9B,CAAC,CAAC,CAAC;YACL,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,GAAG,EAAE,EAAE;gBAC9B,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,KAAK,EAAE,GAAG,CAAC,OAAO,EAAE,EAAE,OAAO,CAAC,CAAC;gBACvE,MAAM,CAAC,GAAG,CAAC,CAAC;YACd,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,WAAW,EAAE,GAAG,EAAE;gBAC/B,MAAM,OAAO,GAAG,IAAI,CAAC,MAAO,CAAC,OAAO,EAAE,CAAC;gBACvC,MAAM,UAAU,GAAG,CAAC,OAAO,IAAI,OAAO,OAAO,KAAK,QAAQ,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC;gBAClF,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,eAAe,EAAE,EAAE,IAAI,EAAE,UAAU,EAAE,EAAE,MAAM,CAAC,CAAC;gBACrE,OAAO,CAAC,UAAU,CAAC,CAAC;YACtB,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC;IAED,KAAK;QACH,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;YAC7B,KAAK,MAAM,EAAE,IAAI,IAAI,CAAC,WAAW,EAAE,CAAC;gBAClC,EAAE,CAAC,KAAK,EAAE,CAAC;YACb,CAAC;YACD,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,CAAC;YAEzB,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC;gBAChB,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,EAAE;oBACrB,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,EAAE,MAAM,CAAC,CAAC;oBAClD,OAAO,EAAE,CAAC;gBACZ,CAAC,CAAC,CAAC;YACL,CAAC;iBAAM,CAAC;gBACN,OAAO,EAAE,CAAC;YACZ,CAAC;QACH,CAAC,CAAC,CAAC;IACL,CAAC;CACF;AAED,MAAM,mBAAoB,SAAQ,MAAM;IAIlB;IAHZ,MAAM,GAAW,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IACjC,UAAU,GAAG,CAAC,CAAC;IAEvB,YAAoB,EAAa;QAC/B,KAAK,CAAC,EAAE,UAAU,EAAE,KAAK,EAAE,CAAC,CAAC;QADX,OAAE,GAAF,EAAE,CAAW;QAG/B,EAAE,CAAC,EAAE,CAAC,SAAS,EAAE,CAAC,IAAY,EAAE,EAAE;YAChC,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,CAAC;QAChC,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,GAAG,EAAE;YAClB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAClB,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,GAAG,EAAE,EAAE;YACrB,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC;QAC1B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,MAAM,CAAC,KAAU,EAAE,QAAwB,EAAE,QAAwC;QACnF,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YAC1C,QAAQ,CAAC,IAAI,KAAK,CAAC,oBAAoB,CAAC,CAAC,CAAC;YAC1C,OAAO;QACT,CAAC;QAED,IAAI,CAAC;YACH,MAAM,KAAK,GAAG,UAAU,CAAC,eAAe,CAAC,KAAK,EAAE,IAAI,CAAC,UAAU,EAAE,CAAC,CAAC;YACnE,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;YACzC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC;QAClC,CAAC;QAAC,OAAO,GAAG,EAAE,CAAC;YACb,QAAQ,CAAC,GAAY,CAAC,CAAC;QACzB,CAAC;IACH,CAAC;IAED,KAAK,CAAC,IAAY;QAChB,oCAAoC;IACtC,CAAC;IAEO,kBAAkB,CAAC,IAAY;QACrC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC,CAAC;QAEjD,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YAC9B,MAAM,MAAM,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAE9C,IAAI,CAAC,MAAM,EAAE,CAAC;gBACZ,MAAM;YACR,CAAC;YAED,MAAM,EAAE,KAAK,EAAE,aAAa,EAAE,GAAG,MAAM,CAAC;YACxC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;YAE/C,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;YAC3B,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBAC1C,IAAI,CAAC,QAAQ,EAAE,CAAC;YAClB,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,OAAO,EAAE,CAAC;gBAC3C,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAClB,CAAC;QACH,CAAC;IACH,CAAC;IAEO,QAAQ;QACd,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YAC1C,MAAM,IAAI,GAAG,UAAU,CAAC,eAAe,EAAE,CAAC;YAC1C,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;YACxC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QACxB,CAAC;IACH,CAAC;CACF"}
\ No newline at end of file
+{"version":3,"file":"WebSocketPipe.js","sourceRoot":"","sources":["../../../../src/pipes/adapters/WebSocketPipe.ts"],"names":[],"mappings":"AAAA,OAAO,EAAE,MAAM,EAAE,MAAM,QAAQ,CAAC;AAChC,OAAO,SAAS,EAAE,EAAE,eAAe,EAAE,MAAM,IAAI,CAAC;AAChD,OAAO,EAAE,UAAU,EAAE,MAAM,oBAAoB,CAAC;AAEhD,OAAO,EAAE,KAAK,EAAE,MAAM,oBAAoB,CAAC;AAU3C,MAAM,OAAO,mBAAoB,SAAQ,MAAM;IAKzB;IAJZ,EAAE,CAAa;IACf,MAAM,GAAW,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IACjC,UAAU,GAAG,CAAC,CAAC;IAEvB,YAAoB,OAA6B;QAC/C,KAAK,CAAC,EAAE,UAAU,EAAE,OAAO,CAAC,UAAU,IAAI,KAAK,EAAE,CAAC,CAAC;QADjC,YAAO,GAAP,OAAO,CAAsB;IAEjD,CAAC;IAED,OAAO;QACL,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACrC,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,WAAW,CAAC;YAC9C,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;YAC/B,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,GAAG,CAAC;YACtC,MAAM,GAAG,GAAG,QAAQ,IAAI,IAAI,IAAI,GAAG,IAAI,EAAE,CAAC;YAE1C,IAAI,CAAC,EAAE,GAAG,IAAI,SAAS,CAAC,GAAG,CAAC,CAAC;YAE7B,IAAI,IAAI,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC;gBACzB,MAAM,OAAO,GAAG,UAAU,CAAC,GAAG,EAAE;oBAC9B,IAAI,CAAC,EAAE,EAAE,SAAS,EAAE,CAAC;oBACrB,MAAM,CAAC,IAAI,KAAK,CAAC,oBAAoB,CAAC,CAAC,CAAC;gBAC1C,CAAC,EAAE,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;gBAEzB,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,GAAG,EAAE;oBACtB,YAAY,CAAC,OAAO,CAAC,CAAC;gBACxB,CAAC,CAAC,CAAC;YACL,CAAC;YAED,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,GAAG,EAAE;gBACtB,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,gBAAgB,EAAE,EAAE,GAAG,EAAE,EAAE,MAAM,CAAC,CAAC;gBACzD,OAAO,EAAE,CAAC;YACZ,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,SAAS,EAAE,CAAC,IAAY,EAAE,EAAE;gBACrC,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,CAAC;YAChC,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,GAAG,EAAE,EAAE;gBAC1B,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,KAAK,EAAE,GAAG,CAAC,OAAO,EAAE,EAAE,OAAO,CAAC,CAAC;gBACvE,MAAM,CAAC,GAAG,CAAC,CAAC;YACd,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,GAAG,EAAE;gBACvB,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,EAAE,MAAM,CAAC,CAAC;gBAClD,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAClB,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC;IAED,MAAM,CAAC,KAAU,EAAE,QAAwB,EAAE,QAAwC;QACnF,IAAI,CAAC,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YACtD,QAAQ,CAAC,IAAI,KAAK,CAAC,yBAAyB,CAAC,CAAC,CAAC;YAC/C,OAAO;QACT,CAAC;QAED,IAAI,CAAC;YACH,MAAM,KAAK,GAAG,UAAU,CAAC,eAAe,CAAC,KAAK,EAAE,IAAI,CAAC,UAAU,EAAE,CAAC,CAAC;YACnE,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;YACzC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC;QAClC,CAAC;QAAC,OAAO,GAAG,EAAE,CAAC;YACb,QAAQ,CAAC,GAAY,CAAC,CAAC;QACzB,CAAC;IACH,CAAC;IAED,KAAK,CAAC,IAAY;QAChB,oCAAoC;IACtC,CAAC;IAEO,kBAAkB,CAAC,IAAY;QACrC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC,CAAC;QAEjD,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YAC9B,MAAM,MAAM,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAE9C,IAAI,CAAC,MAAM,EAAE,CAAC;gBACZ,MAAM;YACR,CAAC;YAED,MAAM,EAAE,KAAK,EAAE,aAAa,EAAE,GAAG,MAAM,CAAC;YACxC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;YAE/C,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;YAC3B,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBAC1C,IAAI,CAAC,QAAQ,EAAE,CAAC;YAClB,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,OAAO,EAAE,CAAC;gBAC3C,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAClB,CAAC;QACH,CAAC;IACH,CAAC;IAEO,QAAQ;QACd,IAAI,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YACrD,MAAM,IAAI,GAAG,UAAU,CAAC,eAAe,EAAE,CAAC;YAC1C,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;YACxC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QACxB,CAAC;IACH,CAAC;IAED,KAAK;QACH,IAAI,IAAI,CAAC,EAAE,EAAE,CAAC;YACZ,MAAM,UAAU,GAAG,UAAU,CAAC,gBAAgB,EAAE,CAAC;YACjD,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAC9C,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,GAAG,EAAE;gBACzB,IAAI,CAAC,EAAE,EAAE,KAAK,EAAE,CAAC;YACnB,CAAC,CAAC,CAAC;QACL,CAAC;IACH,CAAC;IAED,MAAM,CAAC,QAAwC;QAC7C,IAAI,CAAC,KAAK,EAAE,CAAC;QACb,QAAQ,EAAE,CAAC;IACb,CAAC;CACF;AAED,MAAM,OAAO,mBAAmB;IAIV;IAHZ,MAAM,CAAmB;IACzB,WAAW,GAAmB,IAAI,GAAG,EAAE,CAAC;IAEhD,YAAoB,OAA6B;QAA7B,YAAO,GAAP,OAAO,CAAsB;IAAG,CAAC;IAErD,MAAM,CAAC,QAAkC;QACvC,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACrC,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;YAC/B,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,GAAG,CAAC;YAEtC,IAAI,CAAC,MAAM,GAAG,IAAI,eAAe,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC;YAElD,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,YAAY,EAAE,CAAC,EAAE,EAAE,EAAE;gBAClC,MAAM,aAAa,GAAI,EAAU,CAAC,OAAO,EAAE,aAAa,IAAI,SAAS,CAAC;gBACtE,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,mBAAmB,EAAE,EAAE,aAAa,EAAE,EAAE,MAAM,CAAC,CAAC;gBACtE,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;gBAEzB,MAAM,IAAI,GAAG,IAAI,mBAAmB,CAAC,EAAE,CAAC,CAAC;gBACzC,QAAQ,CAAC,IAAI,CAAC,CAAC;gBAEf,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,GAAG,EAAE;oBAClB,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;gBAC9B,CAAC,CAAC,CAAC;YACL,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,GAAG,EAAE,EAAE;gBAC9B,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,KAAK,EAAE,GAAG,CAAC,OAAO,EAAE,EAAE,OAAO,CAAC,CAAC;gBACvE,MAAM,CAAC,GAAG,CAAC,CAAC;YACd,CAAC,CAAC,CAAC;YAEH,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,WAAW,EAAE,GAAG,EAAE;gBAC/B,MAAM,OAAO,GAAG,IAAI,CAAC,MAAO,CAAC,OAAO,EAAE,CAAC;gBACvC,MAAM,UAAU,GAAG,OAAO,IAAI,OAAO,OAAO,KAAK,QAAQ,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC;gBAChF,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,eAAe,EAAE,EAAE,IAAI,EAAE,UAAU,EAAE,EAAE,MAAM,CAAC,CAAC;gBACrE,OAAO,CAAC,UAAU,CAAC,CAAC;YACtB,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;IACL,CAAC;IAED,KAAK;QACH,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;YAC7B,KAAK,MAAM,EAAE,IAAI,IAAI,CAAC,WAAW,EAAE,CAAC;gBAClC,EAAE,CAAC,KAAK,EAAE,CAAC;YACb,CAAC;YACD,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,CAAC;YAEzB,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC;gBAChB,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,EAAE;oBACrB,KAAK,CAAC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,EAAE,EAAE,MAAM,CAAC,CAAC;oBAClD,OAAO,EAAE,CAAC;gBACZ,CAAC,CAAC,CAAC;YACL,CAAC;iBAAM,CAAC;gBACN,OAAO,EAAE,CAAC;YACZ,CAAC;QACH,CAAC,CAAC,CAAC;IACL,CAAC;CACF;AAED,MAAM,mBAAoB,SAAQ,MAAM;IAIlB;IAHZ,MAAM,GAAW,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IACjC,UAAU,GAAG,CAAC,CAAC;IAEvB,YAAoB,EAAa;QAC/B,KAAK,CAAC,EAAE,UAAU,EAAE,KAAK,EAAE,CAAC,CAAC;QADX,OAAE,GAAF,EAAE,CAAW;QAG/B,EAAE,CAAC,EAAE,CAAC,SAAS,EAAE,CAAC,IAAY,EAAE,EAAE;YAChC,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,CAAC;QAChC,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,GAAG,EAAE;YAClB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAClB,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,EAAE,CAAC,OAAO,EAAE,CAAC,GAAG,EAAE,EAAE;YACrB,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC;QAC1B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,MAAM,CAAC,KAAU,EAAE,QAAwB,EAAE,QAAwC;QACnF,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YAC1C,QAAQ,CAAC,IAAI,KAAK,CAAC,oBAAoB,CAAC,CAAC,CAAC;YAC1C,OAAO;QACT,CAAC;QAED,IAAI,CAAC;YACH,MAAM,KAAK,GAAG,UAAU,CAAC,eAAe,CAAC,KAAK,EAAE,IAAI,CAAC,UAAU,EAAE,CAAC,CAAC;YACnE,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;YACzC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC;QAClC,CAAC;QAAC,OAAO,GAAG,EAAE,CAAC;YACb,QAAQ,CAAC,GAAY,CAAC,CAAC;QACzB,CAAC;IACH,CAAC;IAED,KAAK,CAAC,IAAY;QAChB,oCAAoC;IACtC,CAAC;IAEO,kBAAkB,CAAC,IAAY;QACrC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC,CAAC;QAEjD,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YAC9B,MAAM,MAAM,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAE9C,IAAI,CAAC,MAAM,EAAE,CAAC;gBACZ,MAAM;YACR,CAAC;YAED,MAAM,EAAE,KAAK,EAAE,aAAa,EAAE,GAAG,MAAM,CAAC;YACxC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;YAE/C,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;YAC3B,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,MAAM,EAAE,CAAC;gBAC1C,IAAI,CAAC,QAAQ,EAAE,CAAC;YAClB,CAAC;iBAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,KAAK,OAAO,EAAE,CAAC;gBAC3C,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAClB,CAAC;QACH,CAAC;IACH,CAAC;IAEO,QAAQ;QACd,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC;YAC1C,MAAM,IAAI,GAAG,UAAU,CAAC,eAAe,EAAE,CAAC;YAC1C,MAAM,OAAO,GAAG,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;YACxC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QACxB,CAAC;IACH,CAAC;CACF"}
\ No newline at end of file
diff --git a/docs/devex/authoring-a-module.md b/docs/devex/authoring-a-module.md
index 00249b9..6c7c411 100644
--- a/docs/devex/authoring-a-module.md
+++ b/docs/devex/authoring-a-module.md
@@ -23,7 +23,10 @@ export class MyModule {
   private options: MyModuleOptions;
 
   // Constructor: (kernel, options)
-  constructor(private kernel: Kernel, options: MyModuleOptions = {}) {
+  constructor(
+    private kernel: Kernel,
+    options: MyModuleOptions = {},
+  ) {
     this.options = options;
   }
 
@@ -77,12 +80,15 @@ export class MyModule {
   private options: Required<MyModuleOptions>;
 
   // 1. CONSTRUCTOR: Framework calls this
-  constructor(private kernel: Kernel, options: MyModuleOptions = {}) {
+  constructor(
+    private kernel: Kernel,
+    options: MyModuleOptions = {},
+  ) {
     // Set defaults for all options
     this.options = {
       enabled: options.enabled ?? true,
       timeout: options.timeout ?? 5000,
-      ...options  // Merge overrides
+      ...options, // Merge overrides
     };
 
     // Validate options
@@ -95,8 +101,8 @@ export class MyModule {
   }
 
   // 2. PIPES CONNECTED: Framework sets these properties
-  inputPipe?: NodeJS.ReadableStream;   // Set by framework
-  outputPipe?: NodeJS.WritableStream;  // Set by framework
+  inputPipe?: NodeJS.ReadableStream; // Set by framework
+  outputPipe?: NodeJS.WritableStream; // Set by framework
 
   // 3. START CALLED: Framework calls start() after pipes are connected
   start(): void {
@@ -137,39 +143,44 @@ export class BadModule {
 ### How the Framework Creates Modules
 
 1. **Config defines module**:
+
 ```yaml
 nodes:
   - id: my-processor
-    module: MyModule          # ← Framework looks this up in registry
+    module: MyModule # ← Framework looks this up in registry
     params:
-      timeout: 10000         # ← Passed as options to constructor
+      timeout: 10000 # ← Passed as options to constructor
 ```
 
 2. **Framework looks up in registry**:
+
 ```typescript
 const ModuleClass = moduleRegistry.get('MyModule');
 // Returns: typeof MyModule (the class itself)
 ```
 
 3. **Framework instantiates**:
+
 ```typescript
 // This is what the framework does internally:
 const module = new ModuleClass(kernel, {
-  timeout: 10000  // From config params
+  timeout: 10000, // From config params
 });
 ```
 
 4. **Framework connects pipes**:
+
 ```typescript
-module.inputPipe = createReadStream();    // If module needs input
-module.outputPipe = createWriteStream();  // If module produces output
+module.inputPipe = createReadStream(); // If module needs input
+module.outputPipe = createWriteStream(); // If module produces output
 ```
 
 5. **Framework calls lifecycle**:
+
 ```typescript
-module.start();   // When topology starts
+module.start(); // When topology starts
 // ... topology runs ...
-module.stop();    // When topology shuts down
+module.stop(); // When topology shuts down
 ```
 
 ### Registering in ModuleRegistry
@@ -191,8 +202,8 @@ export class ModuleRegistry {
     this.register('ConsoleSink', ConsoleSink);
 
     // Your custom modules
-    this.register('MyModule', MyModule);        // Add this
-    this.register('MyTransform', MyTransform);  // Add this
+    this.register('MyModule', MyModule); // Add this
+    this.register('MyTransform', MyTransform); // Add this
   }
 
   register(name: string, constructor: any): void {
@@ -259,10 +270,13 @@ export class ReverseTransform {
 
   private options: ReverseTransformOptions;
 
-  constructor(private kernel: Kernel, options: ReverseTransformOptions = {}) {
+  constructor(
+    private kernel: Kernel,
+    options: ReverseTransformOptions = {},
+  ) {
     this.options = {
       preserveNewlines: options.preserveNewlines ?? true,
-      ...options
+      ...options,
     };
   }
 
@@ -290,7 +304,7 @@ export class ReverseTransform {
     if (this.options.preserveNewlines) {
       // Keep newlines in place
       const lines = text.split('\n');
-      return lines.map(line => [...line].reverse().join('')).join('\n');
+      return lines.map((line) => [...line].reverse().join('')).join('\n');
     }
     return [...text].reverse().join('');
   }
@@ -320,7 +334,7 @@ nodes:
   - id: output
     module: ConsoleSink
     params:
-      prefix: "[reversed]"
+      prefix: '[reversed]'
 
 connections:
   - from: timer.output
@@ -375,7 +389,10 @@ start(): void {
 export class TimerSource {
   outputPipe?: NodeJS.WritableStream;
 
-  constructor(private kernel: Kernel, private options: TimerOptions) {}
+  constructor(
+    private kernel: Kernel,
+    private options: TimerOptions,
+  ) {}
 
   start(): void {
     setInterval(() => {
@@ -410,7 +427,10 @@ export class UppercaseTransform {
 export class ConsoleSink {
   inputPipe?: NodeJS.ReadableStream;
 
-  constructor(private kernel: Kernel, private options: ConsoleSinkOptions) {}
+  constructor(
+    private kernel: Kernel,
+    private options: ConsoleSinkOptions,
+  ) {}
 
   start(): void {
     this.inputPipe!.on('data', (chunk: Buffer) => {
@@ -492,7 +512,9 @@ describe('MyModule', () => {
 
   beforeEach(() => {
     kernel = new Kernel();
-    module = new MyModule(kernel, { /* options */ });
+    module = new MyModule(kernel, {
+      /* options */
+    });
 
     // Create mock pipes
     input = Readable.from(['hello\n', 'world\n']);
@@ -500,7 +522,7 @@ describe('MyModule', () => {
       write(chunk, encoding, callback) {
         results.push(chunk);
         callback();
-      }
+      },
     });
 
     module.inputPipe = input;
@@ -515,7 +537,7 @@ describe('MyModule', () => {
     module.start();
 
     // Wait for all data to process
-    await new Promise(resolve => output.on('finish', resolve));
+    await new Promise((resolve) => output.on('finish', resolve));
 
     expect(results).toHaveLength(2);
     expect(results[0].toString()).toBe('HELLO\n');
@@ -527,7 +549,7 @@ describe('MyModule', () => {
     module.inputPipe = emptyInput;
 
     module.start();
-    await new Promise(resolve => output.on('finish', resolve));
+    await new Promise((resolve) => output.on('finish', resolve));
 
     expect(results).toHaveLength(0);
   });
@@ -536,18 +558,16 @@ describe('MyModule', () => {
     const errorInput = new Readable({
       read() {
         this.emit('error', new Error('test error'));
-      }
+      },
     });
 
     module.inputPipe = errorInput;
     const spy = vi.spyOn(console, 'error').mockImplementation(() => {});
 
     module.start();
-    await new Promise(resolve => setTimeout(resolve, 100));
+    await new Promise((resolve) => setTimeout(resolve, 100));
 
-    expect(spy).toHaveBeenCalledWith(
-      expect.stringContaining('test error')
-    );
+    expect(spy).toHaveBeenCalledWith(expect.stringContaining('test error'));
   });
 });
 ```
@@ -574,7 +594,7 @@ export class MyModule {
       enabled: options.enabled ?? true,
       timeout: options.timeout ?? 5000,
       maxRetries: options.maxRetries ?? 3,
-      prefix: options.prefix ?? '[module]'
+      prefix: options.prefix ?? '[module]',
     };
 
     // Validate
@@ -605,7 +625,10 @@ export class Counter {
   private count = 0;
   private options: CounterOptions;
 
-  constructor(private kernel: Kernel, options: CounterOptions = {}) {
+  constructor(
+    private kernel: Kernel,
+    options: CounterOptions = {},
+  ) {
     this.options = { format: options.format ?? 'raw' };
   }
 
@@ -613,9 +636,10 @@ export class Counter {
     this.inputPipe!.on('data', () => {
       this.count++;
 
-      const output = this.options.format === 'json'
-        ? JSON.stringify({ count: this.count, timestamp: Date.now() })
-        : this.count.toString();
+      const output =
+        this.options.format === 'json'
+          ? JSON.stringify({ count: this.count, timestamp: Date.now() })
+          : this.count.toString();
 
       this.outputPipe!.write(output + '\n');
     });
@@ -693,7 +717,10 @@ export class BufferTransform {
 
 ```typescript
 export class FilterTransform {
-  constructor(private kernel: Kernel, private predicate: (chunk: Buffer) => boolean) {}
+  constructor(
+    private kernel: Kernel,
+    private predicate: (chunk: Buffer) => boolean,
+  ) {}
 
   start(): void {
     this.inputPipe!.on('data', (chunk: Buffer) => {
@@ -755,6 +782,7 @@ npm run lam -- show mymodule --around "module.start"
 ## Best Practices
 
 ✅ **DO:**
+
 - Handle backpressure with pause/resume
 - Clean up resources in stop()
 - Validate options in constructor
@@ -764,6 +792,7 @@ npm run lam -- show mymodule --around "module.start"
 - Use TypeScript interfaces for options
 
 ❌ **DON'T:**
+
 - Ignore backpressure (causes memory issues)
 - Leave timers/intervals running after stop()
 - Assume pipes are always connected
@@ -804,4 +833,3 @@ Example package.json:
 - **Examples**: Browse `src/modules/` and `src/transforms/`
 - **Testing**: See [Wiring and Tests](./wiring-and-tests.md)
 - **Configuration**: See [mkctl Cookbook](./mkctl-cookbook.md)
-
diff --git a/docs/devex/ci-acceptance-smoke.md b/docs/devex/ci-acceptance-smoke.md
index 2d5bbbc..bb250cf 100644
--- a/docs/devex/ci-acceptance-smoke.md
+++ b/docs/devex/ci-acceptance-smoke.md
@@ -7,11 +7,13 @@
 ## Why Acceptance Smoke Tests?
 
 The smoke test answers three critical questions:
+
 1. **Does the topology actually run?** (Not just unit tests passing)
 2. **Does data flow correctly?** (FilesystemSink receives and records data)
 3. **Is routing working?** (Router endpoints are properly discovered)
 
 These are end-to-end integration checks that **no unit test can fully replicate**. They catch issues like:
+
 - Module instantiation failures in real executor context
 - Pipe connection errors between modules
 - Heartbeat/health check timeouts
@@ -70,9 +72,9 @@ nodes:
       args:
         - -e
         - "require('http').createServer((req,res)=>{
-             console.log(`[${new Date().toISOString()}] ${req.method} ${req.url}`);
-             res.end('ok')
-           }).listen(3000,()=>console.log('Server listening on http://localhost:3000'))"
+          console.log(`[${new Date().toISOString()}] ${req.method} ${req.url}`);
+          res.end('ok')
+          }).listen(3000,()=>console.log('Server listening on http://localhost:3000'))"
       ioMode: stdio
       restart: never
 
@@ -87,6 +89,7 @@ connections:
 ```
 
 **Why this config?**
+
 - **Lightweight**: No external processes or complex setup
 - **Observable**: Generates JSONL output that can be inspected
 - **Isolated**: Doesn't conflict with main unit tests
@@ -101,8 +104,8 @@ acceptance-smoke:
   name: Acceptance Smoke Test (FilesystemSink)
   runs-on: ubuntu-latest
   needs: test
-  if: ${{ always() }}           # Run even if test job fails
-  continue-on-error: true       # Don't block PR on smoke test failure
+  if: ${{ always() }} # Run even if test job fails
+  continue-on-error: true # Don't block PR on smoke test failure
 
   steps:
     - name: Setup
@@ -110,7 +113,7 @@ acceptance-smoke:
 
     - name: Run acceptance smoke test
       env:
-        MK_LOCAL_NODE: '1'      # Enforce Local Node mode
+        MK_LOCAL_NODE: '1' # Enforce Local Node mode
       run: |
         timeout 10 node dist/scripts/mkctl.js run \
           --file examples/configs/http-logs-local-file.yml \
@@ -137,11 +140,13 @@ fi
 ```
 
 **What it validates:**
+
 - mkctl started successfully
 - Executor initialized nodes without errors
 - Topology reached "running" state (not crashed during startup)
 
 **Failure indicators:**
+
 - "Module not found" error
 - "Configuration validation failed"
 - "Health check failed"
@@ -161,12 +166,14 @@ fi
 ```
 
 **What it validates:**
+
 - FilesystemSink module instantiated correctly
 - Pipes connected between ExternalProcess → FilesystemSink
 - HTTP server emitted data (at least one line logged)
 - Data persisted to filesystem
 
 **Failure indicators:**
+
 - File doesn't exist (JSONL never created)
 - File empty (pipes not connected or no data emitted)
 - File permission error (directory not writable)
@@ -185,12 +192,14 @@ fi
 ```
 
 **What it validates:**
+
 - RoutingServer (or in-process Router) running
 - Both endpoints registered: `web.output` and `sink.input`
 - Snapshot persisted to JSON at shutdown
 - Router tracked module endpoints correctly
 
 **Failure indicators:**
+
 - File doesn't exist (Router didn't snapshot)
 - Endpoint count 0 (modules not registered)
 - Endpoint count 1 (one module failed to register)
@@ -225,9 +234,10 @@ The script reads `reports/acceptance-smoke.jsonl` and generates PR comment secti
 function readAcceptanceResults() {
   if (!fs.existsSync(ACCEPTANCE_PATH)) return '';
 
-  const lines = fs.readFileSync(ACCEPTANCE_PATH, 'utf-8')
+  const lines = fs
+    .readFileSync(ACCEPTANCE_PATH, 'utf-8')
     .split('\n')
-    .filter(l => l.trim());
+    .filter((l) => l.trim());
 
   const result = JSON.parse(lines[lines.length - 1]); // Last result
 
@@ -264,6 +274,7 @@ Or if failed:
 ## PR Comment Structure
 
 The aggregated PR comment combines:
+
 1. **Test Summary** (from Laminar unit tests)
 2. **Failure Trends** (from Laminar trends history)
 3. **Flake Budget** (tests failing ≥2 times in last 5 runs)
@@ -274,18 +285,23 @@ The aggregated PR comment combines:
 ## 📊 Laminar Test Report (Aggregated)
 
 ### Test Summary
+
 ...unit test results...
 
 ### Failure Trends
+
 ...failure trends...
 
 ### 🔴 Flake Budget
+
 ...flaky tests...
 
 ### 🧪 Acceptance Smoke Test
+
 ✅ Topology | ✅ FilesystemSink | ✅ Router Endpoints
 
 ### 📁 Artifacts
+
 - Full Summary: See job artifacts for LAMINAR_SUMMARY.txt
 - Repro Hints: See job artifacts for LAMINAR_REPRO.md
 - Acceptance Logs: See job artifacts for acceptance-smoke-logs
@@ -435,12 +451,14 @@ The acceptance smoke results feed into the flake budget (tests failing ≥2 time
 ### Artifact Persistence
 
 CI artifacts retained for 90 days (GitHub Actions default):
+
 - `/tmp/smoke-test.log` — Raw mkctl output
 - `reports/acceptance-smoke.jsonl` — Result record
 - `reports/http-logs.jsonl` — Topology output data
 - `reports/router-endpoints.json` — Endpoint snapshot
 
 **Access in GitHub UI:**
+
 ```
 Actions → Workflow run → Artifacts → acceptance-smoke-logs
 ```
@@ -453,7 +471,7 @@ Actions → Workflow run → Artifacts → acceptance-smoke-logs
 
 ```yaml
 acceptance-smoke:
-  continue-on-error: false  # Change to required status
+  continue-on-error: false # Change to required status
 
 # Would require:
 # - Reducing flakiness (network timeouts, timing issues)
@@ -498,8 +516,8 @@ mk-rc-smoke:
   name: MK RC Smoke Test (init/build/package)
   runs-on: ubuntu-latest
   needs: test
-  if: ${{ always() }}           # Run even if test job fails
-  continue-on-error: true       # Don't block PR on smoke test failure
+  if: ${{ always() }} # Run even if test job fails
+  continue-on-error: true # Don't block PR on smoke test failure
 ```
 
 ### Test Sequence
@@ -515,12 +533,14 @@ Each test is conditional on the previous step passing.
 ### Validation Checks
 
 **Check 1: mk init**
+
 ```bash
 node dist/scripts/mk.js init test-project > /tmp/mk-init.log 2>&1
 # Validates: Project scaffolding, package.json creation, default config generation
 ```
 
 **Check 2: mk build**
+
 ```bash
 cd test-project
 node ../dist/scripts/mk.js build > /tmp/mk-build.log 2>&1
@@ -528,6 +548,7 @@ node ../dist/scripts/mk.js build > /tmp/mk-build.log 2>&1
 ```
 
 **Check 3: mk package**
+
 ```bash
 node ../dist/scripts/mk.js package > /tmp/mk-package.log 2>&1
 # Validates: Tarball creation, dependency bundling, package metadata
@@ -550,6 +571,7 @@ Results are recorded to `reports/mk-rc-smoke.jsonl`:
 ### Artifacts
 
 CI artifacts include:
+
 - `/tmp/mk-init.log` — mk init command output
 - `/tmp/mk-build.log` — mk build command output
 - `/tmp/mk-package.log` — mk package command output
@@ -586,6 +608,7 @@ mk ci plan --env
 ### Output Formats
 
 **JSON (default):**
+
 ```json
 {
   "matrix": {
@@ -600,6 +623,7 @@ mk ci plan --env
 ```
 
 **ENV format (--env):**
+
 ```bash
 export MATRIX_NODE='["20","24"]'
 export MATRIX_LANE='["threads","forks"]'
@@ -665,8 +689,7 @@ Test Configuration:
   ├─ Modules: ExternalProcess → PipeMeterTransform → FilesystemSink
   └─ Router: Heartbeat/TTL tracking enabled (MK_LOCAL_NODE=1)
 
-Validation Checks:
-  ✅ Topology runs successfully under load
+Validation Checks: ✅ Topology runs successfully under load
   ✅ Data throughput sustained (≥10 messages)
   ✅ Router endpoints tracked with heartbeat metadata
   ✅ Stale endpoint detection metadata present
@@ -675,16 +698,19 @@ Validation Checks:
 ### What It Tests
 
 **1. Sustained Load Handling**
+
 - Topology processes ~10,000 messages over 10 seconds
 - Verifies no crashes, deadlocks, or dropped connections
 - Measures data throughput via FilesystemSink output
 
 **2. Router Heartbeat Mechanism**
+
 - Endpoints registered and tracked in router snapshot
 - Heartbeat/TTL metadata recorded for each endpoint
 - Validates infrastructure for stale endpoint eviction
 
 **3. TTL Expiry Readiness**
+
 - Confirms presence of `lastHeartbeat` and `ttlMs` fields
 - Verifies router can identify stale endpoints (future feature)
 - Tests endpoint snapshot persistence under load
@@ -701,17 +727,17 @@ nodes:
       command: node
       args:
         - -e
-        - "setInterval(() => { 
-             for(let i=0; i<100; i++) 
-               console.log('msg-' + Date.now() + '-' + i); 
-           }, 100);"
+        - "setInterval(() => {
+          for(let i=0; i<100; i++)
+          console.log('msg-' + Date.now() + '-' + i);
+          }, 100);"
       ioMode: stdio
-      
+
   - id: meter
     module: PipeMeterTransform
     params:
       emitInterval: 1000
-      
+
   - id: sink
     module: FilesystemSink
     params:
@@ -719,6 +745,7 @@ nodes:
 ```
 
 **Why this config?**
+
 - **High volume**: 100 messages every 100ms = 1000 msg/sec
 - **Observable**: JSONL output provides line count for throughput measurement
 - **Realistic**: Stresses pipe buffers, router tracking, and file I/O
@@ -727,6 +754,7 @@ nodes:
 ### Validation Logic
 
 **Check 1: Topology Started**
+
 ```typescript
 if (!logOutput.includes('Topology running') && !logOutput.includes('Starting')) {
   throw new Error('Topology did not start successfully');
@@ -734,17 +762,19 @@ if (!logOutput.includes('Topology running') && !logOutput.includes('Starting'))
 ```
 
 **Check 2: Data Throughput**
+
 ```typescript
-const lineCount = outputContent.split('\n').filter(l => l.trim()).length;
+const lineCount = outputContent.split('\n').filter((l) => l.trim()).length;
 if (lineCount < 10) {
   throw new Error(`Insufficient data throughput (${lineCount} lines)`);
 }
 ```
 
 **Check 3: Router Heartbeat Metadata**
+
 ```typescript
-const hasHeartbeatData = endpoints.some((ep: any) => 
-  ep.lastHeartbeat !== undefined || ep.ttlMs !== undefined
+const hasHeartbeatData = endpoints.some(
+  (ep: any) => ep.lastHeartbeat !== undefined || ep.ttlMs !== undefined,
 );
 ```
 
@@ -756,8 +786,8 @@ The TTL soak test runs as part of the `acceptance-smoke` job:
 acceptance-smoke:
   name: Acceptance Smoke Test (FilesystemSink)
   runs-on: ubuntu-latest
-  continue-on-error: true  # Non-gating
-  
+  continue-on-error: true # Non-gating
+
   steps:
     - name: Run acceptance tests
       run: npm run test:acceptance
@@ -765,6 +795,7 @@ acceptance-smoke:
 ```
 
 Results are aggregated in the acceptance test report:
+
 - `reports/mk-acceptance-results.md` — Full test results with TTL soak
 - Test duration and throughput metrics logged
 - Router endpoint snapshot saved as artifact
@@ -772,6 +803,7 @@ Results are aggregated in the acceptance test report:
 ### Debugging TTL Soak Failures
 
 **If topology fails to start:**
+
 ```bash
 # Check build artifacts
 npm run build
@@ -783,6 +815,7 @@ timeout 12 node dist/scripts/mkctl.js run \
 ```
 
 **If throughput is low:**
+
 ```bash
 # Check JSONL output
 wc -l reports/ttl-soak.jsonl
@@ -793,6 +826,7 @@ head -n 20 reports/ttl-soak.jsonl
 ```
 
 **If router metadata missing:**
+
 ```bash
 # Check endpoint snapshot
 cat reports/router-endpoints.json | jq '.[] | {id, lastHeartbeat, ttlMs}'
@@ -832,6 +866,7 @@ The TTL soak test is **non-gating** because:
 4. **Best-effort validation** — Failure indicates potential issues but doesn't block PRs
 
 When stale endpoint eviction is fully implemented, this test can be extended to:
+
 - Stop sending heartbeats mid-run
 - Verify endpoints removed after TTL expires
 - Test routing failover when endpoints become stale
@@ -855,6 +890,7 @@ When stale endpoint eviction is fully implemented, this test can be extended to:
 **"My PR has a smoke test warning, should I be concerned?"**
 
 Check the PR comment:
+
 - ✅✅✅ All pass? No action needed
 - ✅❌✅ One failed? Review your changes—likely a real issue in routing or data flow
 - ❌❌❌ All failed? Check if dependent test job failed first
@@ -875,7 +911,7 @@ ls -la reports/
 ```yaml
 # In .github/workflows/tests.yml
 acceptance-smoke:
-  if: ${{ false }}  # Disable job
+  if: ${{ false }} # Disable job
 ```
 
 **"I want to change the test topology"**
diff --git a/docs/devex/cli-reference.md b/docs/devex/cli-reference.md
index e2615cd..4c7472c 100644
--- a/docs/devex/cli-reference.md
+++ b/docs/devex/cli-reference.md
@@ -8,21 +8,22 @@
 
 The `mk` CLI provides commands for the complete development workflow:
 
-| Command | Purpose | Phase |
-|---------|---------|-------|
-| `mk init` | Initialize new mkolbol project | Scaffolding |
-| `mk run` | Execute topology configuration | Development |
-| `mk doctor` | Validate configuration and health | Validation |
-| `mk format` | Convert configs (JSON ↔ YAML) | Authoring |
-| `mk graph` | Visualize topology connections | Documentation |
-| `mk dev` | Hot reload development mode | Development |
-| `mk logs` | Query structured logs | Debugging |
-| `mk trace` | Analyze flow timing | Performance |
-| `mk build` | Compile and bundle artifacts | Build |
-| `mk package` | Create distributable tarball | Distribution |
-| `mk ci plan` | Generate CI configuration | CI/CD |
+| Command      | Purpose                           | Phase         |
+| ------------ | --------------------------------- | ------------- |
+| `mk init`    | Initialize new mkolbol project    | Scaffolding   |
+| `mk run`     | Execute topology configuration    | Development   |
+| `mk doctor`  | Validate configuration and health | Validation    |
+| `mk format`  | Convert configs (JSON ↔ YAML)    | Authoring     |
+| `mk graph`   | Visualize topology connections    | Documentation |
+| `mk dev`     | Hot reload development mode       | Development   |
+| `mk logs`    | Query structured logs             | Debugging     |
+| `mk trace`   | Analyze flow timing               | Performance   |
+| `mk build`   | Compile and bundle artifacts      | Build         |
+| `mk package` | Create distributable tarball      | Distribution  |
+| `mk ci plan` | Generate CI configuration         | CI/CD         |
 
 **Prerequisites:**
+
 - Node 20+ installed
 - mkolbol repository cloned and built (`npm install && npm run build`)
 - `MK_LOCAL_NODE=1` environment variable set (for development)
@@ -42,6 +43,7 @@ node dist/scripts/mk.js init hello-calculator
 ### Adding mk to PATH (Recommended)
 
 **Linux/macOS:**
+
 ```bash
 # Add to ~/.bashrc or ~/.zshrc
 export PATH="/path/to/mkolbol/dist/scripts:$PATH"
@@ -53,6 +55,7 @@ mk --help       # → Shows mk help
 ```
 
 **Windows:**
+
 ```powershell
 # Add to PATH via System Properties → Environment Variables
 # Or create .cmd shim:
@@ -71,11 +74,13 @@ See **[Installation: mk Anywhere](../../README.md#installation-mk-anywhere-self-
 Initialize a new mkolbol project from a template.
 
 **Usage:**
+
 ```
 mk init [project-name] [--lang <ts|js>] [--preset <tty|stdio|interactive>] [--force]
 ```
 
 **Options:**
+
 - `project-name` — Directory name for new project (default: interactive prompt)
 - `--lang <ts|js>` — Language for scaffolded files (default: `ts`)
 - `--preset <name>` — Template preset to use (default: `tty`)
@@ -85,6 +90,7 @@ mk init [project-name] [--lang <ts|js>] [--preset <tty|stdio|interactive>] [--fo
 - `--force` — Overwrite existing directory (default: false)
 
 **What it creates:**
+
 ```
 project-name/
 ├── .mk/
@@ -115,6 +121,7 @@ mk init data-pipeline --lang ts --preset stdio
 ```
 
 **After init:**
+
 ```bash
 cd hello-calculator
 npm install /path/to/mkolbol-0.2.0.tgz  # Install mkolbol dependency
@@ -123,6 +130,7 @@ mk run --file mk.json --duration 10
 ```
 
 **See Also:**
+
 - **[Bootstrap Tutorial](./using-mkolbol-in-your-repo.md)** — Complete out-of-tree workflow
 - **[First Five Minutes](./first-five-minutes.md)** — End-to-end mk workflow
 
@@ -133,11 +141,13 @@ mk run --file mk.json --duration 10
 Execute a topology configuration file.
 
 **Usage:**
+
 ```
 mk run [--file <path>] [--duration <seconds>] [--dry-run] [--profile <name>] [--verbose]
 ```
 
 **Options:**
+
 - `--file <path>` — Config file (JSON or YAML). Default: `mk.json`
 - `--duration <seconds>` — How long to run topology. Default: `5`
 - `--dry-run` — Validate config without executing. Default: `false`
@@ -164,6 +174,7 @@ mk run --file mk.json --duration 10 --verbose
 ```
 
 **Exit Codes:**
+
 - `0` — Success
 - `64` — Usage error (invalid flags)
 - `65` — Config parse error
@@ -172,9 +183,11 @@ mk run --file mk.json --duration 10 --verbose
 - `130` — Interrupted (Ctrl+C)
 
 **Environment:**
+
 - `MK_LOCAL_NODE=1` — Required for development (disables network features)
 
 **See Also:**
+
 - **[Quickstart](./quickstart.md)** — Getting started with mkctl run
 - **[Wiring Guide](./wiring-and-tests.md)** — Complete config schema
 
@@ -185,17 +198,20 @@ mk run --file mk.json --duration 10 --verbose
 Validate configuration and perform health checks.
 
 **Usage:**
+
 ```
 mk doctor [--file <path>] [--module <id>] [--dry-run] [--verbose]
 ```
 
 **Options:**
+
 - `--file <path>` — Config file to validate. Default: `mk.json`
 - `--module <id>` — Check specific module only
 - `--dry-run` — Show what would be checked without executing
 - `--verbose` — Show detailed diagnostic output
 
 **What it checks:**
+
 - ✓ Config file syntax (JSON/YAML)
 - ✓ Schema validation (nodes, connections, params)
 - ✓ Module registry (all modules exist)
@@ -222,6 +238,7 @@ mk doctor --file mk.json --verbose
 ```
 
 **Output:**
+
 ```
 [✓] Config file valid (mk.json)
 [✓] All modules registered (3 modules)
@@ -235,6 +252,7 @@ mk doctor --file mk.json --verbose
 ```
 
 **Errors:**
+
 ```
 [✗] Port 4000 already in use
 Fix: Run: lsof -i :4000 && kill -9 <pid>
@@ -243,6 +261,7 @@ Code: PORT_IN_USE
 ```
 
 **See Also:**
+
 - **[Doctor Guide](./doctor.md)** — Complete troubleshooting reference
 - **[Troubleshooting](./troubleshooting.md)** — Common issues and fixes
 
@@ -253,11 +272,13 @@ Code: PORT_IN_USE
 Convert configuration files between JSON and YAML.
 
 **Usage:**
+
 ```
 mk format [--to <json|yaml>] [--from <path>] [--output <path>] [--dry-run]
 ```
 
 **Options:**
+
 - `--to <format>` — Target format (`json` or `yaml`). Required.
 - `--from <path>` — Source config file. Default: `mk.json`
 - `--output <path>` — Output file path. Default: inferred from source
@@ -282,12 +303,14 @@ mk format --to yaml --from config.json --output topology.yaml
 ```
 
 **Why YAML?**
+
 - More concise (no quotes on most values)
 - Comments supported (`# This is a comment`)
 - Multi-line strings easier
 - Industry standard for config
 
 **See Also:**
+
 - **[Wiring Guide](./wiring-and-tests.md#config-formats)** — JSON vs YAML comparison
 
 ---
@@ -297,11 +320,13 @@ mk format --to yaml --from config.json --output topology.yaml
 Visualize topology connections as ASCII or DOT format.
 
 **Usage:**
+
 ```
 mk graph [--file <path>] [--format <ascii|dot>] [--output <path>]
 ```
 
 **Options:**
+
 - `--file <path>` — Config file to visualize. Default: `mk.json`
 - `--format <type>` — Output format (`ascii` or `dot`). Default: `ascii`
 - `--output <path>` — Write to file instead of stdout
@@ -323,6 +348,7 @@ mk graph --file mk.json --format dot | dot -Tpng > topology.png
 ```
 
 **ASCII Output:**
+
 ```
 ┌──────────────┐
 │  calculator  │
@@ -337,6 +363,7 @@ mk graph --file mk.json --format dot | dot -Tpng > topology.png
 ```
 
 **DOT Output:**
+
 ```dot
 digraph topology {
   rankdir=LR;
@@ -357,11 +384,13 @@ Hot reload development mode (watch source files and restart topology on changes)
 **Status:** Planned (not yet implemented)
 
 **Usage:**
+
 ```
 mk dev [--file <path>] [--watch <glob>] [--debounce <ms>]
 ```
 
 **Options:**
+
 - `--file <path>` — Config file. Default: `mk.json`
 - `--watch <glob>` — Files to watch. Default: `src/**/*.{ts,js}`
 - `--debounce <ms>` — Restart delay. Default: `300`
@@ -380,6 +409,7 @@ mk dev --file mk.json --debounce 500
 ```
 
 **See Also:**
+
 - **[mk dev, logs, trace Guide](./mk-dev-logs-trace.md)** — Development ergonomics
 
 ---
@@ -391,11 +421,13 @@ Query structured logs with filters.
 **Status:** Planned (not yet implemented)
 
 **Usage:**
+
 ```
 mk logs [--file <path>] [--module <id>] [--level <level>] [--since <time>] [--follow]
 ```
 
 **Options:**
+
 - `--file <path>` — Log file. Default: `logs/*.jsonl`
 - `--module <id>` — Filter by module ID
 - `--level <level>` — Filter by level (`error`, `warn`, `info`, `debug`, `trace`)
@@ -422,6 +454,7 @@ mk logs --module calculator --level error --follow
 ```
 
 **See Also:**
+
 - **[mk dev, logs, trace Guide](./mk-dev-logs-trace.md)** — Development ergonomics
 
 ---
@@ -433,11 +466,13 @@ Analyze flow timing and latency.
 **Status:** Planned (not yet implemented)
 
 **Usage:**
+
 ```
 mk trace [--file <path>] [--duration <seconds>] [--threshold <ms>]
 ```
 
 **Options:**
+
 - `--file <path>` — Config file. Default: `mk.json`
 - `--duration <seconds>` — How long to trace. Default: `10`
 - `--threshold <ms>` — Highlight slow operations. Default: `100`
@@ -456,6 +491,7 @@ mk trace --file mk.json --threshold 50
 ```
 
 **Output:**
+
 ```
 Flow Timing (10s sample):
   calculator → tty-renderer    avg: 2.3ms  p95: 5.1ms  p99: 8.7ms
@@ -467,6 +503,7 @@ Slow Operations (>100ms):
 ```
 
 **See Also:**
+
 - **[mk dev, logs, trace Guide](./mk-dev-logs-trace.md)** — Development ergonomics
 
 ---
@@ -476,16 +513,19 @@ Slow Operations (>100ms):
 Compile TypeScript and bundle artifacts.
 
 **Usage:**
+
 ```
 mk build [--target <dev|production>] [--sourcemaps] [--verbose]
 ```
 
 **Options:**
+
 - `--target <name>` — Build target (`dev` or `production`). Default: `production`
 - `--sourcemaps` — Generate source maps. Default: `false`
 - `--verbose` — Show detailed build output
 
 **What it does:**
+
 1. Compiles `src/**/*.ts` → `dist/**/*.js`
 2. Bundles dependencies (if configured in `.mk/options.json`)
 3. Generates `dist/manifest.json` with provenance:
@@ -509,6 +549,7 @@ mk build --verbose
 ```
 
 **Output:**
+
 ```
 [mk] Building project...
 [mk] Compiling TypeScript → dist/
@@ -524,6 +565,7 @@ Artifacts:
 ```
 
 **Manifest Example:**
+
 ```json
 {
   "version": "0.1.0",
@@ -538,6 +580,7 @@ Artifacts:
 ```
 
 **See Also:**
+
 - **[First Five Minutes](./first-five-minutes.md#5-build-artifacts-1-minute)** — Complete workflow
 
 ---
@@ -547,16 +590,19 @@ Artifacts:
 Create distributable tarball with checksums.
 
 **Usage:**
+
 ```
 mk package [--output <path>] [--sign] [--with-sourcemaps]
 ```
 
 **Options:**
+
 - `--output <path>` — Output tarball path. Default: `<project>-<version>.tgz`
 - `--sign` — Sign with GPG. Default: `false`
 - `--with-sourcemaps` — Include source maps. Default: `false`
 
 **What it includes:**
+
 ```
 <project>-<version>.tgz
 ├── dist/                 # Compiled artifacts
@@ -585,6 +631,7 @@ mk package --with-sourcemaps
 ```
 
 **Install elsewhere:**
+
 ```bash
 # Copy tarball
 scp hello-calculator-0.1.0.tgz remote:/tmp/
@@ -598,6 +645,7 @@ mk run --file mk.json
 ```
 
 **See Also:**
+
 - **[First Five Minutes](./first-five-minutes.md#6-package-for-distribution-1-minute)** — Complete workflow
 - **[Distribution Matrix](./distribution.md)** — Installation methods
 
@@ -608,16 +656,19 @@ mk run --file mk.json
 Generate GitHub Actions CI configuration.
 
 **Usage:**
+
 ```
 mk ci plan [--output] [--with-laminar] [--env]
 ```
 
 **Options:**
+
 - `--output` — Write to `.github/workflows/test.yml`. Default: print to stdout
 - `--with-laminar` — Include Laminar test observability. Default: `false`
 - `--env` — Output as environment variables for sourcing
 
 **What it generates:**
+
 - GitHub Actions workflow with matrix testing
 - Test matrix from `.mk/options.json` (node versions, test lanes)
 - Dependency caching
@@ -642,6 +693,7 @@ echo $MATRIX_LANE  # → ["threads", "forks"]
 ```
 
 **Generated Workflow:**
+
 ```yaml
 name: Tests
 
@@ -652,8 +704,8 @@ jobs:
     runs-on: ubuntu-latest
     strategy:
       matrix:
-        node: ["20", "24"]
-        lane: ["threads", "forks"]
+        node: ['20', '24']
+        lane: ['threads', 'forks']
     steps:
       - uses: actions/checkout@v4
       - uses: actions/setup-node@v4
@@ -665,6 +717,7 @@ jobs:
 ```
 
 **See Also:**
+
 - **[CI Acceptance Smoke](./ci-acceptance-smoke.md)** — Complete CI guide
 - **[First Five Minutes](./first-five-minutes.md#7-generate-ci-config-1-minute)** — Complete workflow
 
@@ -674,14 +727,14 @@ jobs:
 
 These flags work with all commands:
 
-| Flag | Description | Default |
-|------|-------------|---------|
-| `--help`, `-h` | Show command help | - |
-| `--version`, `-v` | Show version | - |
-| `--json` | Machine-readable JSON output | `false` |
-| `--no-color` | Disable ANSI colors | `false` |
-| `--verbose` | Show detailed output | `false` |
-| `--quiet` | Suppress non-error output | `false` |
+| Flag              | Description                  | Default |
+| ----------------- | ---------------------------- | ------- |
+| `--help`, `-h`    | Show command help            | -       |
+| `--version`, `-v` | Show version                 | -       |
+| `--json`          | Machine-readable JSON output | `false` |
+| `--no-color`      | Disable ANSI colors          | `false` |
+| `--verbose`       | Show detailed output         | `false` |
+| `--quiet`         | Suppress non-error output    | `false` |
 
 **Examples:**
 
@@ -708,12 +761,12 @@ mk build --quiet
 
 ## Environment Variables
 
-| Variable | Purpose | Default |
-|----------|---------|---------|
-| `MK_LOCAL_NODE` | Enable local node mode (required for development) | `0` |
-| `MK_DEBUG` | Enable debug output | `0` |
-| `MK_DEBUG_MODULES` | Debug specific modules (comma-separated) | - |
-| `MK_DEBUG_LEVEL` | Debug level (`error`, `warn`, `info`, `debug`, `trace`) | `info` |
+| Variable           | Purpose                                                 | Default |
+| ------------------ | ------------------------------------------------------- | ------- |
+| `MK_LOCAL_NODE`    | Enable local node mode (required for development)       | `0`     |
+| `MK_DEBUG`         | Enable debug output                                     | `0`     |
+| `MK_DEBUG_MODULES` | Debug specific modules (comma-separated)                | -       |
+| `MK_DEBUG_LEVEL`   | Debug level (`error`, `warn`, `info`, `debug`, `trace`) | `info`  |
 
 **Examples:**
 
@@ -733,6 +786,7 @@ MK_DEBUG_LEVEL=trace mk run --file mk.json
 ```
 
 **See Also:**
+
 - **[Debug Instrumentation](../../README.md#debug-instrumentation)** — Complete debug guide
 
 ---
@@ -741,15 +795,15 @@ MK_DEBUG_LEVEL=trace mk run --file mk.json
 
 Standard exit codes across all commands:
 
-| Code | Meaning | Example |
-|------|---------|---------|
-| `0` | Success | Command completed successfully |
-| `1` | General error | Unhandled exception |
-| `64` | Usage error | Invalid flags, missing arguments |
-| `65` | Config parse error | Invalid JSON/YAML syntax |
-| `66` | File not found | Config file missing |
-| `70` | Runtime error | Topology execution failed |
-| `130` | Interrupted | Ctrl+C (SIGINT) |
+| Code  | Meaning            | Example                          |
+| ----- | ------------------ | -------------------------------- |
+| `0`   | Success            | Command completed successfully   |
+| `1`   | General error      | Unhandled exception              |
+| `64`  | Usage error        | Invalid flags, missing arguments |
+| `65`  | Config parse error | Invalid JSON/YAML syntax         |
+| `66`  | File not found     | Config file missing              |
+| `70`  | Runtime error      | Topology execution failed        |
+| `130` | Interrupted        | Ctrl+C (SIGINT)                  |
 
 **Using exit codes in scripts:**
 
@@ -778,6 +832,7 @@ mk run --file mk.json --duration 30 || {
 All mk errors follow consistent format:
 
 **Human-readable:**
+
 ```
 [ERR] ERROR_CODE at <location> — brief description
 Fix: <actionable remediation>
@@ -786,6 +841,7 @@ Code: ERROR_CODE  Rerun: <exact command>
 ```
 
 **Machine-readable (with `--json`):**
+
 ```json
 {
   "code": "CONFIG_PARSE",
@@ -798,6 +854,7 @@ Code: ERROR_CODE  Rerun: <exact command>
 ```
 
 **See Also:**
+
 - **[mk DX Style Guide](./mk-dx-style.md)** — Complete error taxonomy
 
 ---
@@ -807,6 +864,7 @@ Code: ERROR_CODE  Rerun: <exact command>
 The CLI suggests typo corrections using Levenshtein distance ≤ 2:
 
 **Unknown command:**
+
 ```bash
 $ mk rnu
 [ERR] UNKNOWN_COMMAND — Unknown command "rnu"
@@ -815,6 +873,7 @@ Fix: Run: mk --help
 ```
 
 **Unknown flag:**
+
 ```bash
 $ mk run --flie mk.json
 [ERR] INVALID_ARGUMENT — Unknown flag "--flie"
@@ -823,6 +882,7 @@ Fix: Run: mk run --help
 ```
 
 **See Also:**
+
 - **[mk DX Style Guide](./mk-dx-style.md#did-you-mean-pattern)** — Implementation details
 
 ---
@@ -830,6 +890,7 @@ Fix: Run: mk run --help
 ## Quick Reference Card
 
 **Complete workflow:**
+
 ```bash
 # Initialize project
 mk init hello-calculator --lang ts --preset tty
@@ -869,6 +930,7 @@ mk ci plan --output
 **Cause:** mk not in PATH or not built
 
 **Fix:**
+
 ```bash
 # Option 1: Use full path
 node /path/to/mkolbol/dist/scripts/mk.js --help
@@ -886,6 +948,7 @@ npm run build
 **Cause:** Wrong path or file doesn't exist
 
 **Fix:**
+
 ```bash
 # Check current directory
 ls -la mk.json
@@ -902,6 +965,7 @@ mk init --force
 **Cause:** Another process using the port
 
 **Fix:**
+
 ```bash
 # Find process
 lsof -i :4000
@@ -918,6 +982,7 @@ kill -9 <pid>
 **Cause:** Typo in module name or module not in registry
 
 **Fix:**
+
 ```bash
 # Check spelling in mk.json
 # "module": "CalculatorServer" (exact case)
diff --git a/docs/devex/distribution.md b/docs/devex/distribution.md
index 6baea05..a233bda 100644
--- a/docs/devex/distribution.md
+++ b/docs/devex/distribution.md
@@ -4,13 +4,13 @@ This guide helps you choose the right way to install and distribute mkolbol for
 
 ## Quick Reference
 
-| Installation Path | Use Case | Ease | Control | Network | Reproducibility |
-|-------------------|----------|------|---------|---------|-----------------|
-| **Tarball** (Recommended) | Early adopters, CI/CD, reproducible builds | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ❌ Offline | ⭐⭐⭐⭐⭐ |
-| **Git Tag** (Pinned) | Teams with git workflows, version tracking | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ✅ Required | ⭐⭐⭐⭐ |
-| **Vendor/Local** (Monorepo) | Same-repo development, zero dependencies | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ❌ Offline | ⭐⭐⭐⭐⭐ |
-| Local Dev (`npm link`) | Active development, debugging | ⭐⭐⭐⭐ | ⭐⭐⭐ | ✅ Required | ⭐⭐ |
-| GitHub Raw (`npm install github:...`) | Latest features, beta testing | ⭐⭐ | ⭐ | ✅ Required | ⭐ (cache issues) |
+| Installation Path                     | Use Case                                   | Ease       | Control    | Network     | Reproducibility   |
+| ------------------------------------- | ------------------------------------------ | ---------- | ---------- | ----------- | ----------------- |
+| **Tarball** (Recommended)             | Early adopters, CI/CD, reproducible builds | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ❌ Offline  | ⭐⭐⭐⭐⭐        |
+| **Git Tag** (Pinned)                  | Teams with git workflows, version tracking | ⭐⭐⭐     | ⭐⭐⭐⭐⭐ | ✅ Required | ⭐⭐⭐⭐          |
+| **Vendor/Local** (Monorepo)           | Same-repo development, zero dependencies   | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ❌ Offline  | ⭐⭐⭐⭐⭐        |
+| Local Dev (`npm link`)                | Active development, debugging              | ⭐⭐⭐⭐   | ⭐⭐⭐     | ✅ Required | ⭐⭐              |
+| GitHub Raw (`npm install github:...`) | Latest features, beta testing              | ⭐⭐       | ⭐         | ✅ Required | ⭐ (cache issues) |
 
 ---
 
@@ -81,6 +81,7 @@ npm install ./mkolbol-0.2.0.tgz
 #### Step 2: Reference in Your Project
 
 **In package.json:**
+
 ```json
 {
   "dependencies": {
@@ -90,6 +91,7 @@ npm install ./mkolbol-0.2.0.tgz
 ```
 
 **Then run:**
+
 ```bash
 npm install
 ```
@@ -159,6 +161,7 @@ Instead of using npm registry or tarballs, you pin a specific git tag directly.
 ```
 
 Then run:
+
 ```bash
 npm install
 ```
@@ -229,17 +232,16 @@ your-project/
 ### Setup with npm Workspaces
 
 **Root package.json:**
+
 ```json
 {
   "name": "my-workspace",
-  "workspaces": [
-    "packages/mkolbol",
-    "packages/my-app"
-  ]
+  "workspaces": ["packages/mkolbol", "packages/my-app"]
 }
 ```
 
 **packages/my-app/package.json:**
+
 ```json
 {
   "dependencies": {
@@ -251,6 +253,7 @@ your-project/
 ### Setup with Relative Paths
 
 **packages/my-app/package.json:**
+
 ```json
 {
   "dependencies": {
@@ -292,16 +295,16 @@ git subtree pull --prefix packages/mkolbol \
 
 ## 4. Comparison Table: When to Use Each
 
-| Scenario | Recommended | Why |
-|----------|-------------|-----|
-| First time, quick start | **Tarball** | Simple, reproducible, works offline after download |
-| Team CI/CD pipeline | **Tarball** | Stable, auditable, easy to cache |
-| Open source integration | **Git tag** | Keep in git history, easy to update |
-| Monorepo / same repo | **Vendor/Local** | Full control, no network needed |
-| Active development | **Vendor/Local** | Fast iteration, source visible |
-| Beta testing | **Git tag** or **Tarball** | Try latest features safely |
-| Production deployment | **Tarball** | Maximum reproducibility |
-| Air-gapped environment | **Tarball** or **Vendor** | Works offline |
+| Scenario                | Recommended                | Why                                                |
+| ----------------------- | -------------------------- | -------------------------------------------------- |
+| First time, quick start | **Tarball**                | Simple, reproducible, works offline after download |
+| Team CI/CD pipeline     | **Tarball**                | Stable, auditable, easy to cache                   |
+| Open source integration | **Git tag**                | Keep in git history, easy to update                |
+| Monorepo / same repo    | **Vendor/Local**           | Full control, no network needed                    |
+| Active development      | **Vendor/Local**           | Fast iteration, source visible                     |
+| Beta testing            | **Git tag** or **Tarball** | Try latest features safely                         |
+| Production deployment   | **Tarball**                | Maximum reproducibility                            |
+| Air-gapped environment  | **Tarball** or **Vendor**  | Works offline                                      |
 
 ---
 
@@ -420,6 +423,7 @@ npm install file:../packages/mkolbol
 **Problem**: Module appears in node_modules but can't be imported.
 
 **Solution**:
+
 ```bash
 # Verify extraction
 tar -tzf mkolbol-0.2.0.tar.gz | grep package.json
@@ -434,6 +438,7 @@ npm install ./mkolbol-0.2.0.tar.gz
 **Problem**: `npm install` uses cached version.
 
 **Solution**:
+
 ```bash
 # Clear npm cache
 npm cache clean --force
@@ -447,6 +452,7 @@ npm install
 **Problem**: `file:` path doesn't work in workspace.
 
 **Solution**:
+
 ```bash
 # Use workspaces in root package.json
 {
diff --git a/docs/devex/doctor.md b/docs/devex/doctor.md
index 6e8feb9..1ac9639 100644
--- a/docs/devex/doctor.md
+++ b/docs/devex/doctor.md
@@ -6,14 +6,14 @@ This guide helps diagnose and fix common issues with mkolbol development, mkctl
 
 ## Quick Fixes for Common Issues
 
-| Issue | Quick Fix |
-|-------|-----------|
+| Issue                     | Quick Fix                                                        |
+| ------------------------- | ---------------------------------------------------------------- |
 | **mk: command not found** | Add to PATH: `export PATH="/path/to/mkolbol/dist/scripts:$PATH"` |
-| **Permission denied** | Make executable: `chmod +x /path/to/mkolbol/dist/scripts/*.js` |
-| **Config file not found** | Use absolute path: `mk run --file $(pwd)/mk.json` |
-| **Port already in use** | Kill process: `lsof -i :4000 && kill -9 $(lsof -t -i :4000)` |
-| **Module not registered** | Check spelling: `mk doctor --file mk.json --verbose` |
-| **Node version < 20** | Upgrade: `nvm install 20 && nvm use 20` |
+| **Permission denied**     | Make executable: `chmod +x /path/to/mkolbol/dist/scripts/*.js`   |
+| **Config file not found** | Use absolute path: `mk run --file $(pwd)/mk.json`                |
+| **Port already in use**   | Kill process: `lsof -i :4000 && kill -9 $(lsof -t -i :4000)`     |
+| **Module not registered** | Check spelling: `mk doctor --file mk.json --verbose`             |
+| **Node version < 20**     | Upgrade: `nvm install 20 && nvm use 20`                          |
 
 ---
 
@@ -22,12 +22,14 @@ This guide helps diagnose and fix common issues with mkolbol development, mkctl
 ### Issue: mk, mkctl, or lam not found
 
 **Symptom:**
+
 ```bash
 $ mk --help
 bash: mk: command not found
 ```
 
 **Root cause:**
+
 - mk binaries not in PATH
 - mkolbol not built
 - Wrong directory
@@ -35,6 +37,7 @@ bash: mk: command not found
 **Fix (Linux/macOS):**
 
 **Option 1: Add to PATH (Recommended)**
+
 ```bash
 # 1. Find absolute path to mkolbol
 cd /path/to/mkolbol
@@ -59,6 +62,7 @@ mk --help       # → Shows mk help
 ```
 
 **Option 2: Symlink to /usr/local/bin**
+
 ```bash
 # Create symlinks (requires sudo)
 cd /path/to/mkolbol
@@ -75,6 +79,7 @@ mk --help       # → Shows mk help
 ```
 
 **Option 3: Wrapper Script**
+
 ```bash
 # Create ~/bin/mk wrapper
 mkdir -p ~/bin
@@ -97,6 +102,7 @@ mk --help       # → Shows mk help
 **Fix (Windows):**
 
 **Option 1: Add to PATH via System Properties**
+
 ```powershell
 # 1. Find mkolbol path
 cd C:\path\to\mkolbol
@@ -120,6 +126,7 @@ mk --help       # → Shows mk help
 ```
 
 **Option 2: Create .cmd Shims**
+
 ```powershell
 # Create mk.cmd in PATH directory
 @"
@@ -150,16 +157,19 @@ mk --help        # → Shows mk help
 ### Issue: Shims Broken After Moving mkolbol
 
 **Symptom:**
+
 ```bash
 $ mk --help
 /usr/local/bin/mk: No such file or directory
 ```
 
 **Root cause:**
+
 - mkolbol directory moved
 - Absolute symlinks point to old location
 
 **Fix:**
+
 ```bash
 # Remove old symlinks
 sudo rm /usr/local/bin/{mk,mkctl,lam}
@@ -183,16 +193,19 @@ mk --help       # → Shows mk help
 ### Issue: Multiple mk Versions in PATH
 
 **Symptom:**
+
 ```bash
 $ mk --help
 # Wrong version executing
 ```
 
 **Root cause:**
+
 - Multiple mk installations
 - PATH order prioritizes wrong version
 
 **Fix (Linux/macOS):**
+
 ```bash
 # Find all mk installations
 which -a mk
@@ -214,6 +227,7 @@ mk --version    # → Should show correct version
 ```
 
 **Fix (Windows):**
+
 ```powershell
 # Find all mk installations
 where.exe mk
@@ -235,16 +249,19 @@ mk --version
 ### Issue: Permission Denied on mk Scripts
 
 **Symptom:**
+
 ```bash
 $ mk --help
 bash: /path/to/mkolbol/dist/scripts/mk.js: Permission denied
 ```
 
 **Root cause:**
+
 - Scripts not executable
 - File permissions too restrictive
 
 **Fix (Linux/macOS):**
+
 ```bash
 # Make scripts executable
 chmod +x /path/to/mkolbol/dist/scripts/*.js
@@ -260,6 +277,7 @@ ls -la /path/to/mkolbol/dist/scripts/
 
 **Fix (Windows):**
 Windows doesn't require executable bit. Ensure you're running with `node`:
+
 ```powershell
 # Test direct execution
 node C:\path\to\mkolbol\dist\scripts\mk.js --help
@@ -273,18 +291,21 @@ node C:\path\to\mkolbol\dist\scripts\mk.js --help
 ### Issue: Node.js Not Found
 
 **Symptom:**
+
 ```bash
 $ mk --help
 /usr/bin/env: 'node': No such file or directory
 ```
 
 **Root cause:**
+
 - Node.js not installed
 - Node.js not in PATH
 
 **Fix:**
 
 **Linux (Ubuntu/Debian):**
+
 ```bash
 # Install Node 20+ via NodeSource
 curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
@@ -296,6 +317,7 @@ npm --version   # → 10.x.x
 ```
 
 **macOS:**
+
 ```bash
 # Install Node 20+ via Homebrew
 brew install node@20
@@ -309,6 +331,7 @@ node --version  # → v20.x.x
 ```
 
 **Windows:**
+
 ```powershell
 # Download installer from https://nodejs.org/
 # Run installer (includes Node.js and npm)
@@ -320,6 +343,7 @@ npm --version
 ```
 
 **Using nvm (Cross-platform):**
+
 ```bash
 # Install nvm
 curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
@@ -363,11 +387,13 @@ mk doctor [--verbose] [--section all|toolchain|environment] [--json]
 **Symptom**: `Configuration validation failed: Error reading file...`
 
 **Root causes**:
+
 - File path is incorrect or relative
 - File doesn't exist at the specified location
 - Directory path invalid
 
 **Fix**:
+
 ```bash
 # Use absolute path
 mkctl run --file $(pwd)/examples/configs/http-logs-local.yml --duration 10
@@ -386,12 +412,14 @@ pwd
 **Exit code**: `65`
 
 **Symptoms**:
+
 - `"nodes" must be an array`
 - `Duplicate node id 'xyz'`
 - `Connection from 'X' to non-existent node 'Y'`
 - `Unknown module 'XYZ'`
 
 **Root causes**:
+
 - YAML syntax error (indentation, colons, quotes)
 - Missing required fields
 - Invalid module names
@@ -399,6 +427,7 @@ pwd
 - Broken connections
 
 **Fix**:
+
 ```bash
 # 1. Validate YAML syntax
 python3 -m yaml examples/configs/http-logs-local.yml
@@ -423,6 +452,7 @@ mkctl run --file my-topology.yml --dry-run
 **Symptom**: `Health check failed for node 'X' after 3 attempts`
 
 **Root causes**:
+
 - External process doesn't start
 - Process doesn't listen on configured port
 - Health check URL/command wrong
@@ -430,6 +460,7 @@ mkctl run --file my-topology.yml --dry-run
 - Port already in use
 
 **Fix**:
+
 ```bash
 # 1. Test process manually
 node server.js &  # Start process
@@ -461,16 +492,19 @@ setTimeout(() => console.log('[startup] Ready'), 1000);
 **Exit code**: `70`
 
 **Symptom**:
+
 ```
 Error: listen EADDRINUSE: address already in use :::3000
 ```
 
 **Root causes**:
+
 - Previous topology still running
 - Different service using port
 - Port not released from previous crash
 
 **Fix**:
+
 ```bash
 # Find what's using the port
 lsof -i :3000
@@ -492,12 +526,14 @@ params:
 **Symptom**: `Unknown module 'MyCustomModule'`
 
 **Root causes**:
+
 - Module not registered in registry
 - Typo in module name
 - Module not imported/exported
 - Case mismatch (MyModule vs myModule)
 
 **Fix**:
+
 ```bash
 # 1. Verify built-in modules available
 mkctl run --file examples/configs/basic.yml --dry-run
@@ -530,6 +566,7 @@ mkctl run --file config.yml --dry-run
 ```
 
 **What it checks**:
+
 - ✓ Config file exists and is readable
 - ✓ YAML/JSON syntax is valid
 - ✓ All required fields present
@@ -539,12 +576,14 @@ mkctl run --file config.yml --dry-run
 - ✗ Does NOT check external processes or connectivity
 
 **Use cases**:
+
 - Pre-deployment validation
 - CI/CD pipeline checks
 - Config development iteration
 - Syntax verification before running
 
 **Exit codes**:
+
 - `0` — Config is valid
 - `65` — Config validation failed
 - `66` — Config file not found
@@ -597,11 +636,13 @@ done
 ### Error: "Permission denied"
 
 **Symptoms**:
+
 - Can't read config file
 - Can't write to logs/ directory
 - Can't execute external process
 
 **Fix**:
+
 ```bash
 # Check file ownership and permissions
 ls -la config/topology.yml
@@ -627,10 +668,12 @@ chown $USER:$USER config/ logs/
 ### Issue: Network features not disabled
 
 **Symptoms**:
+
 - Want to ensure only local mode is used
 - mkctl doesn't print "Running in Local Node mode"
 
 **Fix**:
+
 ```bash
 # Set environment variable before running
 export MK_LOCAL_NODE=1
@@ -647,10 +690,12 @@ mkctl run --file config.yml
 ### Issue: "Network features not available in local mode"
 
 **Symptoms**:
+
 - Config references `type=network` or `address` fields
 - Error: "Network addressing not allowed in Local Node mode"
 
 **Fix**:
+
 ```bash
 # Remove network config from topology
 # Replace:
@@ -675,9 +720,11 @@ nodes:
 ### Environment Checks
 
 #### 1. Node.js Version
+
 **Requirement**: Node.js 20 or later
 
 **Remediation**: If check fails:
+
 ```bash
 # Using nvm
 nvm install 20
@@ -687,9 +734,11 @@ nvm use 20
 ```
 
 #### 2. Package Manager
+
 **Requirement**: npm or pnpm installed
 
 **Remediation**: If check fails:
+
 ```bash
 # pnpm (recommended)
 npm install -g pnpm
@@ -698,25 +747,31 @@ npm install -g pnpm
 ```
 
 #### 3. Git Repository
+
 **Requirement**: Working in a Git repository (warning only)
 
 **Remediation**: If not detected:
+
 ```bash
 git init
 ```
 
 #### 4. Build Status
+
 **Requirement**: `dist/` directory with compiled files
 
 **Remediation**: If check fails:
+
 ```bash
 npm run build
 ```
 
 #### 5. Dependencies Installed
+
 **Requirement**: `node_modules/` directory exists
 
 **Remediation**: If check fails:
+
 ```bash
 npm install
 # or
@@ -724,9 +779,11 @@ pnpm install
 ```
 
 #### 6. TypeScript Compilation
+
 **Requirement**: No TypeScript type errors
 
 **Remediation**: If check fails:
+
 ```bash
 # See detailed errors
 npx tsc --noEmit
@@ -739,9 +796,11 @@ npm run build
 ### Toolchain Checks
 
 #### 7. Toolchain PATH Detection
+
 **Requirement**: `mk`, `mkctl`, and `lam` binaries available in PATH
 
 **Remediation**: If check fails:
+
 ```bash
 # Global install
 npm install -g .
@@ -752,40 +811,49 @@ export PATH="$PATH:~/.local/bin"
 ```
 
 #### 8. Shim Integrity
+
 **Requirement**: All binary shims exist and are executable in `dist/scripts/`
 
 **What it checks**:
+
 - `dist/scripts/mk.js` exists and is executable
 - `dist/scripts/mkctl.js` exists and is executable
 - `dist/scripts/lam.js` exists and is executable
 
 **Remediation**: If check fails:
+
 ```bash
 npm run build
 ```
 
 #### 9. mk Version Consistency
+
 **Requirement**: Binary version matches `package.json` version
 
 **What it checks**:
+
 - Reads version from `package.json`
 - Runs `mk --version` and compares output
 - Detects version mismatches from stale builds
 
 **Remediation**: If check fails:
+
 ```bash
 npm run build
 ```
 
 #### 10. Binary Accessibility
+
 **Requirement**: All binaries can be executed via `node dist/scripts/*.js`
 
 **What it checks**:
+
 - Tests actual execution of each binary
 - Verifies `--version` flag works
 - Detects runtime errors
 
 **Remediation**: If check fails:
+
 ```bash
 npm run build
 npm install
@@ -888,20 +956,25 @@ Use `mk doctor` in CI pipelines to validate environment:
 ## Troubleshooting
 
 ### "dist/ directory not found"
+
 Run `npm run build` to compile TypeScript sources.
 
 ### "node_modules/ not found"
+
 Run `npm install` to install dependencies.
 
 ### "Node.js version v18.x (< 20)"
+
 Upgrade to Node.js 20+ using nvm or download from nodejs.org.
 
 ### TypeScript compilation warnings
+
 Run `npx tsc --noEmit` to see detailed type errors, then fix them in your code.
 
 ## Future Enhancements
 
 Planned checks for future versions:
+
 - Port availability for services
 - Memory/CPU resources
 - External tool dependencies (git, docker)
diff --git a/docs/devex/early-adopter-guide.md b/docs/devex/early-adopter-guide.md
index da055a4..f381484 100644
--- a/docs/devex/early-adopter-guide.md
+++ b/docs/devex/early-adopter-guide.md
@@ -7,20 +7,26 @@ Welcome to mkolbol! This guide will get you up to speed in 5 minutes.
 **New to mkolbol?** Pick one of these entry points based on what you want to do:
 
 ### 🚀 **I want to see it in action** (5 min)
+
 Run a live topology demo without writing code:
+
 - **[Quickstart: mkctl run](./quickstart.md#quick-start-with-mkctl-recommended)** - Execute pre-built topologies from YAML
 - After it runs, inspect the RoutingServer snapshot with `mkctl endpoints`
 - **[Interactive Topology](./interactive-topology.md)** - Keyboard → PTY → Terminal demo
 - **[StdIO Path](./stdio-path.md)** - Non-interactive data pipeline (no terminal overhead)
 
 ### 🔨 **I want to build my first module** (20-30 min)
+
 Create and wire a custom server:
+
 - **[First Server Tutorial](./first-server-tutorial.md)** - Code your first Transform or External process
 - **[Wiring and Testing Guide](./wiring-and-tests.md)** - Configure topologies and test them
 - **[Acceptance Tests](./tests/devex/README.md)** - Validate your module works
 
 ### 🚢 **I want to deploy and observe** (15-20 min)
+
 Prepare modules for production:
+
 - **[Laminar Dev Workflow](./laminar-workflow.md)** - Test observability and debugging
 - **[Packaging Guide](./packaging.md)** - Bundle your modules into single executables
 - **[mkctl Cookbook](./mkctl-cookbook.md)** - Daily cheatsheet for `mkctl run` / `mkctl endpoints`
@@ -79,9 +85,9 @@ import { Kernel } from 'mkolbol';
 const kernel = new Kernel();
 
 // 2. Create modules (they create their own pipes via kernel)
-const timer = new TimerSource(kernel);    // Emits data periodically
-const upper = new UppercaseTransform(kernel);  // Transforms data
-const console = new ConsoleSink(kernel);  // Displays data
+const timer = new TimerSource(kernel); // Emits data periodically
+const upper = new UppercaseTransform(kernel); // Transforms data
+const console = new ConsoleSink(kernel); // Displays data
 
 // 3. Wire them up
 kernel.connect(timer.outputPipe, upper.inputPipe);
@@ -95,15 +101,16 @@ kernel.connect(upper.outputPipe, console.inputPipe);
 
 Every module falls into one of five categories:
 
-| Type | Purpose | Pipes | Examples |
-|------|---------|-------|----------|
-| **Input** | User input sources | Output only | KeyboardInput, VoiceInput, MCPInput |
-| **Source** | Bidirectional processes | Input + Output | PTY, DockerContainer, RemoteShell |
-| **Transform** | Process data in-flight | Input + Output | AnsiParser, Compressor, Encryptor |
-| **Output** | Display/record results | Input only | ScreenRenderer, MP4Recorder, Logger |
-| **Routing** | Manage multiple pipes | Many pipes | RoutingServer, LoadBalancer |
+| Type          | Purpose                 | Pipes          | Examples                            |
+| ------------- | ----------------------- | -------------- | ----------------------------------- |
+| **Input**     | User input sources      | Output only    | KeyboardInput, VoiceInput, MCPInput |
+| **Source**    | Bidirectional processes | Input + Output | PTY, DockerContainer, RemoteShell   |
+| **Transform** | Process data in-flight  | Input + Output | AnsiParser, Compressor, Encryptor   |
+| **Output**    | Display/record results  | Input only     | ScreenRenderer, MP4Recorder, Logger |
+| **Routing**   | Manage multiple pipes   | Many pipes     | RoutingServer, LoadBalancer         |
 
 **Example Flow**:
+
 ```
 KeyboardInput (input)
       ↓
@@ -128,15 +135,17 @@ Screen   Canvas  (both output)
 mkolbol supports four run modes, giving you flexibility for development, testing, and production:
 
 ### 1. inproc (In-Process)
+
 **What**: Module runs in the main Node.js process
 **When**: Development, lightweight transforms, minimal overhead
 **Tradeoff**: Fast but no isolation
 
 ```typescript
-const module = new UppercaseTransform(kernel);  // Runs in same process
+const module = new UppercaseTransform(kernel); // Runs in same process
 ```
 
 ### 2. worker (Worker Thread)
+
 **What**: Module runs in a separate V8 worker thread
 **When**: CPU-intensive work, need memory isolation, parallel processing
 **Tradeoff**: Some overhead, but isolated from main thread
@@ -147,6 +156,7 @@ nodes:
 ```
 
 ### 3. external (Process via stdio)
+
 **What**: Module runs as separate process, communicates over stdin/stdout
 **When**: Any executable, language-agnostic, maximum isolation
 **Tradeoff**: Process startup cost, but can use Python, Go, Rust, etc.
@@ -160,6 +170,7 @@ nodes:
 ```
 
 ### 4. pty (Pseudo-Terminal)
+
 **What**: Module runs as PTY process with terminal emulation
 **When**: Interactive shells, terminal applications, hijacking terminal I/O
 **Tradeoff**: Full terminal semantics, ANSI escape sequences
@@ -226,17 +237,19 @@ Legend:
 These three components work together to manage your system:
 
 ### Executor
+
 Orchestrates module lifecycle: load config → instantiate modules → wire connections → start/stop
 
 ```typescript
 const executor = new Executor(kernel, hostess, stateManager);
-executor.load(topologyConfig);  // Load YAML/JSON config
-await executor.up();             // Start all modules
+executor.load(topologyConfig); // Load YAML/JSON config
+await executor.up(); // Start all modules
 // ... system runs ...
-await executor.down();           // Graceful shutdown
+await executor.down(); // Graceful shutdown
 ```
 
 ### StateManager
+
 Tracks topology (nodes, connections) and emits events for HMI/monitoring
 
 ```typescript
@@ -249,6 +262,7 @@ stateManager.on('connected', ({ from, to }) => {
 ```
 
 ### Hostess
+
 Service registry with heartbeat monitoring and capability-based discovery
 
 ```typescript
@@ -302,23 +316,24 @@ npx lam trends --top 10
 ### Artifacts in CI
 
 GitHub Actions uploads two artifact bundles per Node version:
+
 - `laminar-reports-node-XX` - Contains `summary.jsonl`, case logs, digests
 - Download from the [Actions tab](https://github.com/anteew/mkolbol/actions)
 
 ## Glossary
 
-| Term | Definition |
-|------|------------|
-| **Kernel** | ~100 line core providing pipes, connections, and registry |
-| **Pipe** | Bidirectional data channel (Node.js Duplex stream) |
-| **Module** | Functional unit with input/output pipes (all semantics live here) |
-| **Executor** | Lifecycle manager: loads config, instantiates modules, manages start/stop |
-| **StateManager** | Topology tracker and event emitter for monitoring |
-| **Hostess** | Service registry with heartbeat and capability-based discovery |
-| **Run Mode** | Execution environment: inproc, worker, external, or pty |
-| **Endpoint** | Addressable module instance with type, coordinates, and metadata |
-| **Topology** | Configuration of nodes and connections (YAML/JSON) |
-| **Laminar** | Test observability framework with structured logging (JSONL) |
+| Term             | Definition                                                                |
+| ---------------- | ------------------------------------------------------------------------- |
+| **Kernel**       | ~100 line core providing pipes, connections, and registry                 |
+| **Pipe**         | Bidirectional data channel (Node.js Duplex stream)                        |
+| **Module**       | Functional unit with input/output pipes (all semantics live here)         |
+| **Executor**     | Lifecycle manager: loads config, instantiates modules, manages start/stop |
+| **StateManager** | Topology tracker and event emitter for monitoring                         |
+| **Hostess**      | Service registry with heartbeat and capability-based discovery            |
+| **Run Mode**     | Execution environment: inproc, worker, external, or pty                   |
+| **Endpoint**     | Addressable module instance with type, coordinates, and metadata          |
+| **Topology**     | Configuration of nodes and connections (YAML/JSON)                        |
+| **Laminar**      | Test observability framework with structured logging (JSONL)              |
 
 ## Packaging Walkthrough: Bundle Your First Module
 
@@ -339,7 +354,8 @@ cat scripts/build-bundle.mjs
 ```
 
 This script:
-- Takes your TypeScript source (src/*.ts)
+
+- Takes your TypeScript source (src/\*.ts)
 - Resolves all dependencies (mkolbol kernel, node_modules)
 - Bundles into a single JavaScript file
 - Produces `dist/runner.js` - your distributable executable
@@ -355,6 +371,7 @@ node scripts/build-bundle.mjs
 ```
 
 Expected output:
+
 ```
 ✓ Bundled successfully
 ✓ Output: dist/runner.js
@@ -371,6 +388,7 @@ node dist/runner.js --file ./my-config.yml --duration 10
 ```
 
 Your bundled application runs identically to the source:
+
 - Same module wiring
 - Same configuration loading
 - Same Laminar observability (if enabled)
@@ -395,16 +413,19 @@ See **[Laminar Workflow Guide](./laminar-workflow.md)** for complete observabili
 ### Bundling Tips
 
 **Size optimization:**
+
 - Use esbuild's `--minify` flag to reduce bundle size
 - Tree-shake unused dependencies with `--platform=node`
 - Consider splitting bundles if they exceed 50MB
 
 **Runtime configuration:**
+
 - Store configs in `/etc/myapp/` or `$XDG_CONFIG_HOME`
 - Pass config path as CLI argument (see `dist/runner.js --help`)
 - Embed default config in the bundle as fallback
 
 **Reproducible builds:**
+
 - Pin all versions in `package-lock.json`
 - Store the bundle script in version control
 - Document any environment variables required at runtime
@@ -441,6 +462,7 @@ npm run dev:merge   # Fan-in example
 See the **Quick Start: Choose Your Path** section near the top of this guide to pick your entry point. Each path includes links to everything you need.
 
 **Not sure which path?** Here's how to decide:
+
 - **Just want to explore?** → Choose **"I want to see it in action"**
 - **Ready to code?** → Choose **"I want to build my first module"**
 - **Building something real?** → Choose **"I want to deploy and observe"**
diff --git a/docs/devex/first-five-minutes.md b/docs/devex/first-five-minutes.md
index 5f7a19c..5c58c95 100644
--- a/docs/devex/first-five-minutes.md
+++ b/docs/devex/first-five-minutes.md
@@ -11,6 +11,7 @@ Welcome to mkolbol! This guide shows you the complete developer workflow from pr
 ## What You'll Build
 
 By the end of this guide, you'll have:
+
 - ✅ A working mkolbol project (hello-calculator topology)
 - ✅ Validated configuration with `mk doctor`
 - ✅ Both JSON and YAML workflow experience
@@ -18,6 +19,7 @@ By the end of this guide, you'll have:
 - ✅ Production-ready GitHub Actions CI config
 
 **The mk workflow chain:**
+
 ```
 mk init → mk run → mk doctor → mk format → mk run --yaml → mk build → mk package → mk ci plan
 ```
@@ -54,6 +56,7 @@ node dist/scripts/mk.js init hello-calculator --lang ts --preset tty
 ```
 
 **What happens:**
+
 1. Creates `hello-calculator/` directory
 2. Generates `mk.json` with 3-node topology (CalculatorServer → XtermTTYRenderer → FilesystemSink)
 3. Creates `.mk/options.json` with dev/ci/release profiles
@@ -61,6 +64,7 @@ node dist/scripts/mk.js init hello-calculator --lang ts --preset tty
 5. Adds `package.json`, `.gitignore`, `README.md`
 
 **Verify it worked:**
+
 ```bash
 cd hello-calculator
 ls -la
@@ -79,6 +83,7 @@ node ../dist/scripts/mk.js run --file mk.json --duration 10
 ```
 
 **Expected output:**
+
 ```
 [mk] Running in Local Node mode (MK_LOCAL_NODE=1): network features disabled.
 [mk] Loading config from: mk.json
@@ -90,11 +95,13 @@ node ../dist/scripts/mk.js run --file mk.json --duration 10
 ```
 
 **What's happening:**
+
 1. CalculatorServer starts on port 4000
 2. XtermTTYRenderer displays live output
 3. FilesystemSink logs to `logs/calculator.jsonl`
 
 **Test it:**
+
 ```bash
 # In another terminal
 curl -s "http://localhost:4000/add?a=5&b=3"
@@ -112,6 +119,7 @@ node ../dist/scripts/mk.js doctor --file mk.json
 ```
 
 **Expected output:**
+
 ```
 [✓] Config file valid (mk.json)
 [✓] All modules registered (CalculatorServer, XtermTTYRenderer, FilesystemSink)
@@ -125,6 +133,7 @@ node ../dist/scripts/mk.js doctor --file mk.json
 ```
 
 **What doctor checks:**
+
 - Config syntax and schema validation
 - Module existence in registry
 - Port conflicts
@@ -133,6 +142,7 @@ node ../dist/scripts/mk.js doctor --file mk.json
 - Resource limits
 
 **If you see errors:**
+
 ```bash
 # Dry-run to see what would happen
 node ../dist/scripts/mk.js doctor --file mk.json --dry-run
@@ -154,6 +164,7 @@ node ../dist/scripts/mk.js format --to yaml mk.json
 ```
 
 **Creates `mk.yaml`:**
+
 ```yaml
 nodes:
   - id: calculator
@@ -182,17 +193,20 @@ connections:
 ```
 
 **Run with YAML:**
+
 ```bash
 node ../dist/scripts/mk.js run --file mk.yaml --duration 10
 ```
 
 **Why YAML?**
+
 - More concise (no quotes on most values)
 - Comments supported (`# This is a comment`)
 - Multi-line strings easier
 - Industry standard for config
 
 **Switch back anytime:**
+
 ```bash
 node ../dist/scripts/mk.js format --to json mk.yaml
 ```
@@ -208,6 +222,7 @@ node ../dist/scripts/mk.js build
 ```
 
 **What happens:**
+
 1. Compiles `src/index.ts` → `dist/index.js`
 2. Bundles dependencies (if configured)
 3. Generates `dist/manifest.json` with provenance:
@@ -224,12 +239,14 @@ node ../dist/scripts/mk.js build
 4. Creates `dist/mk.json` (normalized config)
 
 **Verify:**
+
 ```bash
 ls -la dist/
 # dist/index.js, dist/manifest.json, dist/mk.json
 ```
 
 **Build targets:**
+
 ```bash
 # Production build (minified)
 node ../dist/scripts/mk.js build --target production
@@ -251,6 +268,7 @@ node ../dist/scripts/mk.js package
 **Output: `hello-calculator-0.1.0.tgz`**
 
 **What's included:**
+
 ```
 hello-calculator-0.1.0.tgz
 ├── dist/                 # Compiled artifacts
@@ -262,6 +280,7 @@ hello-calculator-0.1.0.tgz
 ```
 
 **Install the package elsewhere:**
+
 ```bash
 # Copy to another machine
 scp hello-calculator-0.1.0.tgz remote:/tmp/
@@ -275,6 +294,7 @@ node ../dist/scripts/mk.js run --file mk.json
 ```
 
 **Package options:**
+
 ```bash
 # Sign with GPG
 node ../dist/scripts/mk.js package --sign
@@ -294,6 +314,7 @@ node ../dist/scripts/mk.js ci plan --output
 ```
 
 **Creates `.github/workflows/test.yml`:**
+
 ```yaml
 name: Tests
 
@@ -339,6 +360,7 @@ jobs:
 ```
 
 **With Laminar integration:**
+
 ```bash
 node ../dist/scripts/mk.js ci plan --output --with-laminar
 ```
@@ -346,6 +368,7 @@ node ../dist/scripts/mk.js ci plan --output --with-laminar
 Adds Laminar test observability (see [CI Acceptance Smoke](./ci-acceptance-smoke.md#mk-ci-plan-command)).
 
 **Test locally:**
+
 ```bash
 # Generate plan JSON
 node ../dist/scripts/mk.js ci plan
@@ -363,13 +386,13 @@ echo $MATRIX_NODE  # ["20", "24"]
 
 ### Immediate Next Steps
 
-| If you want to... | Go here... |
-|-------------------|-----------|
-| **Iterate faster with hot reload** | [mk dev, logs, trace Guide](./mk-dev-logs-trace.md) - Development ergonomics |
-| **Write custom modules** | [Authoring a Module](./authoring-a-module.md) - Complete guide with test patterns |
-| **Understand architecture** | [Early Adopter Guide](./early-adopter-guide.md) - Core concepts and mental models |
-| **Use curated patterns** | [Recipes](./recipes.md) - 9 copy-paste topologies for common use cases |
-| **Troubleshoot issues** | [Doctor Guide](./doctor.md) - Common errors and fixes |
+| If you want to...                  | Go here...                                                                        |
+| ---------------------------------- | --------------------------------------------------------------------------------- |
+| **Iterate faster with hot reload** | [mk dev, logs, trace Guide](./mk-dev-logs-trace.md) - Development ergonomics      |
+| **Write custom modules**           | [Authoring a Module](./authoring-a-module.md) - Complete guide with test patterns |
+| **Understand architecture**        | [Early Adopter Guide](./early-adopter-guide.md) - Core concepts and mental models |
+| **Use curated patterns**           | [Recipes](./recipes.md) - 9 copy-paste topologies for common use cases            |
+| **Troubleshoot issues**            | [Doctor Guide](./doctor.md) - Common errors and fixes                             |
 
 ### Production Workflows
 
@@ -389,17 +412,18 @@ echo $MATRIX_NODE  # ["20", "24"]
 
 ### Common Issues
 
-| Error | Cause | Fix |
-|-------|-------|-----|
-| **mk: command not found** | Script not built or wrong path | Run: `npm run build` from mkolbol repo root |
-| **Config file not found** | Wrong relative path | Use `../dist/scripts/mk.js` from project directory |
-| **Port already in use** | Another process on port 4000 | Check: `lsof -i :4000` and kill process |
-| **Module not registered** | Module name typo in mk.json | Run: `node ../dist/scripts/mk.js doctor --file mk.json` |
-| **Permission denied (logs/)** | Log directory not writable | Run: `mkdir -p logs && chmod 755 logs` |
+| Error                         | Cause                          | Fix                                                     |
+| ----------------------------- | ------------------------------ | ------------------------------------------------------- |
+| **mk: command not found**     | Script not built or wrong path | Run: `npm run build` from mkolbol repo root             |
+| **Config file not found**     | Wrong relative path            | Use `../dist/scripts/mk.js` from project directory      |
+| **Port already in use**       | Another process on port 4000   | Check: `lsof -i :4000` and kill process                 |
+| **Module not registered**     | Module name typo in mk.json    | Run: `node ../dist/scripts/mk.js doctor --file mk.json` |
+| **Permission denied (logs/)** | Log directory not writable     | Run: `mkdir -p logs && chmod 755 logs`                  |
 
 ### Quick Fixes
 
 **"mk init fails"**
+
 ```bash
 # Check if directory already exists
 ls -la hello-calculator/
@@ -410,6 +434,7 @@ node dist/scripts/mk.js init hello-calculator
 ```
 
 **"mk build fails"**
+
 ```bash
 # Check TypeScript compilation
 npx tsc --noEmit
@@ -422,6 +447,7 @@ node ../dist/scripts/mk.js build --verbose
 ```
 
 **"mk package fails"**
+
 ```bash
 # Build first
 node ../dist/scripts/mk.js build
@@ -444,6 +470,7 @@ node ../dist/scripts/mk.js package
 ## Quick Reference Card
 
 **Complete workflow (from mkolbol repo):**
+
 ```bash
 # Initialize project
 node dist/scripts/mk.js init hello-calculator --lang ts --preset tty
@@ -472,6 +499,7 @@ node ../dist/scripts/mk.js ci plan --output
 ```
 
 **Common flags:**
+
 ```bash
 --file <path>          # Config file (mk.json or mk.yaml)
 --duration <seconds>   # How long to run topology
@@ -487,6 +515,7 @@ node ../dist/scripts/mk.js ci plan --output
 **Time spent:** 10 minutes ⏱️
 
 **What you learned:**
+
 - ✅ Initialize mkolbol projects with `mk init`
 - ✅ Run and validate topologies with `mk run` and `mk doctor`
 - ✅ Convert configs between JSON and YAML with `mk format`
diff --git a/docs/devex/first-server-tutorial.md b/docs/devex/first-server-tutorial.md
index ef7ec23..b64d153 100644
--- a/docs/devex/first-server-tutorial.md
+++ b/docs/devex/first-server-tutorial.md
@@ -11,10 +11,10 @@ This tutorial teaches you how to create your first custom server module for mkol
 
 ## Two Paths to Choose From
 
-| Path | Best For | Complexity | Language | Isolation |
-|------|----------|------------|----------|-----------|
-| **Transform (inproc)** | TypeScript/JavaScript, fast iteration, minimal overhead | Simple | TypeScript/JS only | None (same process) |
-| **External (process)** | Any language, maximum isolation, existing CLI tools | Medium | Any (Python, Go, Rust, etc.) | Full (separate process) |
+| Path                   | Best For                                                | Complexity | Language                     | Isolation               |
+| ---------------------- | ------------------------------------------------------- | ---------- | ---------------------------- | ----------------------- |
+| **Transform (inproc)** | TypeScript/JavaScript, fast iteration, minimal overhead | Simple     | TypeScript/JS only           | None (same process)     |
+| **External (process)** | Any language, maximum isolation, existing CLI tools     | Medium     | Any (Python, Go, Rust, etc.) | Full (separate process) |
 
 **Recommendation**: Start with Transform for learning, switch to External when you need multi-language support or process isolation.
 
@@ -69,14 +69,12 @@ export class UppercaseTransform {
       objectMode: true,
       transform(chunk, _encoding, callback) {
         // Convert chunk to string
-        const text = typeof chunk === 'string'
-          ? chunk
-          : chunk.toString('utf8');
+        const text = typeof chunk === 'string' ? chunk : chunk.toString('utf8');
 
         // Transform and pass along
         const uppercased = text.toUpperCase();
         callback(null, uppercased);
-      }
+      },
     });
 
     // Wire internal pipeline: inputPipe -> transformer -> outputPipe
@@ -100,7 +98,7 @@ export class UppercaseTransform {
 
   constructor(
     private kernel: Kernel,
-    private hostess?: Hostess
+    private hostess?: Hostess,
   ) {
     this.inputPipe = kernel.createPipe({ objectMode: true });
     this.outputPipe = kernel.createPipe({ objectMode: true });
@@ -110,7 +108,7 @@ export class UppercaseTransform {
       transform(chunk, _encoding, callback) {
         const text = typeof chunk === 'string' ? chunk : chunk.toString('utf8');
         callback(null, text.toUpperCase());
-      }
+      },
     });
 
     this.inputPipe.pipe(transformer).pipe(this.outputPipe);
@@ -131,18 +129,18 @@ export class UppercaseTransform {
       owner: 'user',
       terminals: [
         { name: 'input', type: 'local', direction: 'input' },
-        { name: 'output', type: 'local', direction: 'output' }
+        { name: 'output', type: 'local', direction: 'output' },
       ],
       capabilities: {
         type: 'transform',
         accepts: ['text', 'string'],
         produces: ['text', 'string'],
-        features: ['uppercase', 'text-transform']
+        features: ['uppercase', 'text-transform'],
       },
       metadata: {
         description: 'Converts text to uppercase',
-        version: '1.0.0'
-      }
+        version: '1.0.0',
+      },
     });
 
     this.serverId = this.hostess.register(manifest);
@@ -198,7 +196,7 @@ async function main() {
   upper.inputPipe.write('this is a test');
 
   // Cleanup
-  await new Promise(resolve => setTimeout(resolve, 100));
+  await new Promise((resolve) => setTimeout(resolve, 100));
   upper.shutdown();
 }
 
@@ -254,11 +252,14 @@ async function main() {
   source.emit('mkolbol is awesome');
 
   // Wait for processing
-  await new Promise(resolve => setTimeout(resolve, 100));
+  await new Promise((resolve) => setTimeout(resolve, 100));
 
   // Query Hostess
   const transforms = hostess.query({ type: 'transform', accepts: 'text' });
-  console.log('Found transforms:', transforms.map(e => e.servername));
+  console.log(
+    'Found transforms:',
+    transforms.map((e) => e.servername),
+  );
 
   transform.shutdown();
 }
@@ -267,6 +268,7 @@ main().catch(console.error);
 ```
 
 **Expected Output:**
+
 ```
 [UppercaseTransform] Registered with Hostess: localhost:uppercase-transform:0x1001:user:no:none:...
 [ConsoleSink] HELLO WORLD
@@ -318,6 +320,7 @@ if __name__ == '__main__':
 ```
 
 Make it executable:
+
 ```bash
 chmod +x scripts/echo-server.py
 ```
@@ -348,13 +351,13 @@ export class SimpleEchoWrapper extends ExternalServerWrapper {
       terminals: [
         { name: 'input', type: 'local', direction: 'input' },
         { name: 'output', type: 'local', direction: 'output' },
-        { name: 'error', type: 'local', direction: 'output' }
+        { name: 'error', type: 'local', direction: 'output' },
       ],
       capabilities: {
         type: 'transform',
         accepts: ['text'],
         produces: ['text'],
-        features: ['echo', 'python']
+        features: ['echo', 'python'],
       },
       command: 'python3',
       args: [path.resolve(process.cwd(), 'scripts/echo-server.py')],
@@ -363,7 +366,7 @@ export class SimpleEchoWrapper extends ExternalServerWrapper {
       ioMode: 'stdio',
       restart: 'on-failure',
       restartDelay: 1000,
-      maxRestarts: 3
+      maxRestarts: 3,
     };
 
     super(kernel, hostess, manifest);
@@ -417,7 +420,7 @@ async function main() {
   echo.inputPipe.write('This is line 2\n');
 
   // Wait for processing
-  await new Promise(resolve => setTimeout(resolve, 500));
+  await new Promise((resolve) => setTimeout(resolve, 500));
 
   // Graceful shutdown
   await echo.shutdown();
@@ -428,6 +431,7 @@ main().catch(console.error);
 ```
 
 **Expected Output:**
+
 ```
 Stderr: [SimpleEcho] Starting up...
 Output: [ECHO] Hello from TypeScript
@@ -481,11 +485,14 @@ async function main() {
   source.emit('test message 1');
   source.emit('test message 2');
 
-  await new Promise(resolve => setTimeout(resolve, 500));
+  await new Promise((resolve) => setTimeout(resolve, 500));
 
   // Query Hostess
   const pythonModules = hostess.query({ features: ['python'] });
-  console.log('Python modules:', pythonModules.map(e => e.servername));
+  console.log(
+    'Python modules:',
+    pythonModules.map((e) => e.servername),
+  );
 
   await echo.shutdown();
 }
@@ -521,6 +528,7 @@ cat reports/endpoints.json
 ```
 
 Example:
+
 ```json
 [
   {
@@ -590,6 +598,7 @@ After creating your module, verify it works:
 - [ ] `shutdown()` cleans up resources
 
 **Test command:**
+
 ```bash
 npm run build
 node dist/your-test-file.js
@@ -610,6 +619,7 @@ node dist/your-test-file.js
 - [ ] Restart policy works (test by killing the process)
 
 **Test command:**
+
 ```bash
 npm run build
 node dist/your-test-file.js
@@ -668,7 +678,7 @@ export class ReverseTransform {
         const text = typeof chunk === 'string' ? chunk : chunk.toString('utf8');
         const reversed = text.split('').reverse().join('');
         cb(null, reversed);
-      }
+      },
     });
 
     this.inputPipe.pipe(transformer).pipe(this.outputPipe);
@@ -679,6 +689,7 @@ export class ReverseTransform {
 ### External Module: WordCount (Bash)
 
 **File: `scripts/word-count.sh`**
+
 ```bash
 #!/bin/bash
 echo "[WordCount] Starting..." >&2
@@ -692,6 +703,7 @@ echo "[WordCount] Stopping..." >&2
 ```
 
 **File: `src/modules/WordCountWrapper.ts`**
+
 ```typescript
 import { Kernel, Hostess, ExternalServerWrapper } from 'mkolbol';
 import type { ExternalServerManifest } from 'mkolbol/types';
@@ -709,13 +721,13 @@ export class WordCountWrapper extends ExternalServerWrapper {
       terminals: [
         { name: 'input', type: 'local', direction: 'input' },
         { name: 'output', type: 'local', direction: 'output' },
-        { name: 'error', type: 'local', direction: 'output' }
+        { name: 'error', type: 'local', direction: 'output' },
       ],
       capabilities: {
         type: 'transform',
         accepts: ['text'],
         produces: ['text'],
-        features: ['word-count', 'bash']
+        features: ['word-count', 'bash'],
       },
       command: path.resolve(process.cwd(), 'scripts/word-count.sh'),
       args: [],
@@ -724,7 +736,7 @@ export class WordCountWrapper extends ExternalServerWrapper {
       ioMode: 'stdio',
       restart: 'on-failure',
       restartDelay: 1000,
-      maxRestarts: 3
+      maxRestarts: 3,
     };
 
     super(kernel, hostess, manifest);
@@ -739,6 +751,7 @@ export class WordCountWrapper extends ExternalServerWrapper {
 After building your module programmatically, you can also load it from YAML/JSON configuration files using the ConfigLoader and Executor.
 
 See **[Wiring and Testing](./wiring-and-tests.md)** guide for:
+
 - How to write topology configs with external processes
 - Both `stdio` and `pty` I/O modes
 - Running tests in threads vs forks lanes
diff --git a/docs/devex/hello-calculator.md b/docs/devex/hello-calculator.md
index bf740e8..03cd498 100644
--- a/docs/devex/hello-calculator.md
+++ b/docs/devex/hello-calculator.md
@@ -12,6 +12,7 @@ Number Generator → Calculator → Display Results
 ```
 
 **Time breakdown:**
+
 - 2 min: Create project structure
 - 3 min: Write the calculator logic
 - 2 min: Create config file
@@ -31,6 +32,7 @@ npm init -y
 ### Install mkolbol (Recommended: Tarball)
 
 **Tarball (Reproducible, Recommended):**
+
 ```bash
 # Local tarball from this repo
 git clone https://github.com/anteew/mkolbol.git
@@ -39,6 +41,7 @@ cd - && npm install ./mkolbol/mkolbol-*.tgz
 ```
 
 **Or from Git tag:**
+
 ```bash
 npm install github:anteew/mkolbol#v0.2.0
 ```
@@ -141,12 +144,12 @@ nodes:
   - id: generator
     module: TimerSource
     params:
-      periodMs: 1000  # Emit every 1 second
+      periodMs: 1000 # Emit every 1 second
 
   - id: display
     module: ConsoleSink
     params:
-      prefix: "[calc]"
+      prefix: '[calc]'
 
 connections:
   - from: generator.output
@@ -170,6 +173,7 @@ npx mkctl run --file config/calculator.yml --duration 10
 ```
 
 **Expected output:**
+
 ```
 [calc] tick
 [calc] tick
@@ -202,7 +206,7 @@ nodes:
   - id: display
     module: ConsoleSink
     params:
-      prefix: "[result]"
+      prefix: '[result]'
 
 connections:
   - from: generator.output
@@ -229,6 +233,7 @@ npx mkctl run --file config/calculator.yml --duration 10
 ```
 
 **Expected output:**
+
 ```
 [result] tick → 10 (operation #1)
 [result] tick → 20 (operation #2)
@@ -245,6 +250,7 @@ params:
 ```
 
 Output:
+
 ```
 [result] tick → tick squared
 [result] tick → tick squared
@@ -312,6 +318,7 @@ connections:
 Here's the full calculator module for reference:
 
 **src/calculator.ts**
+
 ```typescript
 import { Kernel } from 'mkolbol';
 
@@ -373,6 +380,7 @@ export class Calculator {
 ```
 
 **config/calculator.yml**
+
 ```yaml
 nodes:
   - id: generator
@@ -389,7 +397,7 @@ nodes:
   - id: display
     module: ConsoleSink
     params:
-      prefix: "[result]"
+      prefix: '[result]'
 
 connections:
   - from: generator.output
@@ -399,6 +407,7 @@ connections:
 ```
 
 **package.json**
+
 ```json
 {
   "name": "hello-calculator",
diff --git a/docs/devex/installation.md b/docs/devex/installation.md
index 872f503..b925bc9 100644
--- a/docs/devex/installation.md
+++ b/docs/devex/installation.md
@@ -7,10 +7,12 @@
 ## Overview
 
 mkolbol provides two primary CLI tools:
+
 - **mk** - Developer orchestrator (init, run, doctor, build, package, ci plan)
 - **mkctl** - Microkernel control (run topologies, inspect endpoints)
 
 This guide shows you how to:
+
 1. Install mkolbol using tarball, git tag, or vendor paths (no npm registry)
 2. Configure your system for "mk anywhere" usage
 3. Troubleshoot common installation issues
@@ -39,6 +41,7 @@ tar -xzf mkolbol-0.2.0.tgz -C /opt/mkolbol
 ```
 
 **Verify:**
+
 ```bash
 ls -la node_modules/mkolbol/dist/scripts/
 # Should see mk.js and mkctl.js
@@ -129,12 +132,14 @@ mkctl --help    # → Shows mkctl help
 ```
 
 **For zsh users:**
+
 ```bash
 echo "export PATH=\"$MKOLBOL_PATH/dist/scripts:\$PATH\"" >> ~/.zshrc
 source ~/.zshrc
 ```
 
 **For fish users:**
+
 ```fish
 set -Ux fish_user_paths /path/to/mkolbol/dist/scripts $fish_user_paths
 ```
@@ -156,11 +161,13 @@ mk --help       # → Shows mk help
 ```
 
 **Pros:**
+
 - No shell config changes needed
 - Works for all users on the system
 - Clean separation of system binaries
 
 **Cons:**
+
 - Requires sudo/root access
 - Manual updates when mkolbol moves
 
@@ -197,6 +204,7 @@ mk --help       # → Shows mk help
 #### Option 1: Add to PATH via System Properties (GUI)
 
 1. **Find mkolbol path:**
+
    ```powershell
    cd C:\path\to\mkolbol
    pwd
@@ -320,6 +328,7 @@ rm -rf test-project
 **Cause:** PATH not updated or shell not reloaded
 
 **Fix (Linux/macOS):**
+
 ```bash
 # Check if PATH includes mkolbol
 echo $PATH | grep mkolbol
@@ -332,6 +341,7 @@ source ~/.bashrc  # or source ~/.zshrc
 ```
 
 **Fix (Windows):**
+
 ```powershell
 # Check if PATH includes mkolbol
 $env:Path -split ';' | Select-String mkolbol
@@ -349,6 +359,7 @@ exit
 **Cause:** Script not executable (Linux/macOS only)
 
 **Fix:**
+
 ```bash
 chmod +x /path/to/mkolbol/dist/scripts/*.js
 ```
@@ -358,6 +369,7 @@ chmod +x /path/to/mkolbol/dist/scripts/*.js
 **Cause:** Multiple mk installations in PATH
 
 **Fix (Linux/macOS):**
+
 ```bash
 # Find all mk installations
 which -a mk
@@ -370,6 +382,7 @@ export PATH="/correct/path/to/mkolbol/dist/scripts:$PATH"
 ```
 
 **Fix (Windows):**
+
 ```powershell
 # Find all mk installations
 where.exe mk
@@ -383,6 +396,7 @@ where.exe mk
 **Cause:** Node not installed or not in PATH
 
 **Fix:**
+
 ```bash
 # Install Node 20+ (Ubuntu/Debian)
 curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
@@ -396,6 +410,7 @@ brew install node@20
 ```
 
 **Verify:**
+
 ```bash
 node --version  # Should be v20.x or v24.x
 npm --version
@@ -406,6 +421,7 @@ npm --version
 **Cause:** Build failed or incomplete
 
 **Fix:**
+
 ```bash
 cd /path/to/mkolbol
 
@@ -424,6 +440,7 @@ ls -la dist/scripts/
 **Cause:** Absolute symlinks point to old location
 
 **Fix:**
+
 ```bash
 # Remove old symlinks
 sudo rm /usr/local/bin/mk /usr/local/bin/mkctl
@@ -439,6 +456,7 @@ sudo ln -s "$(pwd)/dist/scripts/mkctl.js" /usr/local/bin/mkctl
 **Cause:** Node path not absolute or spaces in path
 
 **Fix:**
+
 ```powershell
 # Get Node path
 where.exe node  # → C:\Program Files\nodejs\node.exe
diff --git a/docs/devex/interactive-topology.md b/docs/devex/interactive-topology.md
index 5a8312f..1e91dc0 100644
--- a/docs/devex/interactive-topology.md
+++ b/docs/devex/interactive-topology.md
@@ -30,6 +30,7 @@ The **Interactive Topology** pattern in mkolbol enables bidirectional communicat
 ```
 
 The topology creates a real-time interactive loop:
+
 1. **Keyboard** captures raw keystrokes from `process.stdin`
 2. **PTY** executes commands in a pseudo-terminal environment
 3. **TTY** renders ANSI-formatted output to `process.stdout`
@@ -37,6 +38,7 @@ The topology creates a real-time interactive loop:
 ## When to Use Interactive Topology
 
 ### Use Interactive Topology when:
+
 - Building terminal emulators or terminal UI applications
 - Creating AI-assisted shells with observability
 - Implementing collaborative terminal sessions
@@ -45,6 +47,7 @@ The topology creates a real-time interactive loop:
 - Building custom REPL environments
 
 ### Alternatives:
+
 - **StdIO Path**: For non-interactive filters and data pipelines (see [stdio-path.md](./stdio-path.md))
 - **HTTP/WebSocket**: For network-based terminal access
 - **Worker Threads**: For CPU-intensive background tasks without I/O
@@ -73,6 +76,7 @@ keyboard.start();
 ```
 
 **Features:**
+
 - Raw mode input (captures individual keypresses)
 - Special key detection (arrows, function keys, modifiers)
 - Ctrl+C handling for graceful shutdown
@@ -96,13 +100,13 @@ const manifest: ExternalServerManifest = {
   terminals: [
     { name: 'input', type: 'local', direction: 'input' },
     { name: 'output', type: 'local', direction: 'output' },
-    { name: 'error', type: 'local', direction: 'output' }
+    { name: 'error', type: 'local', direction: 'output' },
   ],
   capabilities: {
     type: 'transform',
     accepts: ['text'],
     produces: ['text'],
-    features: ['interactive', 'pty']
+    features: ['interactive', 'pty'],
   },
   command: '/bin/bash',
   args: [],
@@ -112,7 +116,7 @@ const manifest: ExternalServerManifest = {
   terminalType: 'xterm-256color',
   initialCols: 80,
   initialRows: 24,
-  restart: 'never'
+  restart: 'never',
 };
 
 const ptyWrapper = new PTYServerWrapper(kernel, hostess, manifest);
@@ -120,6 +124,7 @@ await ptyWrapper.spawn();
 ```
 
 **Features:**
+
 - PTY emulation with full terminal capabilities
 - Window resize support (`resize(cols, rows)`)
 - ANSI escape sequence handling
@@ -231,11 +236,7 @@ Build a custom terminal emulator with additional features:
 
 ```typescript
 // Keyboard → PTY → [Screen Renderer, Logger, AI Observer]
-kernel.split(ptyWrapper.outputPipe, [
-  renderer.inputPipe,
-  logger.inputPipe,
-  aiObserver.inputPipe
-]);
+kernel.split(ptyWrapper.outputPipe, [renderer.inputPipe, logger.inputPipe, aiObserver.inputPipe]);
 ```
 
 ### 2. AI-Assisted Shell
@@ -286,7 +287,7 @@ keyboard.on('keypress', (event) => {
 
 kernel.split(broadcast, [
   ptyWrapper.inputPipe,
-  websocket.inputPipe  // Send to remote users
+  websocket.inputPipe, // Send to remote users
 ]);
 ```
 
@@ -299,6 +300,7 @@ kernel.split(broadcast, [
 **Cause:** The script is running in a non-interactive environment (e.g., piped input, CI/CD, background job).
 
 **Solution:**
+
 ```typescript
 if (!process.stdin.isTTY) {
   console.error('Error: This demo requires an interactive terminal (TTY).');
@@ -316,6 +318,7 @@ if (!process.stdin.isTTY) {
 **Cause:** stdin not in raw mode, or competing input listeners.
 
 **Solution:**
+
 - Ensure `keyboard.start()` is called
 - Check that no other code is reading from `process.stdin`
 - Verify `process.stdin.setRawMode(true)` is not throwing errors
@@ -327,6 +330,7 @@ if (!process.stdin.isTTY) {
 **Cause:** Output pipe not connected, or buffering issues.
 
 **Solution:**
+
 ```typescript
 // Ensure output pipe is connected
 ptyWrapper.outputPipe.on('data', (data) => {
@@ -346,10 +350,11 @@ ptyWrapper.errorPipe.on('data', (data) => {
 **Cause:** Improper cleanup on shutdown.
 
 **Solution:**
+
 ```typescript
 async function cleanup() {
-  keyboard.stop();  // Restores cooked mode
-  await ptyWrapper.shutdown();  // Kills PTY process
+  keyboard.stop(); // Restores cooked mode
+  await ptyWrapper.shutdown(); // Kills PTY process
   process.exit(0);
 }
 
@@ -359,6 +364,7 @@ keyboard.on('ctrl-c', cleanup);
 ```
 
 If terminal is already corrupted:
+
 ```bash
 reset
 ```
@@ -370,6 +376,7 @@ reset
 **Cause:** Missing `node-pty` native module, or insufficient permissions.
 
 **Solution:**
+
 - Install build tools (see [quickstart.md](./quickstart.md#error-node-pty-module-not-found))
 - Rebuild native modules: `npm rebuild`
 - Check PTY permissions (Linux: add user to `tty` group)
@@ -379,6 +386,7 @@ reset
 ### Latency
 
 The interactive topology introduces minimal latency:
+
 - **Keyboard → PTY**: ~100-200μs (event capture + write)
 - **PTY → TTY**: ~100-500μs (depends on ANSI complexity)
 - **Round-trip**: ~200-700μs (typical for simple commands)
@@ -386,6 +394,7 @@ The interactive topology introduces minimal latency:
 ### Throughput
 
 For high-frequency input (e.g., paste operations):
+
 - Enable buffering: `keyboard.setBufferSize(1024)`
 - Use debouncing: `keyboard.setDebounce(10)` (ms)
 - Monitor backpressure: `ptyWrapper.inputPipe.writableHighWaterMark`
@@ -393,6 +402,7 @@ For high-frequency input (e.g., paste operations):
 ### Memory
 
 Interactive topology has low memory overhead:
+
 - KeyboardInput: ~10KB
 - PTYServerWrapper: ~50-100KB (depends on terminal state)
 - Pipes: ~16KB per pipe (default high water mark)
diff --git a/docs/devex/laminar-workflow.md b/docs/devex/laminar-workflow.md
index 859f582..90728b4 100644
--- a/docs/devex/laminar-workflow.md
+++ b/docs/devex/laminar-workflow.md
@@ -32,6 +32,7 @@ npm install --save-dev github:anteew/Laminar
 ```
 
 **No private npm registry needed.** This approach works for:
+
 - Local development
 - CI/CD pipelines (GitHub Actions, GitLab CI, etc.)
 - Team collaboration without publishing infrastructure
@@ -67,11 +68,11 @@ import { defineConfig } from 'vitest/config';
 export default defineConfig({
   test: {
     reporters: [
-      'default',  // Keep console output
-      './node_modules/@agent_vega/laminar/dist/src/test/reporter/jsonlReporter.js'
+      'default', // Keep console output
+      './node_modules/@agent_vega/laminar/dist/src/test/reporter/jsonlReporter.js',
     ],
     // ... other config
-  }
+  },
 });
 ```
 
@@ -95,6 +96,7 @@ npm run test:pty # For fork-based tests (if applicable)
 ```
 
 **What happens:**
+
 - Tests execute normally with console output
 - Laminar reporter writes structured events to `reports/` directory
 - Each test case gets its own `.jsonl` file with full execution trace
@@ -109,6 +111,7 @@ npm run lam -- summary
 ```
 
 **Example output:**
+
 ```
 Test Summary (42 tests):
 ✓ 38 passed
@@ -137,6 +140,7 @@ npm run lam -- trends --top 10
 ```
 
 **Example output:**
+
 ```
 Top Failure Trends (last 100 runs):
 
@@ -235,6 +239,7 @@ One-line JSON per test with status and metadata:
 ```
 
 Fields:
+
 - `status`: "pass" | "fail" | "skip"
 - `duration`: milliseconds
 - `location`: file path and line number
@@ -254,6 +259,7 @@ Structured event stream for each test case:
 ```
 
 Fields:
+
 - `ts`: timestamp (milliseconds since epoch)
 - `lvl`: log level (debug, info, warn, error)
 - `case`: test case identifier
@@ -312,9 +318,9 @@ name: Tests with Laminar
 
 on:
   push:
-    branches: [ main ]
+    branches: [main]
   pull_request:
-    branches: [ main ]
+    branches: [main]
 
 jobs:
   test:
@@ -376,12 +382,14 @@ After CI run completes:
    - Download `laminar-reports.zip`
 
 2. **Extract locally:**
+
    ```bash
    unzip laminar-reports.zip -d ci-reports/
    cd ci-reports/
    ```
 
 3. **Analyze failures:**
+
    ```bash
    # View summary
    cat LAMINAR_SUMMARY.txt
@@ -396,11 +404,13 @@ After CI run completes:
 ### Sharing Results
 
 **Option 1: CI Artifacts (Recommended)**
+
 - GitHub Actions automatically retains artifacts for 90 days
 - Team members download from Actions UI
 - No external storage needed
 
 **Option 2: Archive to Cloud Storage**
+
 ```yaml
 - name: Archive reports to S3
   if: always()
@@ -409,6 +419,7 @@ After CI run completes:
 ```
 
 **Option 3: Attach to PR Comments**
+
 ```yaml
 - name: Post summary to PR
   if: github.event_name == 'pull_request' && always()
@@ -432,12 +443,14 @@ After CI run completes:
 #### 1. Command not found: lam
 
 **Symptom:**
+
 ```
 bash: lam: command not found
 ```
 
 **Solution:**
 Use `npx` or npm script:
+
 ```bash
 # Option 1: npx
 npx @agent_vega/laminar --help
@@ -460,12 +473,14 @@ Tests run but no `reports/` directory appears.
 **Causes & Solutions:**
 
 1. **Reporter not configured**
+
    ```bash
    # Verify reporter is in vitest command:
    npx vitest run --reporter=./node_modules/@agent_vega/laminar/dist/src/test/reporter/jsonlReporter.js
    ```
 
 2. **Reporter path incorrect**
+
    ```bash
    # Check that Laminar is installed:
    ls node_modules/@agent_vega/laminar/dist/src/test/reporter/jsonlReporter.js
@@ -486,6 +501,7 @@ Tests run but no `reports/` directory appears.
 `reports/summary.jsonl` exists but is empty or missing test results.
 
 **Solution:**
+
 - Ensure tests actually ran (check console output)
 - Verify reporter was active (look for "Laminar reporter" in output)
 - Check for errors in test framework initialization
@@ -497,6 +513,7 @@ Artifact paths reference different directory than expected.
 
 **Solution:**
 Laminar uses the directory where tests run. Ensure consistent working directory:
+
 ```bash
 # In CI:
 - name: Run tests
@@ -511,6 +528,7 @@ Laminar uses the directory where tests run. Ensure consistent working directory:
    - Issues: https://github.com/anteew/Laminar/issues
 
 2. **Review existing artifacts:**
+
    ```bash
    # Check index.json for manifest
    cat reports/index.json | jq .
@@ -520,6 +538,7 @@ Laminar uses the directory where tests run. Ensure consistent working directory:
    ```
 
 3. **Enable debug output:**
+
    ```bash
    DEBUG=laminar* npm test
    ```
@@ -537,6 +556,7 @@ Laminar uses the directory where tests run. Ensure consistent working directory:
 Once comfortable with basic workflow, explore:
 
 1. **Custom digest rules** - Filter and slice logs with precision
+
    ```bash
    # Configure in laminar.config.json (if using standalone Laminar)
    npm run lam -- rules get
@@ -544,17 +564,20 @@ Once comfortable with basic workflow, explore:
    ```
 
 2. **Repro bundles** - Package failures for sharing
+
    ```bash
    npm run lam -- repro --bundle
    npm run lam -- repro --bundle --case kernel.spec/connect_moves_data_1_1
    ```
 
 3. **Digest diffs** - Compare failures across runs
+
    ```bash
    npm run lam -- diff reports/run1.digest.json reports/run2.digest.json
    ```
 
 4. **Flake detection** - Identify non-deterministic tests
+
    ```bash
    npm run lam -- run --flake-detect --flake-runs 5
    ```
@@ -583,6 +606,7 @@ Protect sensitive data in logs:
 ```
 
 Laminar includes built-in secret detection for:
+
 - API keys (AWS, Stripe, etc.)
 - JWT tokens
 - Database connection strings
@@ -600,6 +624,7 @@ Laminar includes built-in secret detection for:
 5. **Iterate** on test failures with self-service logs
 
 **ROI benefits:**
+
 - Faster debugging (structured logs vs. raw console output)
 - Historical trends (identify regressions early)
 - Self-service (no need to ask maintainers for logs)
diff --git a/docs/devex/local-ci.md b/docs/devex/local-ci.md
index f2c5aaf..d7b6df2 100644
--- a/docs/devex/local-ci.md
+++ b/docs/devex/local-ci.md
@@ -1,31 +1,38 @@
 # Local CI Runner (Fast Feedback)
 
 ## Why
+
 - Catch CI failures locally on a fast box before pushing.
 - Optional RAM-backed workspace for speed (tmpfs via /dev/shm).
 
 Commands
+
 - Native: `npm run ci:local`
 - RAM-backed: `npm run ci:local:fast` (uses /dev/shm when present)
 
 What it runs
-1) `npm ci`
-2) `npm run build`
-3) Threads tests: `npm run test:ci`
-4) Process/forks tests: `MK_PROCESS_EXPERIMENTAL=1 npm run test:pty`
-5) Acceptance smoke: `mkctl run examples/configs/http-logs-local-file.yml` on an ephemeral port
+
+1. `npm ci`
+2. `npm run build`
+3. Threads tests: `npm run test:ci`
+4. Process/forks tests: `MK_PROCESS_EXPERIMENTAL=1 npm run test:pty`
+5. Acceptance smoke: `mkctl run examples/configs/http-logs-local-file.yml` on an ephemeral port
 
 Artifacts
+
 - Copied back to `reports/local-ci/<ISO-stamp>/`
 
 Determinism
+
 - Node 24, `CI=true`, `MK_LOCAL_NODE=1`, `npm ci` from lockfile
 
 Pre-commit hook (optional)
+
 - Install: `npm run hooks:install`
 - Runs on commit: `prettier -c` and `eslint .` (warnings allowed)
 - Tip: use pre-push for heavier checks if desired (see `scripts/git-hooks/pre-push.sample`).
 
 Docker stub
+
 - `docker/Dockerfile.ci` documents the target runner image.
 - A future `npm run ci:local:docker` will bind-mount the repo and run the same steps inside the container.
diff --git a/docs/devex/mk-dev-logs-trace.md b/docs/devex/mk-dev-logs-trace.md
index e8bb0c8..0d6cb5e 100644
--- a/docs/devex/mk-dev-logs-trace.md
+++ b/docs/devex/mk-dev-logs-trace.md
@@ -54,6 +54,7 @@ mk trace --file mk.json --top 10 --sort latency
 ### What It Does
 
 `mk dev` runs your topology with **file watch** enabled. When you edit:
+
 - **TypeScript/JavaScript module source** → recompiles and restarts the module (in-process)
 - **Configuration file** (mk.json or mk.yaml) → reloads and validates topology
 - **Package.json dependencies** → rebuilds, then restarts affected modules
@@ -126,12 +127,7 @@ Override in `.mk/options.json`:
 ```json
 {
   "dev": {
-    "watch": [
-      "src/**/*.ts",
-      "src/**/*.js",
-      "config/*.yaml",
-      "data/seeds/*.json"
-    ],
+    "watch": ["src/**/*.ts", "src/**/*.js", "config/*.yaml", "data/seeds/*.json"],
     "ignore": ["**/*.test.ts", "**/node_modules"]
   }
 }
@@ -256,6 +252,7 @@ mk logs --level info,debug --watch
 ```
 
 Levels (from most to least severe):
+
 - `error` — runtime failures, exceptions
 - `warning` — deprecations, slow operations, retries
 - `info` — normal operation, requests, module lifecycle
@@ -325,7 +322,7 @@ By default, logs use ISO 8601 UTC timestamps. Configure in `.mk/options.json`:
 ```json
 {
   "logs": {
-    "timezone": "local",        // local | UTC
+    "timezone": "local", // local | UTC
     "format": "iso|human|epoch"
   }
 }
@@ -501,12 +498,14 @@ mk trace --top 3 --sort latency
 **Problem**: File changes don't trigger reload.
 
 **Checklist**:
+
 1. Verify file path is correct: `mk dev --verbose` shows watched paths
 2. Ensure module is in `runMode: inproc` or `worker` (external processes don't hot-reload)
 3. Check file is in watched patterns in `.mk/options.json`
 4. On Mac: ensure Terminal has full disk access (System Preferences → Security & Privacy)
 
 **Fix**:
+
 ```bash
 # Force rebuild and restart all modules
 mk dev --reload-all
@@ -517,11 +516,13 @@ mk dev --reload-all
 **Problem**: Recompile fails silently; topology keeps running old version.
 
 **Fix**: Enable verbose logging
+
 ```bash
 mk dev --verbose
 ```
 
 Or check errors explicitly:
+
 ```bash
 mk doctor --section types
 ```
@@ -531,11 +532,13 @@ mk doctor --section types
 **Problem**: `mk logs --watch` shows nothing.
 
 **Checklist**:
+
 1. Is topology running? (`mk logs` requires `mk dev` or `mk run` to be active)
 2. Are modules outputting logs? (some modules may be silent)
 3. Check stdout/stderr redirection: is output captured?
 
 **Fix**:
+
 ```bash
 # Ensure topology is running
 mk dev &
@@ -548,6 +551,7 @@ mk logs --watch  # should now show output
 **Problem**: `mk logs --watch` is overwhelming.
 
 **Solutions**:
+
 ```bash
 # Filter to one module
 mk logs --module http-server --watch
@@ -564,6 +568,7 @@ mk logs --tail 50
 **Problem**: Tracing adds noticeable latency.
 
 **Solutions**:
+
 - Use `--duration` to limit capture window instead of `--watch`
 - Reduce sample rate: `mk trace --sample-rate 0.1` (trace 10% of messages)
 - Trace only specific modules: `mk trace --module parser`
@@ -573,10 +578,12 @@ mk logs --tail 50
 **Problem**: `mk trace` returns empty results.
 
 **Checklist**:
+
 1. Is topology running with messages flowing?
 2. Was capture duration long enough? (need at least 100 messages for meaningful stats)
 
 **Fix**:
+
 ```bash
 # Ensure topology is active
 mk dev &
@@ -610,11 +617,11 @@ export MK_TRACE_SAMPLE_RATE=0.5
 
 ## Quick Reference
 
-| Command | Purpose | Key Flags |
-|---------|---------|-----------|
-| `mk dev` | Hot reload on file changes | `--file`, `--duration`, `--verbose`, `--dry-run` |
-| `mk logs` | Stream & filter logs | `--module`, `--level`, `--pattern`, `--watch`, `--tail` |
-| `mk trace` | Analyze flow latency | `--duration`, `--top`, `--sort`, `--format`, `--watch` |
+| Command    | Purpose                    | Key Flags                                               |
+| ---------- | -------------------------- | ------------------------------------------------------- |
+| `mk dev`   | Hot reload on file changes | `--file`, `--duration`, `--verbose`, `--dry-run`        |
+| `mk logs`  | Stream & filter logs       | `--module`, `--level`, `--pattern`, `--watch`, `--tail` |
+| `mk trace` | Analyze flow latency       | `--duration`, `--top`, `--sort`, `--format`, `--watch`  |
 
 ---
 
diff --git a/docs/devex/mk-dx-checklist.md b/docs/devex/mk-dx-checklist.md
index 4af44d8..f50c913 100644
--- a/docs/devex/mk-dx-checklist.md
+++ b/docs/devex/mk-dx-checklist.md
@@ -5,42 +5,50 @@
 Use this checklist on every PR that changes CLI output, flags, errors, or docs. Enforced by `mk-dx-style.md` snapshot tests.
 
 ## Quick Pass
+
 - [ ] TTFR still ≤ 60s on fresh clone (Hello preset).
 - [ ] `mk run --dry-run` still < 400ms on example.
 - [ ] No unexplained new flags; help updated.
 
 ## Help & Discoverability
+
 - [ ] `mk --help` sections present and ordered.
 - [ ] Each new flag has an example.
 - [ ] Did‑you‑mean suggestions trigger for common typos.
 
 ## Errors & Microcopy
+
 - [ ] Errors follow 3‑line pattern (status, fix, docs+code+rerun).
 - [ ] Exit codes mapped and documented.
 - [ ] `--json` payload includes { code, message, remediation, details, docs, hint }.
 
 ## Accessibility
+
 - [ ] `--no-ansi` looks clean; tokens readable.
 - [ ] ASCII graph path tested.
 - [ ] No red/green dependency.
 
 ## Prompt
+
 - [ ] `mk prompt print` emits correct snippet.
 - [ ] `mk prompt off` restores prior prompt.
 - [ ] `.mk/state/prompt.json` updates predictably.
 
 ## Docs
+
 - [ ] DX style guide rules followed.
 - [ ] New docs link to stable anchors.
 - [ ] Examples are copy‑paste runnable.
 
 ## Snapshot Tests
+
 - [ ] Help text snapshot (mkdxHelp.spec.ts) passes without unintended changes.
 - [ ] Error output snapshot (mkdxErrors.spec.ts) passes with all error codes validated.
 - [ ] Run `npm run test:ci -- tests/cli/mkdx*.spec.ts` to verify snapshots.
 - [ ] Any approved snapshot changes are documented in PR description.
 
 ## CI & Artifacts
+
 - [ ] Laminar PR comment still aggregates.
 - [ ] History cache keys remain stable.
 - [ ] Reports written to `reports/` deterministically.
@@ -52,6 +60,6 @@ Use this checklist on every PR that changes CLI output, flags, errors, or docs.
 For implementation guidance, see **[mk-dx-style.md](./mk-dx-style.md#snapshot-testing-scaffolds)** — Snapshot Testing Scaffolds section.
 
 **Snapshot Test Files**:
+
 - `tests/cli/mkdxHelp.spec.ts` — Help output consistency (scaffold mode)
 - `tests/cli/mkdxErrors.spec.ts` — Error format consistency (active)
-
diff --git a/docs/devex/mk-dx-style.md b/docs/devex/mk-dx-style.md
index 20201ec..dfd96fc 100644
--- a/docs/devex/mk-dx-style.md
+++ b/docs/devex/mk-dx-style.md
@@ -5,6 +5,7 @@
 Purpose: Encode developer‑joy into our CLI microcopy, output structure, and error semantics so every interaction is fast, obvious, reversible, and helpful.
 
 ## Principles
+
 - Short first, details on demand.
 - Every error teaches (code, cause, fix, rerun).
 - Deterministic output; machine‑readable with `--json`.
@@ -12,11 +13,13 @@ Purpose: Encode developer‑joy into our CLI microcopy, output structure, and er
 - Quiet on success, rich with `-v/--debug`.
 
 ## Status Line Conventions
+
 - Prefix tokens (TTY): `[OK ]`, `[ERR]`, `[WARN]`, `[INFO]`.
 - Non‑TTY: same tokens without color. Provide `--no-color`.
 - One short line first; follow with bullet details.
 
 Examples:
+
 ```
 [ERR] CONFIG_PARSE at mk.yaml:12:7 — invalid indent under "nodes".
 Fix: run `mk format --to json --dry-run` to see a normalized form.
@@ -29,6 +32,7 @@ Code: CONFIG_PARSE  Rerun: mk run --file mk.yaml --dry-run
 ```
 
 ## "Did You Mean" Pattern
+
 - **Algorithm**: Levenshtein distance ≤ 2 for commands/flags
 - **Limit**: Suggest at most 2 candidates
 - **Format**: `Unknown command "losg". Did you mean: logs, trace?`
@@ -36,6 +40,7 @@ Code: CONFIG_PARSE  Rerun: mk run --file mk.yaml --dry-run
 - **Scope**: Apply to both commands (`mk rnu`) and flags (`--flie`)
 
 ### Implementation Rules
+
 1. Calculate edit distance for all known commands/flags
 2. Filter candidates with distance ≤ 2
 3. Sort by distance (ascending), then alphabetically
@@ -43,6 +48,7 @@ Code: CONFIG_PARSE  Rerun: mk run --file mk.yaml --dry-run
 5. If no matches found, show generic "Unknown command" error
 
 ### Examples
+
 ```
 $ mk rnu
 [ERR] UNKNOWN_COMMAND — Unknown command "rnu"
@@ -65,6 +71,7 @@ Fix: Run: mk --help
 ```
 
 ## Error Taxonomy (Human)
+
 - CONFIG_NOT_FOUND — show searched paths; suggest `mk init`.
 - CONFIG_PARSE — include line:col; suggest `mk format --dry-run`.
 - SCHEMA_INVALID — show JSONPath to field; suggest fix snippet.
@@ -72,6 +79,7 @@ Fix: Run: mk --help
 - PERMISSION_DENIED — show exact flag to enable.
 
 ## Error Payload (Machine, with `--json`)
+
 ```json
 {
   "code": "CONFIG_PARSE",
@@ -86,7 +94,9 @@ Fix: Run: mk --help
 ## Help Text Conventions
 
 ### Structure
+
 All help text follows consistent sections:
+
 1. **Header**: Command name + one-line description
 2. **Usage**: Command syntax with brackets for optional args
 3. **Description**: 1-2 sentences explaining what the command does
@@ -97,6 +107,7 @@ All help text follows consistent sections:
 8. **Learn More**: Links to full docs and RFCs
 
 ### Formatting Rules
+
 - Use UPPERCASE for section headers
 - Indent options with 2 spaces
 - Keep primary lines ≤ 80 columns
@@ -105,6 +116,7 @@ All help text follows consistent sections:
 - Group related flags together
 
 ### Example Pattern
+
 ```
 mk <command> — Short description
 
@@ -131,6 +143,7 @@ LEARN MORE
 ```
 
 ### Stability Requirements
+
 - **No timestamps or dates** in help text
 - **No dynamic version numbers** that change per build
 - **Deterministic output**: Running `mk --help` twice produces identical output
@@ -139,6 +152,7 @@ LEARN MORE
 ## Error Message Style Guide
 
 ### Format
+
 ```
 [ERR] ERROR_CODE at <location> — brief description
 Fix: <actionable remediation>
@@ -147,6 +161,7 @@ Code: ERROR_CODE  Rerun: <exact command to retry>
 ```
 
 ### Writing Rules
+
 1. **Be specific**: "Configuration file not found at ./mk.json" > "File not found"
 2. **Show location**: Include file:line:col when available
 3. **Provide fix**: Every error includes actionable remediation
@@ -158,6 +173,7 @@ Code: ERROR_CODE  Rerun: <exact command to retry>
 ### Examples
 
 **Good**:
+
 ```
 [ERR] CONFIG_NOT_FOUND — Configuration file not found at ./mk.json
 Fix: Run: mk init --preset tty
@@ -166,32 +182,38 @@ Code: CONFIG_NOT_FOUND
 ```
 
 **Bad**:
+
 ```
 Error: couldn't find the config
 Try creating one
 ```
 
 ## Accessibility
+
 - Support `--no-ansi`; ensure high‑contrast tokens.
 - ASCII graphs for non‑TTY; avoid red/green only.
 - Respect `$LANG` for numbers/dates (messages remain English in v0).
 
 ## Prompt Snippet
+
 - Format: `[mk:<profile> <in/out format> <gates>]` (e.g., `[mk:dev yaml local]`).
 - Never write to shell rc files; `print` only; reversible.
 
 ## Snapshot Targets (v0)
+
 - Help text (`mk --help`, `mk dev --help`, `mk logs --help`, `mk trace --help`): stable sections and examples.
 - 10 canonical error messages: exact 3‑line structure.
 - JSON error payload shape: fields present and typed.
 - **Phase C Additions** (P11): `mk dev`, `mk logs`, `mk trace` help snapshots (see fixtures below).
 
 ## Copywriting Rules
+
 - Use imperative voice. Avoid jargon. Prefer verbs: "Run", "Fix", "Open".
 - Link to stable anchors. Avoid 404 risk.
 - Keep primary lines ≤ 80 columns.
 
 ## Acceptance Gates
+
 - TTFR ≤ 60s; TTR (parse error) ≤ 30s with provided fix.
 - `mk run --dry-run` latency < 400ms on example.
 - Help and error outputs pass snapshot tests.
@@ -201,6 +223,7 @@ Try creating one
 To enforce DX consistency, we maintain snapshot tests for critical CLI surfaces:
 
 ### Help Text Snapshot (`tests/cli/mkdxHelp.spec.ts`)
+
 - **Purpose**: Detect unintended help output changes
 - **Scope**: `mk --help` sections, command order, examples
 - **Structure**: Organized sections (Usage, Commands, Options, Examples)
@@ -208,7 +231,9 @@ To enforce DX consistency, we maintain snapshot tests for critical CLI surfaces:
 - **Status**: Active with 27 tests covering all commands and fixtures
 
 ### Test Coverage
+
 The help test suite includes:
+
 1. **Main help**: `mk --help` and `mk -h` flags
 2. **Command help**: All 8 core commands (`init`, `run`, `doctor`, `validate`, `graph`, `dev`, `logs`, `trace`)
 3. **Stability**: Deterministic output (no timestamps, no dynamic versions)
@@ -216,14 +241,16 @@ The help test suite includes:
 5. **Fixture validation**: Structure verification for `mk dev`, `mk logs`, `mk trace` fixtures
 
 ### Error Output Snapshot (`tests/cli/mkdxErrors.spec.ts`)
+
 - **Purpose**: Enforce error format consistency across all error codes
-- **Scope**: 15 core error codes (CONFIG_*, HEALTH_CHECK_*, SCHEMA_*, MODULE_*, RUNTIME_*, etc.)
+- **Scope**: 15 core error codes (CONFIG*\*, HEALTH_CHECK*_, SCHEMA\__, MODULE*\*, RUNTIME*\*, etc.)
 - **Format**: MkError class with code/message/remediation/details/docs/hint
 - **Coverage**: Text format (human-readable), JSON format (machine-parseable)
 - **Validation**: All errors include non-empty message and remediation
 - **Status**: Active; tests ERROR_CATALOG and formatError() function
 
 ### How to Update Snapshots
+
 ```bash
 # Review and accept snapshot changes
 npm run test:ci -- --update
@@ -234,6 +261,7 @@ npx vitest tests/cli/mkdxErrors.spec.ts --update
 ```
 
 ### Adding New Error Codes
+
 1. Add to `ERROR_CATALOG` in error definitions
 2. Include code, message, remediation, docs link
 3. Run tests to verify scaffold coverage
@@ -246,6 +274,7 @@ npx vitest tests/cli/mkdxErrors.spec.ts --update
 Added help text snapshots for new developer ergonomics commands:
 
 ### Files Added
+
 - `tests/fixtures/mkdx/mk-dev.help.txt` — Help for `mk dev` (hot reload)
 - `tests/fixtures/mkdx/mk-logs.help.txt` — Help for `mk logs` (structured logging)
 - `tests/fixtures/mkdx/mk-trace.help.txt` — Help for `mk trace` (flow analysis)
@@ -280,6 +309,7 @@ npm run test:ci -- tests/cli/mkdxHelp.spec.ts --update
 ## Implementation Checklist for Future MK CLI Phases
 
 **Phase A (v0):**
+
 - [x] mkdxHelp.spec.ts — Activated with 27 comprehensive help tests
 - [x] mkdxErrors.spec.ts — Extended ERROR_CATALOG for all error scenarios
 - [ ] Implement mk --help with sections matching snapshot expectations
@@ -288,6 +318,7 @@ npm run test:ci -- tests/cli/mkdxHelp.spec.ts --update
 - [ ] Run full test suite: `npm run test:ci -- tests/cli/mkdx*`
 
 **Phase C (P11+):**
+
 - [x] Add mk dev/logs/trace help text snapshots (fixtures created)
 - [x] Add comprehensive did-you-mean tests
 - [x] Document help text conventions and error message style guide
diff --git a/docs/devex/packaging.md b/docs/devex/packaging.md
index 361fddf..d159071 100644
--- a/docs/devex/packaging.md
+++ b/docs/devex/packaging.md
@@ -25,11 +25,13 @@ $ mk build
 ```
 
 **Output files:**
+
 - `dist/bundle.js` - Your bundled application
 - `dist/bundle.js.map` - Source maps for debugging
 - `dist/build-info.json` - Build provenance metadata
 
 **Provenance metadata includes:**
+
 - Version, timestamp, and Node.js version
 - Platform and architecture
 - Source files list
@@ -47,6 +49,7 @@ $ mk package
 ```
 
 **Output:**
+
 - Deterministic filename: `mkolbol-{version}-{platform}-{arch}-{timestamp}.capsule.tgz`
 - Contains: bundle.js, bundle.js.map, build-info.json
 - SHA256 hash for integrity verification
@@ -92,6 +95,7 @@ mk fetch latest
 ```
 
 **What it does**:
+
 1. Queries GitHub releases API for the specified tag
 2. Downloads the `.tgz` asset to your current directory
 3. Runs `npm install <tarball>` to install it
@@ -116,6 +120,7 @@ Installation complete
 ```
 
 **Limitations**:
+
 - Requires internet connection to GitHub
 - Only works with published GitHub releases
 - Does not support pre-release tags (alpha, beta)
@@ -179,18 +184,21 @@ npm install
 ```
 
 **Pros**:
+
 - Pin to any commit, tag, or branch
 - No need to wait for npm registry publish
 - Works in CI/CD environments
 - Reproducible builds
 
 **Cons**:
+
 - Requires git checkout and build on install
 - Slower than tarball install
 - Requires build dependencies (TypeScript, etc.)
 - Not suitable for production deployments
 
 **When to use**:
+
 - Development against unreleased features
 - Testing release candidates
 - CI/CD pipelines with specific version requirements
@@ -199,6 +207,7 @@ npm install
 ## Overview
 
 When you build an application with mkolbol, you typically have:
+
 - Your custom server modules (TypeScript/JavaScript)
 - The mkolbol kernel and its dependencies
 - External process scripts (Python, Go, Rust, etc.)
@@ -216,12 +225,14 @@ There are three popular tools for packaging Node.js applications:
 **Overview**: An extremely fast JavaScript bundler and minifier written in Go.
 
 **How it works**:
+
 - Bundles all JavaScript/TypeScript into a single file
 - Tree-shakes unused code
 - Minifies output
 - Outputs a JavaScript file that still requires Node.js to run
 
 **Pros**:
+
 - Blazingly fast (10-100x faster than webpack)
 - Simple configuration
 - Excellent TypeScript support
@@ -230,12 +241,14 @@ There are three popular tools for packaging Node.js applications:
 - Minimal overhead for native modules
 
 **Cons**:
+
 - Still requires Node.js runtime on target
 - Limited support for dynamic requires
 - No binary executable output
 - Native modules (like node-pty) need special handling
 
 **Best for**:
+
 - Fast development iteration
 - Docker/container deployments (Node.js is available)
 - Cloud functions / serverless
@@ -246,12 +259,14 @@ There are three popular tools for packaging Node.js applications:
 **Overview**: Simple CLI for compiling Node.js modules into a single file, designed by Vercel.
 
 **How it works**:
+
 - Uses webpack under the hood
 - Bundles everything into one .js file
 - Includes all dependencies
 - Optimized for serverless deployments
 
 **Pros**:
+
 - Zero configuration required
 - Designed specifically for Node.js applications
 - Good native module support
@@ -259,6 +274,7 @@ There are three popular tools for packaging Node.js applications:
 - Small learning curve
 
 **Cons**:
+
 - Still requires Node.js runtime
 - Slower than esbuild
 - Less flexibility in configuration
@@ -266,6 +282,7 @@ There are three popular tools for packaging Node.js applications:
 - Can struggle with complex dependency trees
 
 **Best for**:
+
 - Serverless deployments (Vercel, AWS Lambda, etc.)
 - Simple applications with straightforward dependencies
 - Quick prototyping without configuration overhead
@@ -275,12 +292,14 @@ There are three popular tools for packaging Node.js applications:
 **Overview**: Package Node.js projects into standalone executables for Windows, macOS, and Linux.
 
 **How it works**:
+
 - Bundles Node.js runtime + your code
 - Creates platform-specific native executables
 - Embeds file system (snapshots your app)
 - No Node.js required on target
 
 **Pros**:
+
 - Produces true standalone executables
 - No Node.js required on target system
 - Cross-platform builds from single machine
@@ -288,6 +307,7 @@ There are three popular tools for packaging Node.js applications:
 - Users get native binary experience
 
 **Cons**:
+
 - Large binary size (40-50MB+, includes Node.js)
 - Slow build times
 - Native modules can be problematic
@@ -296,6 +316,7 @@ There are three popular tools for packaging Node.js applications:
 - Project is less actively maintained
 
 **Best for**:
+
 - Distributing CLI tools to non-technical users
 - Environments where Node.js can't be installed
 - Desktop applications
@@ -303,18 +324,18 @@ There are three popular tools for packaging Node.js applications:
 
 ## Comparison Table
 
-| Feature | esbuild | @vercel/ncc | pkg |
-|---------|---------|-------------|-----|
-| **Speed** | Extremely fast (< 1s) | Fast (2-5s) | Slow (10-30s) |
-| **Bundle Size** | Small (< 1MB) | Medium (1-3MB) | Large (40-50MB+) |
-| **Requires Node.js** | Yes | Yes | No |
-| **Native Modules** | Moderate support | Good support | Difficult |
-| **Configuration** | Simple | Zero config | Moderate |
-| **Tree-shaking** | Excellent | Good | Limited |
-| **Output Format** | .js file | .js file | Native executable |
-| **Cross-platform** | Yes (code) | Yes (code) | Yes (binaries) |
-| **Dynamic requires** | Limited | Good | Requires config |
-| **Active Development** | Very active | Active | Less active |
+| Feature                | esbuild               | @vercel/ncc    | pkg               |
+| ---------------------- | --------------------- | -------------- | ----------------- |
+| **Speed**              | Extremely fast (< 1s) | Fast (2-5s)    | Slow (10-30s)     |
+| **Bundle Size**        | Small (< 1MB)         | Medium (1-3MB) | Large (40-50MB+)  |
+| **Requires Node.js**   | Yes                   | Yes            | No                |
+| **Native Modules**     | Moderate support      | Good support   | Difficult         |
+| **Configuration**      | Simple                | Zero config    | Moderate          |
+| **Tree-shaking**       | Excellent             | Good           | Limited           |
+| **Output Format**      | .js file              | .js file       | Native executable |
+| **Cross-platform**     | Yes (code)            | Yes (code)     | Yes (binaries)    |
+| **Dynamic requires**   | Limited               | Good           | Requires config   |
+| **Active Development** | Very active           | Active         | Less active       |
 
 ## Recommendation: esbuild
 
@@ -357,6 +378,7 @@ npx esbuild src/index.ts \
 ```
 
 **Explanation**:
+
 - `--bundle`: Combine all dependencies into one file
 - `--platform=node`: Target Node.js (not browser)
 - `--target=node20`: Use Node.js 20+ features
@@ -393,11 +415,13 @@ dist/
 ```
 
 The bundle includes:
+
 - Your application code
 - mkolbol kernel
 - All JavaScript dependencies
 
 Excluded (must be installed separately):
+
 - node-pty (native module)
 - yaml (if marked external)
 
@@ -417,6 +441,7 @@ const CONFIG_PATH = process.env.CONFIG_PATH || './config.yml';
 ```
 
 **Usage**:
+
 ```bash
 DEBUG=1 PORT=3000 node dist/runner.js
 ```
@@ -442,6 +467,7 @@ const configData = readFileSync(configPath, 'utf-8');
 ```
 
 **Directory structure for deployment**:
+
 ```
 deployment/
 ├── dist/
@@ -454,6 +480,7 @@ deployment/
 ```
 
 **Minimal package.json for deployment**:
+
 ```json
 {
   "name": "my-mkolbol-app",
@@ -506,7 +533,7 @@ Always exclude native modules from the bundle:
 
 ```javascript
 // build-bundle.mjs
-external: ['node-pty', 'fsevents', 'better-sqlite3']
+external: ['node-pty', 'fsevents', 'better-sqlite3'];
 ```
 
 ### 2. Use Tree-shaking
@@ -530,6 +557,7 @@ npm list --depth=0
 ```
 
 Remove unused packages:
+
 ```bash
 npm uninstall unused-package
 ```
@@ -540,9 +568,9 @@ npm uninstall unused-package
 // build-bundle.mjs
 esbuild.build({
   // ...
-  minify: true,        // Minify code
-  treeShaking: true,   // Remove dead code
-})
+  minify: true, // Minify code
+  treeShaking: true, // Remove dead code
+});
 ```
 
 ### 5. Analyze Bundle Size
@@ -564,10 +592,10 @@ For very large apps, consider code splitting:
 esbuild.build({
   // ...
   splitting: true,
-  outdir: 'dist',  // Use outdir instead of outfile
+  outdir: 'dist', // Use outdir instead of outfile
   entryPoints: ['src/index.ts'],
   format: 'esm',
-})
+});
 ```
 
 ## Debugging Bundled Applications
@@ -578,11 +606,12 @@ esbuild.build({
 // build-bundle.mjs
 esbuild.build({
   // ...
-  sourcemap: 'linked',  // or 'inline' or 'external'
-})
+  sourcemap: 'linked', // or 'inline' or 'external'
+});
 ```
 
 Run with source map support:
+
 ```bash
 node --enable-source-maps dist/runner.js
 ```
@@ -593,8 +622,8 @@ node --enable-source-maps dist/runner.js
 // build-bundle.mjs
 esbuild.build({
   // ...
-  keepNames: true,  // Preserve function/class names
-})
+  keepNames: true, // Preserve function/class names
+});
 ```
 
 ### Add Debug Logging
@@ -657,7 +686,7 @@ Use paths relative to bundle or environment variables:
 
 ```typescript
 // Before bundling
-command: './scripts/echo-server.py'
+command: './scripts/echo-server.py';
 
 // After bundling (use absolute paths)
 import { dirname, join } from 'path';
@@ -666,7 +695,7 @@ import { fileURLToPath } from 'url';
 const __dirname = dirname(fileURLToPath(import.meta.url));
 const scriptsDir = join(__dirname, '../scripts');
 
-command: join(scriptsDir, 'echo-server.py')
+command: join(scriptsDir, 'echo-server.py');
 ```
 
 Or use environment variables:
@@ -706,6 +735,7 @@ npx ncc build src/index.ts \
 ```
 
 Output:
+
 ```
 dist/
 └── index.js  # Everything bundled (larger than esbuild)
@@ -730,15 +760,8 @@ npm install --save-dev pkg
   "bin": "dist/runner.js",
   "pkg": {
     "scripts": "dist/**/*.js",
-    "assets": [
-      "config/**/*",
-      "scripts/**/*"
-    ],
-    "targets": [
-      "node20-linux-x64",
-      "node20-macos-x64",
-      "node20-win-x64"
-    ],
+    "assets": ["config/**/*", "scripts/**/*"],
+    "targets": ["node20-linux-x64", "node20-macos-x64", "node20-win-x64"],
     "outputPath": "build"
   }
 }
@@ -755,6 +778,7 @@ npx pkg .
 ```
 
 Output:
+
 ```
 build/
 ├── runner-linux
@@ -853,8 +877,9 @@ After packaging your application:
 **Problem**: Bundle can't find external modules.
 
 **Solution**: Mark them as external in build script:
+
 ```javascript
-external: ['node-pty', 'yaml']
+external: ['node-pty', 'yaml'];
 ```
 
 ### Native module errors
@@ -862,6 +887,7 @@ external: ['node-pty', 'yaml']
 **Problem**: `node-pty` fails to load.
 
 **Solution**:
+
 1. Don't bundle native modules
 2. Ensure node_modules/node-pty exists in deployment
 3. Rebuild for target platform: `npm rebuild node-pty`
@@ -871,6 +897,7 @@ external: ['node-pty', 'yaml']
 **Problem**: Bundle can't find topology.yml.
 
 **Solution**: Use proper path resolution:
+
 ```typescript
 const configPath = join(process.cwd(), 'config/topology.yml');
 ```
@@ -880,6 +907,7 @@ const configPath = join(process.cwd(), 'config/topology.yml');
 **Problem**: Bundle is several megabytes.
 
 **Solution**:
+
 1. Mark large dependencies as external
 2. Enable tree-shaking and minification
 3. Remove unused dependencies
@@ -890,11 +918,13 @@ const configPath = join(process.cwd(), 'config/topology.yml');
 **Problem**: Python/Bash scripts fail with permission errors.
 
 **Solution**:
+
 ```bash
 chmod +x scripts/*.py scripts/*.sh
 ```
 
 Or in deployment script:
+
 ```typescript
 import { chmodSync } from 'fs';
 chmodSync('scripts/echo-server.py', 0o755);
diff --git a/docs/devex/quickstart.md b/docs/devex/quickstart.md
index 7d9a564..c952ac7 100644
--- a/docs/devex/quickstart.md
+++ b/docs/devex/quickstart.md
@@ -28,6 +28,7 @@ node dist/scripts/mkctl.js run --file examples/configs/external-pty.yaml --durat
 ```
 
 **Why use mkctl run?**
+
 - No need to write TypeScript/JavaScript code
 - Config is shareable and version-controllable
 - Same approach scales from local development to distributed deployments
@@ -44,6 +45,7 @@ mkctl endpoints
 You’ll see the endpoint id, module type, coordinates (`node:<id>` for in-process modules), and the timestamps when the announcement was recorded. Re-run the command any time to confirm which modules are currently live.
 
 ---
+
 ### Local Node Mode (MK_LOCAL_NODE=1)
 
 By default, mkolbol runs in Local Node mode with in-process routing only. This is enforced via the `MK_LOCAL_NODE=1` environment variable:
@@ -54,11 +56,13 @@ MK_LOCAL_NODE=1 node dist/scripts/mkctl.js run --file examples/configs/basic.yml
 ```
 
 **What Local Node mode does:**
+
 - **Enables:** In-process RoutingServer, Executor, Hostess, StateManager
 - **Disables:** Network transports, distributed routing, multi-machine topologies
 - **Validates:** Config loader rejects any node with `type=network` or `address` parameters
 
 **When to use Local Node mode:**
+
 - Local development and testing
 - Single-machine deployments
 - When you don't need network communication
@@ -70,6 +74,7 @@ MK_LOCAL_NODE=1 node dist/scripts/mkctl.js run --file examples/configs/basic.yml
 ## Local Node v1.0 Demo: HTTP to Console
 
 This is the canonical "hello world" for Local Node routing. It demonstrates:
+
 - ExternalProcess (HTTP server) → ConsoleSink (terminal output)
 - RoutingServer endpoint discovery
 - Local Node topology lifecycle (spawn, run, shutdown)
@@ -84,6 +89,7 @@ node dist/scripts/mkctl.js run --file examples/configs/http-logs-local.yml --dur
 ```
 
 Expected output:
+
 ```
 Loading config from: examples/configs/http-logs-local.yml
 Bringing topology up...
@@ -99,6 +105,7 @@ curl -s http://localhost:3000/hello
 ```
 
 You'll see logged in Terminal 1:
+
 ```
 [http] [2025-10-17T04:15:23.456Z] GET /hello
 ```
@@ -115,6 +122,7 @@ node dist/scripts/mkctl.js endpoints --watch
 ```
 
 You'll see:
+
 ```
 Registered Endpoints (RoutingServer snapshot)
 
@@ -141,15 +149,18 @@ Coordinates: node:sink
 ### Today vs Soon
 
 **Today (Current):**
+
 - Output → ConsoleSink (terminal console)
 - Users who want persistent logs can tee output: `… | tee reports/http-demo.log`
 
 **FilesystemSink with PipeMeter (file output with metrics):**
+
 - Output → PipeMeter → FilesystemSink (writes to `reports/http-logs.jsonl`)
 - Use the ready-made config: `examples/configs/http-logs-local-file.yml`
 - Topology: ExternalProcess (HTTP server) → PipeMeterTransform → FilesystemSink (JSONL format)
 
 Run it:
+
 ```bash
 export MK_LOCAL_NODE=1
 node dist/scripts/mkctl.js run --file examples/configs/http-logs-local-file.yml --duration 5
@@ -160,6 +171,7 @@ cat reports/http-logs.jsonl
 ```
 
 Expected output in `reports/http-logs.jsonl`:
+
 ```jsonl
 {"ts":"2025-10-16T12:34:56.789Z","data":"Server listening on http://localhost:3000"}
 {"ts":"2025-10-16T12:34:57.123Z","data":"[2025-10-16T12:34:57.123Z] GET /"}
@@ -173,40 +185,45 @@ Expected output in `reports/http-logs.jsonl`:
 FilesystemSink supports two output formats:
 
 **Raw format (default):**
+
 ```yaml
 - id: sink
   module: FilesystemSink
   params:
     path: reports/output.log
-    format: raw  # default, can be omitted
+    format: raw # default, can be omitted
 ```
 
 **JSONL format with timestamps:**
+
 ```yaml
 - id: sink
   module: FilesystemSink
   params:
     path: reports/output.jsonl
-    format: jsonl  # wraps each chunk as {"ts": "2025-10-16T...", "data": "..."}
+    format: jsonl # wraps each chunk as {"ts": "2025-10-16T...", "data": "..."}
 ```
 
 Example JSONL output:
+
 ```jsonl
 {"ts":"2025-10-16T12:34:56.789Z","data":"[http] GET /hello"}
 {"ts":"2025-10-16T12:34:57.123Z","data":"[http] GET /test"}
 ```
 
 **Raw format with timestamps:**
+
 ```yaml
 - id: sink
   module: FilesystemSink
   params:
     path: reports/output.log
     format: raw
-    includeTimestamp: true  # prepends ISO timestamp to each line
+    includeTimestamp: true # prepends ISO timestamp to each line
 ```
 
 Example timestamped raw output:
+
 ```
 2025-10-16T12:34:56.789Z [http] GET /hello
 2025-10-16T12:34:57.123Z [http] GET /test
@@ -225,16 +242,16 @@ nodes:
       args:
         - -e
         - "require('http').createServer((req,res)=>{ … }).listen(3000)"
-      ioMode: stdio  # stdio for non-interactive (vs. pty for shells)
+      ioMode: stdio # stdio for non-interactive (vs. pty for shells)
 
   - id: sink
     module: ConsoleSink
     params:
-      prefix: "[http]"  # Add prefix to all console output
+      prefix: '[http]' # Add prefix to all console output
 
 connections:
   - from: web.output
-    to: sink.input  # Wire HTTP logs to console
+    to: sink.input # Wire HTTP logs to console
 ```
 
 Learn more: **[Wiring and Testing](./wiring-and-tests.md)** for complete config schema.
@@ -257,6 +274,7 @@ node dist/scripts/mkctl.js run --file examples/configs/tty-external.yml --durati
 This topology pipes `ls --color=always -la` output through TTYRenderer to your terminal with full ANSI color support.
 
 **Expected output:**
+
 ```
 total 456
 drwxr-xr-x  25 user  staff    800 Oct 16 14:32 .
@@ -288,7 +306,7 @@ nodes:
   - id: tty-renderer
     module: XtermTTYRenderer
     params:
-      altBuffer: false  # false = inline output; true = alternate screen
+      altBuffer: false # false = inline output; true = alternate screen
 
 connections:
   - from: ls-command.output
@@ -296,6 +314,7 @@ connections:
 ```
 
 **Key parameters:**
+
 - `ioMode: stdio` - Non-interactive command output (vs. `pty` for shells)
 - `altBuffer: false` - Inline rendering (set `true` to use alternate screen buffer)
 - `--color=always` - Force ANSI colors even when piped
@@ -303,6 +322,7 @@ connections:
 ### Other TTY Examples
 
 **Colorized grep output:**
+
 ```bash
 # Create config with grep --color=always
 cat > examples/configs/tty-grep.yml <<EOF
@@ -325,6 +345,7 @@ node dist/scripts/mkctl.js run --file examples/configs/tty-grep.yml --duration 3
 ```
 
 **Tail colored logs:**
+
 ```bash
 # Watch a log file with color highlighting
 node dist/scripts/mkctl.js run --file examples/configs/tty-tail-logs.yml --duration 10
@@ -346,10 +367,10 @@ node dist/scripts/mkctl.js run --file examples/configs/tty-external-alt.yml --du
 
 ### When to Use TTYRenderer vs ConsoleSink
 
-| Module | Use Case |
-|--------|----------|
+| Module               | Use Case                                                                  |
+| -------------------- | ------------------------------------------------------------------------- |
 | **XtermTTYRenderer** | Commands with ANSI colors, terminal control sequences, or rich formatting |
-| **ConsoleSink** | Plain text logs, structured data, or when you need prefix/formatting |
+| **ConsoleSink**      | Plain text logs, structured data, or when you need prefix/formatting      |
 
 ---
 
@@ -393,6 +414,7 @@ node dist/src/examples/tty-renderer-demo.js
 ### What You'll See
 
 The demo will:
+
 1. Enter alternate screen buffer (clears your terminal view)
 2. Spawn a bash shell in a PTY
 3. Send the command: `echo "xterm TTY renderer demo"`
@@ -411,6 +433,7 @@ echo "xterm TTY renderer demo"
 ```
 
 The output includes:
+
 - ANSI escape codes for colors (e.g., `[01;32m` for green bold text)
 - Bracketed paste mode sequences (`[?2004h` and `[?2004l`)
 - Terminal title sequences (`]0;...`)
@@ -467,10 +490,12 @@ npm run build
 **Problem:** Insufficient permissions to create a PTY.
 
 **macOS Solution:**
+
 - Check System Preferences → Security & Privacy → Privacy → Developer Tools
 - Grant Terminal.app or your terminal emulator full disk access
 
 **Linux Solution:**
+
 - Ensure your user is in the `tty` group:
   ```bash
   groups | grep tty
@@ -539,8 +564,8 @@ This demo uses mkolbol's **ExternalProcess** support with PTY mode. The PTYServe
 ```yaml
 params:
   command: /bin/bash
-  ioMode: 'pty'                    # PTY mode (vs. stdio)
-  terminalType: 'xterm-256color'   # Terminal emulation
+  ioMode: 'pty' # PTY mode (vs. stdio)
+  terminalType: 'xterm-256color' # Terminal emulation
 ```
 
 To understand how to configure external processes from YAML/JSON files, see **[Wiring and Testing](./wiring-and-tests.md#external-process-configuration)** guide.
@@ -552,11 +577,13 @@ For non-interactive data pipelines using `stdio` mode, see the **[StdIO Path](./
 Congratulations on running your first topology! Here's what to explore next:
 
 ### Continue Your Journey
+
 - **[Early Adopter Guide - Quick Start](./early-adopter-guide.md#quick-start-choose-your-path)** - Choose your next path (build, deploy, or dive deeper)
 - **[Interactive Topology](./interactive-topology.md)** - Build keyboard → PTY → TTY pipelines
 - **[StdIO Path](./stdio-path.md)** - Explore non-interactive data processing
 
 ### Learn More
+
 - **[Wiring and Testing](./wiring-and-tests.md)** - Configuration and testing with external processes
 - **[First Server Tutorial](./first-server-tutorial.md)** - Build your first custom module
 - **[Stream Kernel RFC](../rfcs/stream-kernel/00-index.md)** - Architecture deep dive
diff --git a/docs/devex/recipes.md b/docs/devex/recipes.md
index c63a8c5..b8bf3dc 100644
--- a/docs/devex/recipes.md
+++ b/docs/devex/recipes.md
@@ -17,6 +17,7 @@ mk recipes --show http-logs-jsonl
 ## Available Recipes
 
 ### tee-filesink
+
 **Description**: Duplicate output to console and file simultaneously  
 **Use Case**: Log to file while monitoring console output  
 **Tags**: logging, monitoring, fan-out
@@ -24,6 +25,7 @@ mk recipes --show http-logs-jsonl
 **Pattern**: Timer → Tee → [Console, FileSink]
 
 **When to use**:
+
 - Need both live console output and persistent logs
 - Debugging while capturing full session
 - Multi-destination output
@@ -31,6 +33,7 @@ mk recipes --show http-logs-jsonl
 ---
 
 ### rate-limit
+
 **Description**: Throttle message flow with token bucket rate limiting  
 **Use Case**: Prevent overwhelming downstream systems  
 **Tags**: rate-limiting, backpressure, throttling
@@ -38,12 +41,14 @@ mk recipes --show http-logs-jsonl
 **Pattern**: Source → RateLimiter → Sink
 
 **When to use**:
+
 - API rate limiting
 - Resource protection
 - Burst smoothing
 - Fair queuing
 
 **Configuration options**:
+
 - `capacity`: Token bucket size
 - `refillRate`: Tokens per interval
 - `refillInterval`: Refill frequency (ms)
@@ -51,6 +56,7 @@ mk recipes --show http-logs-jsonl
 ---
 
 ### http-logs-jsonl
+
 **Description**: Fetch HTTP responses and log as JSONL with metrics  
 **Use Case**: API monitoring and structured logging  
 **Tags**: http, logging, metrics, jsonl
@@ -58,12 +64,14 @@ mk recipes --show http-logs-jsonl
 **Pattern**: ExternalProcess (curl) → PipeMeter → FileSink (JSONL)
 
 **When to use**:
+
 - HTTP endpoint monitoring
 - API response logging
 - Structured log analysis
 - Throughput measurement
 
 **Features**:
+
 - JSONL format for easy parsing (jq, logq)
 - Throughput metrics (bytes/sec, msg/sec)
 - Timestamped entries
@@ -71,6 +79,7 @@ mk recipes --show http-logs-jsonl
 ---
 
 ### transform-chain
+
 **Description**: Chain multiple transforms for data processing pipeline  
 **Use Case**: Multi-stage data transformation  
 **Tags**: pipeline, transform, processing
@@ -78,12 +87,14 @@ mk recipes --show http-logs-jsonl
 **Pattern**: Source → Transform1 → Transform2 → ... → Sink
 
 **When to use**:
+
 - Multi-step processing
 - Data enrichment pipelines
 - Format conversions
 - Filtering and routing
 
 **Example transforms**:
+
 - UppercaseTransform
 - PipeMeterTransform (metrics)
 - RateLimiterTransform (throttling)
@@ -92,6 +103,7 @@ mk recipes --show http-logs-jsonl
 ---
 
 ### health-check
+
 **Description**: External process with startup health verification  
 **Use Case**: Ensure service is healthy before routing traffic  
 **Tags**: health-check, external-process, reliability
@@ -99,16 +111,19 @@ mk recipes --show http-logs-jsonl
 **Pattern**: ExternalProcess (with healthCheck) → Sink
 
 **When to use**:
+
 - Running external services (HTTP servers, daemons)
 - Need startup verification
 - Circuit breaker patterns
 - Graceful degradation
 
 **Health check types**:
+
 - **HTTP**: GET request, expect 2xx status
 - **Command**: Shell command, expect exit 0
 
 **Configuration**:
+
 ```yaml
 healthCheck:
   type: http
@@ -124,6 +139,7 @@ healthCheck:
 To create your own recipe:
 
 1. Start with an existing recipe as template:
+
    ```bash
    mk recipes --show tee-filesink > my-topology.yml
    ```
@@ -131,6 +147,7 @@ To create your own recipe:
 2. Modify for your use case
 
 3. Test with `mk run`:
+
    ```bash
    mk run my-topology.yml --dry-run   # Validate
    mk run my-topology.yml              # Execute
diff --git a/docs/devex/releases.md b/docs/devex/releases.md
index 9d1f29a..1b2fbfc 100644
--- a/docs/devex/releases.md
+++ b/docs/devex/releases.md
@@ -1,6 +1,7 @@
 # mkolbol Releases
 
 This guide covers:
+
 1. **Release Candidate (RC)** - Current status, features, install paths, known limitations
 2. **Creating Releases** - For maintainers: how to publish new versions
 3. **Consuming Releases** - For users: how to install specific versions
@@ -16,6 +17,7 @@ This guide covers:
 This RC delivers the complete **Local Node v1.0** experience with:
 
 #### Core Features
+
 - ✅ **Stream Kernel** - ~100 line microkernel with pipes, connect, split, merge
 - ✅ **Local Node Mode** - In-process routing (MK_LOCAL_NODE=1 enforced)
 - ✅ **Router & Hostess** - Endpoint discovery and health monitoring
@@ -23,6 +25,7 @@ This RC delivers the complete **Local Node v1.0** experience with:
 - ✅ **mkctl CLI** - Run topologies (`mkctl run`) and inspect endpoints (`mkctl endpoints`)
 
 #### Modules (Production-Ready)
+
 - ✅ **ExternalProcess** - Spawn external processes (stdio/pty modes)
 - ✅ **FilesystemSink** - Write to files (JSONL, raw, append/truncate modes)
 - ✅ **ConsoleSink** - Console output with prefixes
@@ -31,6 +34,7 @@ This RC delivers the complete **Local Node v1.0** experience with:
 - ✅ **UppercaseTransform** - String transformation example
 
 #### Developer Experience (RC)
+
 - ✅ **mk CLI** - Project scaffolding and workflow orchestrator
   - `mk init` - Initialize projects with templates (hello-calculator)
   - `mk run` - Execute topologies with validation
@@ -50,6 +54,7 @@ This RC delivers the complete **Local Node v1.0** experience with:
 **See [Distribution Matrix](./distribution.md) for complete installation guide.**
 
 #### Method 1: Tarball (Recommended for RC)
+
 ```bash
 # Download from GitHub Releases (when published)
 curl -L https://github.com/anteew/mkolbol/releases/download/v1.0.0-rc.1/mkolbol-1.0.0-rc.1.tar.gz \
@@ -60,6 +65,7 @@ npm install ./mkolbol-1.0.0-rc.1.tar.gz
 ```
 
 #### Method 2: Git Tag (For Development)
+
 ```bash
 # Clone specific RC tag
 git clone --branch v1.0.0-rc.1 https://github.com/anteew/mkolbol.git mkolbol-rc
@@ -69,11 +75,13 @@ npm run build
 ```
 
 #### Method 3: npm Registry
+
 > **Not Yet Available**: mkolbol is not published to npm. Use tarball or git tag.
 
 ### Known Limitations (RC)
 
 #### mk CLI Implementation Status
+
 - ⚠️ **Partial Implementation**: Most mk commands return placeholder help text (implementation in progress)
 - ⚠️ **No Wizard Mode**: `mk init` requires inline args (`--lang ts --preset tty`), no interactive prompts yet
 - ⚠️ **No Hot Reload**: `mk dev` not yet implemented (manual restart required)
@@ -82,22 +90,26 @@ npm run build
 - ⚠️ **Did-You-Mean**: Typo suggestions not yet implemented (generic error messages)
 
 #### Local Node Mode Only
+
 - ⚠️ **Single Machine**: Distributed routing (multi-machine topologies) not yet available
 - ⚠️ **In-Process Only**: Worker threads and external process modes limited
 - ⚠️ **Network Features Gated**: MK_LOCAL_NODE=1 disables network transports
 
 #### Module Ecosystem
+
 - ⚠️ **Limited Modules**: 6 core modules available, community modules not yet published
 - ⚠️ **No Plugin System**: Custom modules require code changes (no dynamic loading)
 - ⚠️ **TTY Rendering**: XtermTTYRenderer module not yet fully integrated
 
 #### Testing & CI
+
 - ⚠️ **Non-Gating Smoke Tests**: Acceptance tests run but don't block PRs
 - ⚠️ **Flake Detection**: Laminar trends available but not enforced
 
 ### Roadmap to v1.0.0
 
 **Before Final Release:**
+
 - [ ] Implement mk dev (hot reload)
 - [ ] Implement mk logs (structured log streaming)
 - [ ] Implement mk trace (latency analysis)
@@ -107,6 +119,7 @@ npm run build
 - [ ] Add performance benchmarks
 
 **Future (v1.1+):**
+
 - [ ] Distributed routing (multi-machine topologies)
 - [ ] Worker thread support
 - [ ] Plugin system for dynamic module loading
@@ -116,6 +129,7 @@ npm run build
 ### Getting Started
 
 **Quickest Path (10 minutes):**
+
 1. Read [First Five Minutes Guide](./first-five-minutes.md)
 2. Run the hello-calculator example:
    ```bash
@@ -130,6 +144,7 @@ npm run build
 3. Explore [Recipes](./recipes.md) for more patterns
 
 **Deep Dive:**
+
 - [Early Adopter Guide](./early-adopter-guide.md) - Architecture and concepts
 - [mkctl Cookbook](./mkctl-cookbook.md) - Daily CLI reference
 - [Authoring a Module](./authoring-a-module.md) - Write custom modules
@@ -191,14 +206,17 @@ Create or update `CHANGELOG.md`:
 ## [0.2.0] - 2025-10-16
 
 ### Added
+
 - Distribution matrix documentation
 - Tarball-first installation path
 - GitHub Releases workflow
 
 ### Fixed
+
 - Bug fixes from 0.1.0
 
 ### Changed
+
 - Documentation restructuring
 ```
 
diff --git a/docs/devex/rfcs/0001-mkolbol-init.md b/docs/devex/rfcs/0001-mkolbol-init.md
index a69ce80..66744b5 100644
--- a/docs/devex/rfcs/0001-mkolbol-init.md
+++ b/docs/devex/rfcs/0001-mkolbol-init.md
@@ -20,6 +20,7 @@ Early adopters face friction when starting with mkolbol. The current workflow re
 7. Configuring CI for testing
 
 This takes 30-60 minutes and is error-prone. New users must:
+
 - Study existing examples to understand project structure
 - Copy-paste boilerplate from documentation
 - Manually configure build tooling
@@ -65,21 +66,23 @@ A CLI scaffolder that generates a complete, working mkolbol module project. User
 
 ### Option Analysis
 
-| Approach | Command | Pros | Cons |
-|----------|---------|------|------|
-| **A: npm create** | `npm create mkolbol@latest my-project` | Standard npm convention, familiar to users, auto-installs latest | Requires separate package `create-mkolbol` |
-| **B: npx** | `npx mkolbol-create my-project` | Simpler to publish, one package | Less discoverable, manual version management |
-| **C: Integrated** | `npx mkolbol init` | Ships with main package, no extra install | Bloats main package, version coupling |
+| Approach          | Command                                | Pros                                                             | Cons                                         |
+| ----------------- | -------------------------------------- | ---------------------------------------------------------------- | -------------------------------------------- |
+| **A: npm create** | `npm create mkolbol@latest my-project` | Standard npm convention, familiar to users, auto-installs latest | Requires separate package `create-mkolbol`   |
+| **B: npx**        | `npx mkolbol-create my-project`        | Simpler to publish, one package                                  | Less discoverable, manual version management |
+| **C: Integrated** | `npx mkolbol init`                     | Ships with main package, no extra install                        | Bloats main package, version coupling        |
 
 ### Recommendation: Option A (`npm create mkolbol`)
 
 **Rationale:**
+
 - Industry standard pattern (Vite, Next.js, React all use `npm create`)
 - Auto-fetches latest version without user intervention
 - Clear separation: `mkolbol` = runtime, `create-mkolbol` = scaffolder
 - Better discoverability via npm registry search
 
 **Implementation:**
+
 - Publish separate package: `create-mkolbol`
 - Entry point: `index.js` with shebang
 - Users invoke: `npm create mkolbol@latest`
@@ -158,6 +161,7 @@ my-awesome-module/
 #### 1. `package.json`
 
 **Transform variant:**
+
 ```json
 {
   "name": "my-awesome-module",
@@ -213,7 +217,7 @@ export class MyAwesomeModule {
         // TODO: Implement your transformation logic here
         const output = chunk; // Replace with actual transformation
         callback(null, output);
-      }
+      },
     });
 
     this.inputPipe.pipe(transformer).pipe(this.outputPipe);
@@ -249,7 +253,7 @@ describe('MyAwesomeModule', () => {
 
     module.inputPipe.write('test');
 
-    await new Promise(resolve => setTimeout(resolve, 100));
+    await new Promise((resolve) => setTimeout(resolve, 100));
 
     expect(received.length).toBeGreaterThan(0);
   });
@@ -295,22 +299,26 @@ A mkolbol transform module generated with `npm create mkolbol`.
 ## Getting Started
 
 ### Install Dependencies
+
 \`\`\`bash
 npm install
 \`\`\`
 
 ### Build
+
 \`\`\`bash
 npm run build
 \`\`\`
 
 ### Test
+
 \`\`\`bash
 npm test
-npm run test:watch  # Watch mode
+npm run test:watch # Watch mode
 \`\`\`
 
 ### Run Example
+
 \`\`\`bash
 npm run dev
 \`\`\`
@@ -346,19 +354,21 @@ MIT
 **Requirement:** All dependencies use exact versions (no `^` or `~`).
 
 **Rationale:**
+
 - Deterministic builds across environments
 - Avoid breakage from transitive dependency updates
 - Users can manually upgrade after reviewing changes
 
 **Implementation:**
+
 ```json
 {
   "dependencies": {
-    "mkolbol": "0.2.0"  // NOT "^0.2.0"
+    "mkolbol": "0.2.0" // NOT "^0.2.0"
   },
   "devDependencies": {
-    "typescript": "5.6.2",  // Exact version
-    "vitest": "1.6.0"       // Exact version
+    "typescript": "5.6.2", // Exact version
+    "vitest": "1.6.0" // Exact version
   }
 }
 ```
@@ -368,11 +378,13 @@ MIT
 **Requirement:** Same inputs produce identical output every time.
 
 **No:**
+
 - Randomized IDs or timestamps in generated code
 - Non-deterministic ordering of imports/exports
 - Environment-dependent paths
 
 **Yes:**
+
 - Fixed file structure
 - Alphabetical import ordering
 - Absolute paths resolved at runtime, not generation time
@@ -384,11 +396,13 @@ MIT
 **Requirement:** Generated projects cannot modify mkolbol kernel internals.
 
 **Enforcement:**
+
 - Templates import from `mkolbol` as a library
 - No direct kernel source file modifications
 - Documentation emphasizes "build on top, not inside"
 
 **Violation example (prohibited):**
+
 ```typescript
 // BAD: Modifying kernel internals
 import { Kernel } from 'mkolbol';
@@ -396,12 +410,13 @@ Kernel.prototype.myCustomMethod = function() { ... };
 ```
 
 **Correct approach:**
+
 ```typescript
 // GOOD: Building on kernel APIs
 import { Kernel } from 'mkolbol';
 export class MyModule {
   constructor(kernel: Kernel) {
-    this.pipe = kernel.createPipe();  // Use public APIs
+    this.pipe = kernel.createPipe(); // Use public APIs
   }
 }
 ```
@@ -409,17 +424,20 @@ export class MyModule {
 ### 4. Convention Adherence
 
 **Naming:**
+
 - PascalCase for class names: `MyAwesomeModule`
 - camelCase for file names: `myAwesomeModule.spec.ts`
 - Descriptive pipe names: `inputPipe`, `outputPipe`, `errorPipe`
 
 **Directory Structure:**
+
 - `src/` for source code
 - `tests/` for test files (NOT `__tests__` or `spec/`)
 - `dist/` for compiled output
 - `.github/workflows/` for CI
 
 **TypeScript:**
+
 - Strict mode enabled
 - ES modules (`"type": "module"`)
 - Source maps for debugging
@@ -431,20 +449,24 @@ export class MyModule {
 ### Technology Choice
 
 **CLI Framework:** [Commander.js](https://github.com/tj/commander.js)
+
 - Industry standard (used by Vite, Angular CLI, Create React App)
 - Lightweight, minimal dependencies
 - Well-documented
 
 **Prompts:** [prompts](https://github.com/terkelg/prompts)
+
 - Lightweight, aesthetic, cancellable
 - Better UX than inquirer (smaller, faster)
 
 **Template Engine:** String interpolation + file system operations
+
 - No complex templating (Mustache, Handlebars) needed
 - Simple variable substitution in template files
 - Easier to maintain, debug
 
 **File Operations:** Node.js `fs` module
+
 - Native, zero dependencies for this part
 - Sufficient for copying files, replacing placeholders
 
@@ -485,6 +507,7 @@ create-mkolbol/
 4. **Documentation:** Scaffolder README lists kernel compatibility matrix
 
 **Example:**
+
 ```json
 // create-mkolbol/package.json
 {
@@ -497,6 +520,7 @@ create-mkolbol/
 ```
 
 **Process:**
+
 1. mkolbol kernel releases v0.3.0
 2. CI runs: `npm create mkolbol@latest test-project && cd test-project && npm test`
 3. If tests fail, open issue: "Scaffolder templates incompatible with v0.3.0"
@@ -520,6 +544,7 @@ create-mkolbol/
 - **Template quality:** Generated code passes linting, tests, and CI without modification
 
 **How to measure:**
+
 - Telemetry: Optional anonymous ping on successful generation (opt-in)
 - Surveys: Periodic feedback forms in README
 - GitHub metrics: Issues tagged `scaffolder`, discussion activity
@@ -535,6 +560,7 @@ create-mkolbol/
 **Impact:** High - users get bad first impression, churn increases.
 
 **Mitigation:**
+
 - CI pipeline runs scaffolder against latest kernel on every commit
 - Automated tests: scaffold project → build → run tests → verify
 - Version compatibility matrix in documentation
@@ -551,6 +577,7 @@ create-mkolbol/
 **Impact:** Medium - maintenance burden, bugs, slow iteration.
 
 **Mitigation:**
+
 - Strict scope: P1 = 2 templates only (Transform, External)
 - Feature requests go to backlog (P2/P3)
 - YAGNI principle: only implement when users ask repeatedly
@@ -567,12 +594,14 @@ create-mkolbol/
 **Impact:** Medium - scaffolder generates broken projects until updated.
 
 **Mitigation:**
+
 - Quarterly dependency review (check changelogs)
 - Test matrix: Node 20, 22, 24 (current LTS + next)
 - Document upgrade path in scaffolder README
 - Pin to LTS versions by default
 
 **Process:**
+
 - Dependabot alerts → review → test → bump version → release
 
 ---
@@ -584,11 +613,13 @@ create-mkolbol/
 **Goal:** Support Python, Go, Rust external modules.
 
 **Template additions:**
+
 - `external-python/` - Uses `ExternalServerWrapper` + Python script
 - `external-go/` - Compiles Go binary, wraps in TypeScript
 - `external-rust/` - Similar pattern
 
 **UX:**
+
 ```bash
 ? Server type:
   ○ Transform (TypeScript, in-process)
@@ -607,11 +638,13 @@ create-mkolbol/
 **Goal:** Generate routing modules, middleware, protocol adapters.
 
 **Templates:**
+
 - `routing-server/` - Service mesh routing example
 - `mcp-adapter/` - MCP protocol wrapper
 - `middleware/` - Auth, logging, metrics
 
 **UX:**
+
 ```bash
 ? Module category:
   ○ Basic (Transform/External)
@@ -629,6 +662,7 @@ create-mkolbol/
 **Goal:** Production-ready templates with Docker, K8s, monitoring.
 
 **Includes:**
+
 - Dockerfile + docker-compose.yml
 - Kubernetes manifests
 - Prometheus metrics exporter
@@ -653,6 +687,7 @@ create-mkolbol/
 6. **Mitigations in place:** CI checks, version pinning, quarterly audits
 
 **Implementation Effort:** 1 developer, 3-5 days
+
 - Day 1: CLI setup (Commander, prompts)
 - Day 2: Transform template + tests
 - Day 3: External template + tests
@@ -660,6 +695,7 @@ create-mkolbol/
 - Day 5: Integration tests, polish, publish
 
 **Approval Criteria:**
+
 - [ ] CLI generates valid project (npm install, build, test all pass)
 - [ ] Both templates (Transform, External) tested
 - [ ] CI workflow runs successfully on GitHub Actions
@@ -748,6 +784,7 @@ $ npm run dev
 ```
 
 **User now has:**
+
 - Working module skeleton
 - Passing tests
 - Runnable example
diff --git a/docs/devex/stdio-path.md b/docs/devex/stdio-path.md
index 9929d08..0687a2e 100644
--- a/docs/devex/stdio-path.md
+++ b/docs/devex/stdio-path.md
@@ -7,6 +7,7 @@ The **StdIO path** in mkolbol provides a lightweight way to communicate with ext
 ## When to Use StdIO vs PTY
 
 ### Use StdIO when:
+
 - Your external process is a simple filter or transformer (e.g., `cat`, `jq`, `sed`)
 - You're piping plain text or binary data
 - You don't need terminal control sequences (cursor movement, colors, etc.)
@@ -14,6 +15,7 @@ The **StdIO path** in mkolbol provides a lightweight way to communicate with ext
 - Your process doesn't require a controlling terminal
 
 ### Use PTY when:
+
 - You need to run an interactive shell (e.g., `bash`, `zsh`)
 - Your process expects terminal capabilities (e.g., `vim`, `less`, `top`)
 - You need to handle ANSI escape sequences for colors/formatting
@@ -75,20 +77,20 @@ const manifest: ExternalServerManifest = {
   terminals: [
     { name: 'input', type: 'local', direction: 'input' },
     { name: 'output', type: 'local', direction: 'output' },
-    { name: 'error', type: 'local', direction: 'output' }
+    { name: 'error', type: 'local', direction: 'output' },
   ],
   capabilities: {
     type: 'transform',
     accepts: ['text'],
     produces: ['text'],
-    features: ['passthrough']
+    features: ['passthrough'],
   },
   command: '/bin/cat',
   args: [],
   env: {},
   cwd: process.cwd(),
-  ioMode: 'stdio',  // ← StdIO mode
-  restart: 'never'
+  ioMode: 'stdio', // ← StdIO mode
+  restart: 'never',
 };
 ```
 
@@ -103,6 +105,7 @@ The kernel creates standard Node.js `Duplex` streams that connect your applicati
 ### 3. No PTY Emulation
 
 Unlike PTY mode, StdIO mode:
+
 - Does **not** allocate a pseudo-terminal device
 - Does **not** handle terminal control sequences
 - Does **not** maintain terminal state (cursor position, scrollback, etc.)
@@ -112,7 +115,7 @@ Unlike PTY mode, StdIO mode:
 
 See [src/examples/stdio-echo-demo.ts](../../src/examples/stdio-echo-demo.ts) for a complete working example:
 
-```bash
+````bash
 # Build the project
 npm run build
 
@@ -126,14 +129,16 @@ When you launch a topology with `mkctl run`, the executor now publishes endpoint
 ```bash
 mkctl run --file examples/configs/external-stdio.yaml --duration 2
 mkctl endpoints
-```
+````
 
 Typical output lists endpoint IDs, coordinates, and the timestamp of the last announcement so you can confirm your StdIO adapters came online.
+
 ```
 
 ### Expected Output
 
 ```
+
 [stdio-echo-demo] Starting echo demo with stdio mode...
 
 [SEND] Hello from StdIO!
@@ -143,7 +148,8 @@ Typical output lists endpoint IDs, coordinates, and the timestamp of the last an
 
 [stdio-echo-demo] Demo completed successfully!
 [SUMMARY] Sent 2 messages, received 2 lines
-```
+
+````
 
 ## Performance Characteristics
 
@@ -171,7 +177,7 @@ wrapper.inputPipe.write(JSON.stringify({ name: 'test' }));
 wrapper.outputPipe.on('data', (data) => {
   console.log('Filtered:', data.toString());
 });
-```
+````
 
 ### 2. Batch Processor
 
@@ -180,7 +186,7 @@ const processor: ExternalServerManifest = {
   // ... manifest fields
   command: '/usr/bin/sed',
   args: ['s/foo/bar/g'],
-  ioMode: 'stdio'
+  ioMode: 'stdio',
 };
 
 // Send multiple lines
@@ -196,7 +202,7 @@ const compressor: ExternalServerManifest = {
   // ... manifest fields
   command: '/usr/bin/gzip',
   args: ['-c'],
-  ioMode: 'stdio'
+  ioMode: 'stdio',
 };
 
 wrapper.inputPipe.write(Buffer.from('binary data'));
@@ -237,14 +243,17 @@ await wrapper.shutdown(2000); // 2 second timeout
 ## Comparison with Other Patterns
 
 ### vs PTY Mode
+
 - **StdIO**: Direct pipes, no terminal emulation, best for data processing
 - **PTY**: Terminal emulation, ANSI support, best for interactive programs
 
 ### vs Worker Threads
+
 - **StdIO**: External processes, separate memory space, any language
 - **Worker Threads**: JavaScript only, shared memory, lower startup cost
 
 ### vs HTTP/WebSocket
+
 - **StdIO**: Local processes, low latency, no network overhead
 - **HTTP/WebSocket**: Network-capable, higher latency, standard protocols
 
@@ -285,6 +294,7 @@ Metadata:    {"cols":80,"rows":24,"terminalType":"xterm-256color","ioMode":"pty"
 ```
 
 **Key fields:**
+
 - **IO Mode: stdio** - Lightweight pipe-based process (no terminal emulation)
 - **IO Mode: pty** - Pseudo-terminal process (interactive, terminal emulation)
 - **Type: external** - External process (vs inproc, worker)
diff --git a/docs/devex/troubleshooting.md b/docs/devex/troubleshooting.md
index a5dd393..2716ee3 100644
--- a/docs/devex/troubleshooting.md
+++ b/docs/devex/troubleshooting.md
@@ -11,6 +11,7 @@ Running into issues? This guide maps common errors to solutions.
 **Cause**: Native dependencies not built for your platform
 
 **Fix**:
+
 ```bash
 # 1. Ensure build tools are installed
 # macOS:
@@ -34,6 +35,7 @@ npm install
 **Cause**: Package not installed or wrong directory
 
 **Fix**:
+
 ```bash
 # Install locally in your project
 npm install mkolbol
@@ -56,6 +58,7 @@ npx lam init
 **Cause**: The `mkctl` script is in `dist/scripts/`
 
 **Fix**:
+
 ```bash
 # Use the full path
 node dist/scripts/mkctl.js run --file examples/configs/basic.yml
@@ -71,6 +74,7 @@ npm run build
 **Cause**: Config file path is wrong or relative path is off
 
 **Fix**:
+
 ```bash
 # Check the file exists
 ls examples/configs/
@@ -89,6 +93,7 @@ ls -la examples/configs/
 **Cause**: YAML syntax error (indentation, colons, quotes)
 
 **Fix**:
+
 ```yaml
 # ✗ Wrong
 nodes:
@@ -104,6 +109,7 @@ nodes:
 ```
 
 Validate your YAML before running:
+
 ```bash
 # Use an online validator: https://www.yamllint.com/
 # Or pipe to Python validator:
@@ -117,6 +123,7 @@ python3 -m yaml examples/configs/my-topology.yml
 **Cause**: Command path doesn't exist or isn't in PATH
 
 **Fix**:
+
 ```yaml
 # ✗ Wrong
 nodes:
@@ -136,6 +143,7 @@ nodes:
 ```
 
 Verify the command exists:
+
 ```bash
 which jq        # Find path
 /usr/bin/jq --version  # Test it
@@ -152,12 +160,14 @@ which jq        # Find path
 **Cause**: Insufficient terminal permissions
 
 **macOS Fix**:
+
 ```
 System Preferences → Security & Privacy → Privacy → Developer Tools
 → Add Terminal.app (or your terminal emulator)
 ```
 
 **Linux Fix**:
+
 ```bash
 # Check if user is in tty group
 groups | grep tty
@@ -175,6 +185,7 @@ sudo usermod -a -G tty $USER
 **Cause**: `lam` not in PATH or not installed
 
 **Fix**:
+
 ```bash
 # Install locally (recommended)
 npm install mkolbol
@@ -195,6 +206,7 @@ lam init
 **Cause**: Terminal state not reset properly after PTY exit
 
 **Fix**:
+
 ```bash
 # Reset terminal to clean state
 reset
@@ -217,6 +229,7 @@ stty sane
 **Cause**: Running on Node 18 or earlier
 
 **Fix**:
+
 ```bash
 # Check your version
 node --version
@@ -239,6 +252,7 @@ node --version  # Should be v20.x.x or v24.x.x
 **Cause**: version-specific behavior differences
 
 **Fix**:
+
 ```bash
 # Test on both supported versions
 nvm use 20
@@ -263,19 +277,21 @@ nvm use
 **Cause**: Command path wrong, or process exiting immediately
 
 **Fix**:
+
 ```yaml
 # Verify command and args
 nodes:
   - id: my-process
     module: ExternalProcess
     params:
-      command: /bin/bash  # Use absolute path
-      args: ["-c", "cat"]  # Test: /bin/bash -c "cat"
+      command: /bin/bash # Use absolute path
+      args: ['-c', 'cat'] # Test: /bin/bash -c "cat"
       cwd: /tmp
       ioMode: stdio
 ```
 
 Test the command manually:
+
 ```bash
 # Test command directly
 /bin/bash -c "cat"
@@ -291,6 +307,7 @@ node dist/scripts/mkctl.js run --file examples/configs/external-stdio.yaml --dur
 **Cause**: Wrong ioMode for the process
 
 **Fix**:
+
 ```yaml
 # ✗ Wrong: interactive shell on stdio
 nodes:
@@ -310,6 +327,7 @@ nodes:
 ```
 
 **Quick guide**:
+
 - **stdio**: For filters, data processing, non-interactive programs
 - **pty**: For shells, TUI apps, anything needing terminal features
 
@@ -326,6 +344,7 @@ See **[I/O Modes Guide](./wiring-and-tests.md#i-o-modes)** for more details.
 **Cause**: Missing `.end()` call or process not terminating
 
 **Fix**:
+
 ```typescript
 // ✗ Hangs
 wrapper.inputPipe.write('data\n');
@@ -333,7 +352,7 @@ wrapper.inputPipe.write('data\n');
 
 // ✓ Works
 wrapper.inputPipe.write('data\n');
-wrapper.inputPipe.end();  // ← Signal EOF
+wrapper.inputPipe.end(); // ← Signal EOF
 ```
 
 ### "Tests fail locally but pass in CI"
@@ -343,9 +362,10 @@ wrapper.inputPipe.end();  // ← Signal EOF
 **Cause**: Fixed timeouts too short for your hardware
 
 **Fix**: Use event-driven waiting instead of timers:
+
 ```typescript
 // ✗ Bad (fixed timeout)
-await new Promise(resolve => setTimeout(resolve, 500));
+await new Promise((resolve) => setTimeout(resolve, 500));
 
 // ✓ Good (event-driven)
 await new Promise<void>((resolve) => {
@@ -360,6 +380,7 @@ await new Promise<void>((resolve) => {
 **Cause**: Flag not set or tests gated
 
 **Fix**:
+
 ```bash
 # Enable executor integration tests
 MK_DEVEX_EXECUTOR=1 npm run test:pty
@@ -379,6 +400,7 @@ MK_DEVEX_EXECUTOR=1 npm run test:pty:lam
 **Cause**: Topology never ran or Hostess didn't register
 
 **Fix**:
+
 ```bash
 # 1. Run a topology first
 node dist/scripts/mkctl.js run --file examples/configs/basic.yml --duration 5
@@ -397,6 +419,7 @@ node dist/scripts/mkctl.js endpoints
 **Cause**: Wire (connection) defined but target module not running
 
 **Fix**:
+
 ```yaml
 # ✓ Check your connections match node IDs exactly
 nodes:
@@ -407,7 +430,7 @@ nodes:
 
 connections:
   - from: source1.output
-    to: filter1.input  # ← Must match node ID "filter1"
+    to: filter1.input # ← Must match node ID "filter1"
 ```
 
 ---
@@ -421,6 +444,7 @@ connections:
 **Cause**: Backpressure not handled, buffer bloat
 
 **Fix**:
+
 ```yaml
 # Add restart policy to shed load
 nodes:
@@ -429,7 +453,7 @@ nodes:
     params:
       command: /bin/cat
       ioMode: stdio
-      restart: on-failure  # ← Restart on crash
+      restart: on-failure # ← Restart on crash
       maxRestarts: 3
       restartDelay: 5000
 ```
@@ -441,6 +465,7 @@ nodes:
 **Cause**: Wrong ioMode (overhead), or tight loop
 
 **Fix**:
+
 ```yaml
 # Use stdio instead of pty if terminal features not needed
 params:
@@ -460,6 +485,7 @@ params:
 **Cause**: File not in watch patterns, or module runMode doesn't support hot reload
 
 **Fix**:
+
 ```bash
 # 1. Check which files are being watched
 mk dev --verbose
@@ -485,6 +511,7 @@ mk dev --dry-run
 **Cause**: Error output not being printed; compile fails but topology keeps previous version
 
 **Fix**:
+
 ```bash
 # Use verbose mode to see compile errors
 mk dev --verbose
@@ -503,20 +530,13 @@ mk doctor --section types
 **Cause**: Large codebase or many watch patterns; TypeScript compilation overhead
 
 **Fix**:
+
 ```json
 // .mk/options.json: ignore unnecessary paths
 {
   "dev": {
-    "watch": [
-      "src/**/*.ts",
-      "mk.json"
-    ],
-    "ignore": [
-      "**/*.test.ts",
-      "**/node_modules",
-      "dist/**",
-      "reports/**"
-    ]
+    "watch": ["src/**/*.ts", "mk.json"],
+    "ignore": ["**/*.test.ts", "**/node_modules", "dist/**", "reports/**"]
   }
 }
 ```
@@ -533,7 +553,7 @@ Modules should persist important state externally. For example:
 ```typescript
 // ✗ Bad: State lost on reload
 class MyModule {
-  cache: Map<string, any> = new Map();  // ← Gone on reload!
+  cache: Map<string, any> = new Map(); // ← Gone on reload!
 }
 
 // ✓ Good: State in shared storage
@@ -559,6 +579,7 @@ See **[Authoring a Module](./authoring-a-module.md)** for patterns.
 **Cause**: Topology not running or modules not outputting
 
 **Fix**:
+
 ```bash
 # 1. Verify topology is running
 mk dev --file my-topology.json &
@@ -581,6 +602,7 @@ mk logs --tail 50  # Show recent lines without watching
 **Cause**: Default is ISO 8601 UTC
 
 **Fix**:
+
 ```bash
 # Show in local time
 mk logs --timezone local --watch
@@ -602,6 +624,7 @@ mk logs --watch
 ```
 
 **Timezone options**:
+
 - `ISO` (default): 2025-10-17T10:23:45.123Z
 - `local`: Oct 17, 10:23:45 AM (respects system timezone)
 - `epoch`: 1729163025123 (milliseconds since epoch)
@@ -613,6 +636,7 @@ mk logs --watch
 **Cause**: Capturing all levels (info, debug, trace)
 
 **Fix**:
+
 ```bash
 # Filter to errors and warnings only
 mk logs --level error,warning --watch
@@ -637,6 +661,7 @@ mk logs --output debug.log --watch  # File, no console
 **Cause**: JSONL (newline-delimited) not pure JSON array
 
 **Fix**:
+
 ```bash
 # JSONL format (correct for streaming)
 mk logs --format jsonl --output logs.jsonl
@@ -659,6 +684,7 @@ jq -s '.' logs.jsonl > logs-array.json
 **Cause**: Tracing all messages; can add ~50 microseconds per message
 
 **Fix**:
+
 ```bash
 # Option 1: Trace only 10% of messages
 mk trace --sample-rate 0.1 --duration 30
@@ -671,6 +697,7 @@ mk trace --duration 60 &  # Background it
 ```
 
 **Performance targets**:
+
 - CPU overhead: ~0.5% per topology (usually negligible)
 - Latency impact: < 50 microseconds per message
 - Safe to leave enabled during development
@@ -682,6 +709,7 @@ mk trace --duration 60 &  # Background it
 **Cause**: Topology not running or no messages flowing
 
 **Fix**:
+
 ```bash
 # 1. Verify topology is active
 ps aux | grep mkctl
@@ -703,6 +731,7 @@ mk dev --file my-topology.json --graph
 **Cause**: Insufficient message volume for statistical significance
 
 **Fix**:
+
 ```bash
 # Trace for longer to collect more data
 mk trace --duration 60 --top 5
@@ -721,6 +750,7 @@ mk trace --duration 60 --top 5
 **Cause**: Module is fast (low latency) and not in top N
 
 **Fix**:
+
 ```bash
 # Increase top N to see more modules
 mk trace --duration 30 --top 20
@@ -739,6 +769,7 @@ mk trace --module my-module --duration 30
 **Cause**: Format incompatibility
 
 **Fix**:
+
 ```bash
 # Verify JSON is valid
 mk trace --format json --output trace.json
@@ -758,6 +789,7 @@ cat trace.json | head -5  # Inspect structure
 **Still stuck?**
 
 1. **Check the logs:**
+
    ```bash
    npx lam summary     # Test results
    npx lam digest      # Failure details
@@ -775,6 +807,7 @@ cat trace.json | head -5  # Inspect structure
 ---
 
 **Pro tip**: Most "failed to run" issues come down to:
+
 1. **Wrong command path** → Use absolute paths
 2. **Wrong ioMode** → Use stdio for filters, pty for shells
 3. **Missing .end()** → Always signal EOF when done writing
diff --git a/docs/devex/tty-renderer.md b/docs/devex/tty-renderer.md
index f470d05..b512157 100644
--- a/docs/devex/tty-renderer.md
+++ b/docs/devex/tty-renderer.md
@@ -36,9 +36,9 @@ nodes:
   - id: tty1
     module: TTYRenderer
     params:
-      target: stdout        # or a file path like 'logs/output.log'
-      rawMode: true         # enable raw mode (default: true)
-      stripAnsi: false      # strip ANSI codes (default: false)
+      target: stdout # or a file path like 'logs/output.log'
+      rawMode: true # enable raw mode (default: true)
+      stripAnsi: false # strip ANSI codes (default: false)
 
 connections:
   - from: source.output
@@ -48,16 +48,19 @@ connections:
 ## Options
 
 ### `target`
+
 - **Type**: `'stdout' | string`
 - **Default**: `'stdout'`
 - **Description**: Output destination. Use `'stdout'` for standard output or provide a file path.
 
 ### `rawMode`
+
 - **Type**: `boolean`
 - **Default**: `true`
 - **Description**: Enable TTY raw mode when output target is stdout. Only applies if stdout is a TTY.
 
 ### `stripAnsi`
+
 - **Type**: `boolean`
 - **Default**: `false`
 - **Description**: Remove ANSI escape sequences from output. Useful for creating plain text logs.
@@ -72,7 +75,7 @@ nodes:
     module: TimerSource
     params:
       periodMs: 1000
-  
+
   - id: tty1
     module: TTYRenderer
 
@@ -82,6 +85,7 @@ connections:
 ```
 
 Run with:
+
 ```bash
 node dist/scripts/mkctl.js run --file examples/configs/tty-basic.yml --duration 5
 ```
@@ -92,7 +96,7 @@ node dist/scripts/mkctl.js run --file examples/configs/tty-basic.yml --duration
 nodes:
   - id: source1
     module: SomeSource
-  
+
   - id: tty1
     module: TTYRenderer
     params:
@@ -112,7 +116,7 @@ This configuration preserves all ANSI codes in the output file, useful for creat
 nodes:
   - id: source1
     module: SomeSource
-  
+
   - id: tty1
     module: TTYRenderer
     params:
@@ -132,15 +136,15 @@ This removes all ANSI escape sequences, creating clean plain text logs suitable
 nodes:
   - id: source1
     module: SomeSource
-  
+
   - id: tee1
     module: TeeTransform
-  
+
   - id: tty-stdout
     module: TTYRenderer
     params:
       target: stdout
-  
+
   - id: tty-file
     module: TTYRenderer
     params:
@@ -169,17 +173,21 @@ constructor(kernel: Kernel, options?: TTYRendererOptions)
 ### Methods
 
 #### `start(): Promise<void>`
+
 Initializes the renderer. If outputting to a file, creates necessary directories and opens the file stream. If `rawMode` is enabled and stdout is a TTY, sets raw mode.
 
 #### `stop(): Promise<void>`
+
 Gracefully stops the renderer. If `rawMode` was enabled, restores normal mode. If outputting to a file, closes the file stream.
 
 #### `destroy(): void`
+
 Forcefully destroys the renderer and any open file streams.
 
 ### Properties
 
 #### `inputPipe: Pipe`
+
 The input pipe that accepts data for rendering.
 
 ## TTY vs Non-TTY Behavior
@@ -214,29 +222,32 @@ node dist/scripts/mkctl.js run --file examples/configs/tty-basic.yml | cat
 
 ## Comparison with Other Renderers
 
-| Feature | TTYRenderer | ConsoleSink | FilesystemSink |
-|---------|-------------|-------------|----------------|
-| ANSI passthrough | ✓ | ✗ | ✓ |
-| stdout output | ✓ | ✓ (with prefix) | ✗ |
-| File output | ✓ | ✗ | ✓ |
-| ANSI stripping | ✓ | ✗ | ✗ |
-| Raw mode | ✓ | ✗ | ✗ |
-| Timestamps | ✗ | ✗ | ✓ |
-| JSONL format | ✗ | ✓ | ✓ |
-| Statistics | ✗ | ✗ | ✓ |
+| Feature          | TTYRenderer | ConsoleSink     | FilesystemSink |
+| ---------------- | ----------- | --------------- | -------------- |
+| ANSI passthrough | ✓           | ✗               | ✓              |
+| stdout output    | ✓           | ✓ (with prefix) | ✗              |
+| File output      | ✓           | ✗               | ✓              |
+| ANSI stripping   | ✓           | ✗               | ✗              |
+| Raw mode         | ✓           | ✗               | ✗              |
+| Timestamps       | ✗           | ✗               | ✓              |
+| JSONL format     | ✗           | ✓               | ✓              |
+| Statistics       | ✗           | ✗               | ✓              |
 
 **When to use TTYRenderer**:
+
 - Need simple ANSI passthrough
 - Want raw terminal output without prefixes
 - Need optional ANSI stripping
 - Want both stdout and file output with same module
 
 **When to use ConsoleSink**:
+
 - Need prefixed console output
 - Want JSONL format for logs
 - Don't need file output
 
 **When to use FilesystemSink**:
+
 - Need advanced file features (fsync, modes)
 - Want statistics tracking
 - Need timestamp injection
@@ -245,14 +256,17 @@ node dist/scripts/mkctl.js run --file examples/configs/tty-basic.yml | cat
 ## Troubleshooting
 
 ### ANSI codes not rendering in terminal
+
 - Ensure stdout is a TTY: `node -p "process.stdout.isTTY"`
 - Check terminal supports ANSI: `echo -e "\x1b[31mRed\x1b[0m"`
 
 ### File output missing ANSI codes
+
 - Verify `stripAnsi: false` (default)
 - Check file with `cat -v filename` to see escape sequences
 
 ### Raw mode not working
+
 - Verify stdout is a TTY
 - Check `target: stdout` is set
 - Ensure no process overrides `process.stdin.setRawMode`
diff --git a/docs/devex/using-mkolbol-in-your-repo.md b/docs/devex/using-mkolbol-in-your-repo.md
index fe86320..4668dfb 100644
--- a/docs/devex/using-mkolbol-in-your-repo.md
+++ b/docs/devex/using-mkolbol-in-your-repo.md
@@ -9,12 +9,14 @@ This guide shows you how to bootstrap mkolbol applications in your own repositor
 ## Overview
 
 **What is bootstrapping?**
+
 - Create a new mkolbol project from a template
 - Generate project structure, configs, and starter code
 - Install mkolbol as a dependency (tarball, git tag, or vendor)
 - Get a runnable topology in under 5 minutes
 
 **What you'll create:**
+
 - A complete hello-calculator app (3-node topology)
 - All project files (package.json, tsconfig.json, src/, .mk/)
 - Ready to run, test, and customize
@@ -26,6 +28,7 @@ This guide shows you how to bootstrap mkolbol applications in your own repositor
 **Before bootstrapping, you need mkolbol available:**
 
 1. **Clone and build mkolbol** (one-time setup):
+
    ```bash
    git clone https://github.com/anteew/mkolbol.git
    cd mkolbol
@@ -60,12 +63,14 @@ mk init hello-calculator --lang ts --preset tty
 ```
 
 **What happens:**
+
 1. Creates `hello-calculator/` directory
 2. Generates project structure (src/, .mk/, package.json, tsconfig.json)
 3. Scaffolds 3-node topology (CalculatorServer → XtermTTYRenderer → FilesystemSink)
 4. Adds README.md and .gitignore
 
 **Output:**
+
 ```
 ✓ Created hello-calculator/
 ✓ Initialized package.json
@@ -87,6 +92,7 @@ Next steps:
 Choose your distribution method (see [Distribution Matrix](./distribution.md) for details):
 
 **Option 1: Tarball (Recommended)**
+
 ```bash
 cd hello-calculator
 
@@ -100,12 +106,14 @@ npm install /path/to/mkolbol/mkolbol-0.2.0.tgz
 ```
 
 **Option 2: Git Tag**
+
 ```bash
 cd hello-calculator
 npm install github:anteew/mkolbol#v0.2.0
 ```
 
 **Option 3: Vendor (Monorepo)**
+
 ```bash
 # Copy mkolbol into your monorepo
 cp -r /path/to/mkolbol ~/my-monorepo/packages/mkolbol
@@ -130,6 +138,7 @@ curl 'http://localhost:4000/subtract?a=10&b=7' # → {"result":3}
 ```
 
 **Expected output:**
+
 ```
 [mk] Running in Local Node mode (MK_LOCAL_NODE=1): network features disabled.
 [mk] Loading config from: mk.json
@@ -230,7 +239,7 @@ export class CalculatorServer {
 
   constructor(
     private kernel: Kernel,
-    private options: { port: number; precision: number }
+    private options: { port: number; precision: number },
   ) {}
 
   start() {
@@ -262,11 +271,11 @@ export class CalculatorServer {
 
 > **Note:** mkolbol is not published to npm. Choose one of these methods:
 
-| Method | Use Case | Pros | Cons |
-|--------|----------|------|------|
-| **Tarball** | Production, CI/CD | Reproducible, version-pinned, offline installs | Manual tarball management |
-| **Git Tag** | Development, testing | Easy version switching | Requires git access |
-| **Vendor** | Monorepo, offline builds | Full control, no external deps | Repo bloat, manual updates |
+| Method      | Use Case                 | Pros                                           | Cons                       |
+| ----------- | ------------------------ | ---------------------------------------------- | -------------------------- |
+| **Tarball** | Production, CI/CD        | Reproducible, version-pinned, offline installs | Manual tarball management  |
+| **Git Tag** | Development, testing     | Easy version switching                         | Requires git access        |
+| **Vendor**  | Monorepo, offline builds | Full control, no external deps                 | Repo bloat, manual updates |
 
 ### Tarball Installation (Detailed)
 
@@ -327,6 +336,7 @@ After bootstrapping with `mk init`, customize the generated files:
 ### Customize Topology (mk.json)
 
 **Change ports:**
+
 ```json
 {
   "params": { "port": 5000, "precision": 3 }
@@ -334,6 +344,7 @@ After bootstrapping with `mk init`, customize the generated files:
 ```
 
 **Add more nodes:**
+
 ```json
 {
   "nodes": [
@@ -345,6 +356,7 @@ After bootstrapping with `mk init`, customize the generated files:
 ```
 
 **Change connections:**
+
 ```json
 {
   "connections": [
@@ -357,6 +369,7 @@ After bootstrapping with `mk init`, customize the generated files:
 ### Customize Module (src/index.ts)
 
 **Add new endpoints:**
+
 ```typescript
 if (url.pathname === '/multiply') {
   const a = parseFloat(url.searchParams.get('a') || '0');
@@ -367,6 +380,7 @@ if (url.pathname === '/multiply') {
 ```
 
 **Add request logging:**
+
 ```typescript
 console.log(`[${new Date().toISOString()}] ${req.method} ${req.url}`);
 ```
@@ -374,6 +388,7 @@ console.log(`[${new Date().toISOString()}] ${req.method} ${req.url}`);
 ### Customize Profiles (.mk/options.json)
 
 **Add staging profile:**
+
 ```json
 {
   "profiles": {
@@ -483,6 +498,7 @@ connections:
 ```
 
 **Usage:**
+
 ```bash
 # Run for 60 seconds
 npx mkctl run --file http-logging.yml --duration 60
@@ -539,7 +555,7 @@ nodes:
 
   - id: console-sink
     module: ConsoleSink
-    params: { prefix: "[console]" }
+    params: { prefix: '[console]' }
 
   - id: file-sink
     module: FilesystemSink
@@ -559,13 +575,7 @@ connections:
 ### Creating a Topology in Code
 
 ```typescript
-import {
-  Kernel,
-  Hostess,
-  StateManager,
-  Executor,
-  RoutingServer
-} from 'mkolbol';
+import { Kernel, Hostess, StateManager, Executor, RoutingServer } from 'mkolbol';
 
 async function runTopology() {
   // Create core components
@@ -583,17 +593,15 @@ async function runTopology() {
       {
         id: 'timer',
         module: 'TimerSource',
-        params: { periodMs: 1000 }
+        params: { periodMs: 1000 },
       },
       {
         id: 'console',
         module: 'ConsoleSink',
-        params: { prefix: '[log]' }
-      }
+        params: { prefix: '[log]' },
+      },
     ],
-    connections: [
-      { from: 'timer.output', to: 'console.input' }
-    ]
+    connections: [{ from: 'timer.output', to: 'console.input' }],
   };
 
   try {
@@ -601,7 +609,7 @@ async function runTopology() {
     await executor.up();
 
     // Run for 10 seconds
-    await new Promise(resolve => setTimeout(resolve, 10000));
+    await new Promise((resolve) => setTimeout(resolve, 10000));
 
     await executor.down();
   } catch (err) {
@@ -622,7 +630,10 @@ export class MyCustomModule {
   inputPipe?: NodeJS.ReadableStream;
   outputPipe?: NodeJS.WritableStream;
 
-  constructor(private kernel: Kernel, private options: any = {}) {}
+  constructor(
+    private kernel: Kernel,
+    private options: any = {},
+  ) {}
 
   start(): void {
     this.inputPipe?.on('data', (chunk: Buffer) => {
@@ -648,17 +659,20 @@ executor.registerModule('MyCustomModule', MyCustomModule);
 ### 1. Configuration Management
 
 **Do's:**
+
 - ✅ Use environment variables for paths and ports
 - ✅ Validate configs with `--dry-run` before deployment
 - ✅ Version control your topology files
 - ✅ Use absolute paths for external processes
 
 **Don'ts:**
+
 - ❌ Hardcode ports or file paths
 - ❌ Use relative paths for external commands
 - ❌ Mix logic and configuration
 
 **Example:**
+
 ```yaml
 # ❌ Bad
 nodes:
@@ -776,13 +790,13 @@ services:
 
 ### Common Issues
 
-| Issue | Solution |
-|-------|----------|
-| "Config file not found" | Use absolute path: `mkctl run --file $(pwd)/topology.yml` |
-| "Command not found" | Use full path: `/usr/bin/node` instead of `node` |
-| "Health check failed" | Verify service is running: `curl http://localhost:3000/health` |
-| "Port already in use" | Find/kill process: `lsof -i :3000 && kill -9 <pid>` |
-| "Permission denied" | Fix file permissions: `chmod 755 logs/` |
+| Issue                   | Solution                                                       |
+| ----------------------- | -------------------------------------------------------------- |
+| "Config file not found" | Use absolute path: `mkctl run --file $(pwd)/topology.yml`      |
+| "Command not found"     | Use full path: `/usr/bin/node` instead of `node`               |
+| "Health check failed"   | Verify service is running: `curl http://localhost:3000/health` |
+| "Port already in use"   | Find/kill process: `lsof -i :3000 && kill -9 <pid>`            |
+| "Permission denied"     | Fix file permissions: `chmod 755 logs/`                        |
 
 ### Getting Help
 
@@ -805,6 +819,7 @@ After bootstrapping your first project:
 ## Quick Reference
 
 **Bootstrap a new project:**
+
 ```bash
 mk init my-project --lang ts --preset tty
 cd my-project
@@ -814,12 +829,14 @@ mk run --file mk.json --duration 10
 ```
 
 **Verify your project:**
+
 ```bash
 mk doctor --file mk.json
 mk run --file mk.json --dry-run
 ```
 
 **Package for distribution:**
+
 ```bash
 mk build
 mk package
@@ -827,6 +844,7 @@ mk package
 ```
 
 **Generate CI config:**
+
 ```bash
 mk ci plan --output
 # → .github/workflows/test.yml
diff --git a/docs/devex/web-terminal-quickstart.md b/docs/devex/web-terminal-quickstart.md
index d1077b8..072c119 100644
--- a/docs/devex/web-terminal-quickstart.md
+++ b/docs/devex/web-terminal-quickstart.md
@@ -3,6 +3,7 @@
 This guide shows how to run a bash shell in your browser using mkolbol. The browser connects via WebSockets to a Node server that bridges to a PTY (bash) hosted by mkolbol.
 
 ## Prerequisites
+
 - Node.js 20+ (macOS/Linux/WSL). Ensure `node -v` prints 20.x or 24.x.
 - Interactive terminal (PTY requires a TTY).
 
@@ -17,6 +18,7 @@ node dist/src/examples/web-terminal-server.js
 ```
 
 Open the page:
+
 - http://localhost:9090
 
 Type commands in the browser terminal (ls, pwd, echo). The path is:
@@ -26,6 +28,7 @@ Browser (xterm.js) ←→ WebSocket (3001) ←→ mkolbol ←→ bash PTY ←→
 ```
 
 ## SSH port forwarding (remote server)
+
 If the server runs remotely and you browse from your laptop:
 
 ```bash
@@ -35,16 +38,18 @@ ssh -L 9090:localhost:9090 <user>@<server-host>
 ```
 
 ## Files
+
 - `src/examples/web-terminal-server.ts` — Node server that spawns bash PTY and serves the terminal page.
 - `examples/web-terminal/public/terminal.html` — HTML that embeds xterm.js and talks to the WebSocket.
 
 ## Notes
+
 - Keep `MK_LOCAL_NODE=1` exported during local trials.
 - PTY requires a TTY; run the server inside a real terminal.
 - Change ports by editing constants at the top of `web-terminal-server.ts`.
 
 ## Next steps
+
 - Add session recording with FilesystemSink.
 - Split output (TTY + JSONL) using Tee and PipeMeter.
 - Gate with a simple auth token on the WS (for multi-user setups).
-
diff --git a/docs/devex/wiring-and-tests.md b/docs/devex/wiring-and-tests.md
index 0b98f48..50ce477 100644
--- a/docs/devex/wiring-and-tests.md
+++ b/docs/devex/wiring-and-tests.md
@@ -25,20 +25,20 @@ nodes:
     module: ExternalProcess
     params:
       # Process spawn
-      command: /bin/bash              # Executable path or name
-      args: ["-c", "cat"]             # Command arguments
-      env:                            # Environment variables
-        DEBUG: "1"
-      cwd: /tmp                       # Working directory
-      
+      command: /bin/bash # Executable path or name
+      args: ['-c', 'cat'] # Command arguments
+      env: # Environment variables
+        DEBUG: '1'
+      cwd: /tmp # Working directory
+
       # I/O mode
-      ioMode: stdio                   # 'stdio' | 'pty'
-      
+      ioMode: stdio # 'stdio' | 'pty'
+
       # Restart policy
-      restart: on-failure             # 'never' | 'on-failure' | 'always'
-      restartDelay: 5000              # ms between restarts
-      maxRestarts: 3                  # Max restart attempts
-      
+      restart: on-failure # 'never' | 'on-failure' | 'always'
+      restartDelay: 5000 # ms between restarts
+      maxRestarts: 3 # Max restart attempts
+
       # PTY-specific (when ioMode: pty)
       terminalType: xterm-256color
       initialCols: 80
@@ -52,6 +52,7 @@ nodes:
 Lightweight pipe-based I/O without terminal emulation. Use for filters, data processors, and non-interactive programs.
 
 **When to use:**
+
 - Plain text or binary data processing
 - CLI tools (jq, sed, grep)
 - No ANSI/terminal control needed
@@ -65,17 +66,17 @@ nodes:
     module: TimerSource
     params:
       periodMs: 1000
-  
+
   - id: filter1
     module: ExternalProcess
     params:
       command: /bin/cat
       ioMode: stdio
-  
+
   - id: sink1
     module: ConsoleSink
     params:
-      prefix: "[filtered]"
+      prefix: '[filtered]'
 
 connections:
   - { from: source1.output, to: filter1.input }
@@ -89,6 +90,7 @@ connections:
 Pseudo-terminal emulation for interactive applications. Use for shells, TUIs, and programs requiring terminal capabilities.
 
 **When to use:**
+
 - Interactive shells (bash, zsh)
 - TUI applications (vim, htop)
 - ANSI escape sequences
@@ -107,10 +109,10 @@ nodes:
       terminalType: xterm-256color
       initialCols: 80
       initialRows: 24
-  
+
   - id: parser1
     module: AnsiParserModule
-  
+
   - id: renderer1
     module: XtermTTYRenderer
 
@@ -149,7 +151,7 @@ nodes:
 nodes:
   - { id: timer1, module: TimerSource, params: { periodMs: 1000 } }
   - { id: echo1, module: ExternalProcess, params: { command: /bin/cat, ioMode: stdio } }
-  - { id: console1, module: ConsoleSink, params: { prefix: "[echo]" } }
+  - { id: console1, module: ConsoleSink, params: { prefix: '[echo]' } }
 
 connections:
   - { from: timer1.output, to: echo1.input }
@@ -164,13 +166,13 @@ nodes:
     module: ExternalProcess
     params:
       command: /bin/bash
-      args: ["-c", "while true; do echo -e '\\e[1;32mGreen\\e[0m'; sleep 1; done"]
+      args: ['-c', "while true; do echo -e '\\e[1;32mGreen\\e[0m'; sleep 1; done"]
       ioMode: pty
       terminalType: xterm-256color
-  
+
   - id: ansi1
     module: AnsiParserModule
-  
+
   - id: console1
     module: ConsoleSink
 
@@ -188,14 +190,14 @@ nodes:
     params:
       command: /bin/bash
       ioMode: pty
-  
+
   - id: tty1
     module: XtermTTYRenderer
-  
+
   - id: log1
     module: ConsoleSink
     params:
-      prefix: "[raw]"
+      prefix: '[raw]'
 
 connections:
   - { from: shell1.output, to: tty1.input }
@@ -228,6 +230,7 @@ npx tsx examples/config-runner.ts --file examples/configs/my-topology.yml
 ```
 
 **Why mkctl run?**
+
 - Unified interface for running any topology
 - Automatically registers modules with Hostess
 - Endpoint metadata is captured for `mkctl endpoints` discovery
@@ -250,15 +253,18 @@ npm run test:ci
 ## Troubleshooting
 
 **Process not spawning:**
+
 - Check `command` path is absolute or in PATH
 - Verify `cwd` exists
 - Inspect stderr via `errorPipe`
 
 **stdio vs pty confusion:**
+
 - stdio: Binary/text data, no terminal
 - pty: Interactive, ANSI codes, terminal emulation
 
 **Restart not working:**
+
 - Ensure `restart` policy is set
 - Check `maxRestarts` limit not exceeded
 - Review `restartDelay` timing
@@ -278,11 +284,13 @@ MK_DEVEX_EXECUTOR=1 npm run test:pty:lam
 ```
 
 **What this flag does:**
+
 - Enables tests that exercise the full Executor topology loading and wiring flow
 - Requires forks lane for process-mode isolation (prevents stdio/pty cross-talk)
 - Tests complete topology lifecycle: load → up → down
 
 **Why gate executor tests?**
+
 - Executor tests spawn real processes and are resource-intensive
 - Longer execution time than basic unit tests
 - Optional for simple server implementations
diff --git a/docs/mk-bootstrap-architecture.md b/docs/mk-bootstrap-architecture.md
index 6f6aa98..90e4731 100644
--- a/docs/mk-bootstrap-architecture.md
+++ b/docs/mk-bootstrap-architecture.md
@@ -111,7 +111,7 @@ examples/mk/init-templates/
 
 ```typescript
 // Configuration
-{ 
+{
   source: 'tarball',
   tarballPath: './mkolbol-0.2.0-rfc.tgz'  // Optional
 }
@@ -136,7 +136,7 @@ examples/mk/init-templates/
 
 ```typescript
 // Configuration
-{ 
+{
   source: 'git',
   gitTag: 'v0.2.0'  // Default: 'main'
 }
diff --git a/docs/mk-logs-guide.md b/docs/mk-logs-guide.md
index 8a785dd..d1beb53 100644
--- a/docs/mk-logs-guide.md
+++ b/docs/mk-logs-guide.md
@@ -12,14 +12,14 @@ mk logs [options]
 
 ## Options
 
-| Option | Description |
-|--------|-------------|
-| `--module <name>` | Filter logs by module name (e.g., `kernel`, `router`, `executor`) |
-| `--level <level>` | Filter by log level: `error`, `warn`, `info`, or `debug` |
-| `--json` | Output logs in JSON format instead of human-readable |
-| `--follow` or `-f` | Follow log file in real-time (like `tail -f`) |
-| `--lines <n>` | Show last N lines (default: 50) |
-| `--help` | Show help message |
+| Option             | Description                                                       |
+| ------------------ | ----------------------------------------------------------------- |
+| `--module <name>`  | Filter logs by module name (e.g., `kernel`, `router`, `executor`) |
+| `--level <level>`  | Filter by log level: `error`, `warn`, `info`, or `debug`          |
+| `--json`           | Output logs in JSON format instead of human-readable              |
+| `--follow` or `-f` | Follow log file in real-time (like `tail -f`)                     |
+| `--lines <n>`      | Show last N lines (default: 50)                                   |
+| `--help`           | Show help message                                                 |
 
 ## Log Levels
 
@@ -205,12 +205,14 @@ mk logs --level warn --follow
 ### "Debug logging is not enabled"
 
 This means no log files were found. Generate logs by:
+
 - Running tests with `LAMINAR_DEBUG=1`
 - Running topologies with `DEBUG=1`
 
 ### No output shown
 
 Check that:
+
 - The `reports/` directory exists
 - There are `.jsonl` files in `reports/<suite>/`
 - Logs contain `debug.*` events
@@ -219,6 +221,7 @@ Check that:
 ### Logs are empty or filtered out
 
 Try:
+
 - Remove filters: `mk logs` (no options)
 - Lower the level: `mk logs --level debug`
 - Check available modules: `mk logs | grep -o '\[.*\]' | sort -u`
diff --git a/docs/product/pty-metasurface.md b/docs/product/pty-metasurface.md
index f6a2dd6..17c5e99 100644
--- a/docs/product/pty-metasurface.md
+++ b/docs/product/pty-metasurface.md
@@ -49,13 +49,13 @@ Environment
 
 Reference flows (P0 demos)
 
-1) Dual render: Wrap `bash` via PTYServerWrapper. Fan out stdout to:
+1. Dual render: Wrap `bash` via PTYServerWrapper. Fan out stdout to:
    - Passthrough renderer (stdout) for regular terminal
    - Braille/text transform module that logs to console (placeholder for real braille device)
 
-2) Optional: Headless canvas snapshot (post-P0 candidate). Route output → ANSI parser → headless render; emit PNG buffers on sideband.
+2. Optional: Headless canvas snapshot (post-P0 candidate). Route output → ANSI parser → headless render; emit PNG buffers on sideband.
 
-3) Programmatic input: An “agent input” module sends `ls -la\n` (or similar) into the PTY input after observing initial output, demonstrating control injection.
+3. Programmatic input: An “agent input” module sends `ls -la\n` (or similar) into the PTY input after observing initial output, demonstrating control injection.
 
 Sideband examples
 
diff --git a/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v0.md b/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v0.md
index 3d09281..8c48809 100644
--- a/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v0.md
+++ b/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v0.md
@@ -21,6 +21,7 @@ This RFC defines goals, UX, schemas, command surfaces, and implementation phases
 - Seamless authoring: author in JSON by default or YAML with `--yaml`; round‑trip either way.
 
 Non‑negotiables for v0:
+
 - Single source of truth for topology validation (reuses kernel loader).
 - Canonical JSON AST inside mk; format adapters perform JSON⇄YAML I/O only.
 - Per‑repo `.mk/options.json` fully populated with defaults and inactive stubs.
@@ -31,6 +32,7 @@ Non‑negotiables for v0:
 We optimize for knees‑go‑weak delight. Every interaction must be: fast, obvious, reversible, and helpful. If a developer pauses to think about the tool instead of their app, we consider that a bug.
 
 DX commandments:
+
 - 1. Zero‑to‑run in under 60 seconds, always.
 - 2. If we can infer, we infer; if we guess, we show our work.
 - 3. Every error teaches: code, cause, fix, and a copy‑paste rerun.
@@ -79,6 +81,7 @@ DX commandments:
 ```
 
 Key points:
+
 - mk owns developer ergonomics (format, defaults, profiles, UX) while deferring topology semantics and validation to the existing kernel loader. This avoids drift.
 - All config is normalized to a canonical JSON AST. YAML/JSON adapters read/write only; comments/anchors are not preserved across translation (documented).
 
@@ -96,11 +99,11 @@ Key points:
   - `yaml-in`: parse YAML → JSON AST.
   - `yaml-out`: serialize JSON AST → YAML.
 - CLI precedence (highest→lowest):
-  1) Flags (`--yaml`, `--yaml-in`, `--yaml-out`, `--format`) 
-  2) Profile in `.mk/options.json`
-  3) Environment variables (e.g., `MK_FORMAT=yaml`)
-  4) File extension (mk.yaml → yaml-in default)
-  5) Defaults (JSON for both in/out)
+  1. Flags (`--yaml`, `--yaml-in`, `--yaml-out`, `--format`)
+  2. Profile in `.mk/options.json`
+  3. Environment variables (e.g., `MK_FORMAT=yaml`)
+  4. File extension (mk.yaml → yaml-in default)
+  5. Defaults (JSON for both in/out)
 - Comment preservation: not guaranteed; `mk format --to yaml --dry-run` offers diffs.
 
 ### Project Options Schema (.mk/options.json)
@@ -112,9 +115,20 @@ JSON only; shipped as a fully populated example with inactive stubs. Users toggl
   "$schema": "https://mkolbol.dev/schemas/mk-options.v0.json",
   "version": 0,
   "profiles": {
-    "dev": { "format": { "in": "auto", "out": "auto" }, "gate": { "localNode": true }, "prompt": { "enabled": true } },
-    "ci":  { "format": { "in": "json", "out": "json" }, "gate": { "localNode": true }, "prompt": { "enabled": false } },
-    "release": { "format": { "in": "json", "out": "yaml" }, "packaging": { "capsule": { "enabled": true } } }
+    "dev": {
+      "format": { "in": "auto", "out": "auto" },
+      "gate": { "localNode": true },
+      "prompt": { "enabled": true }
+    },
+    "ci": {
+      "format": { "in": "json", "out": "json" },
+      "gate": { "localNode": true },
+      "prompt": { "enabled": false }
+    },
+    "release": {
+      "format": { "in": "json", "out": "yaml" },
+      "packaging": { "capsule": { "enabled": true } }
+    }
   },
   "activeProfile": "dev",
   "format": { "in": "auto", "out": "auto" },
@@ -122,8 +136,8 @@ JSON only; shipped as a fully populated example with inactive stubs. Users toggl
   "prompt": { "enabled": false, "style": { "theme": "auto", "compact": true } },
   "packaging": {
     "bundle": { "enabled": true, "tool": "esbuild" },
-    "image":  { "enabled": false, "base": "node:20-slim" },
-    "capsule":{ "enabled": false, "sign": false }
+    "image": { "enabled": false, "base": "node:20-slim" },
+    "capsule": { "enabled": false, "sign": false }
   },
   "ci": { "laminar": { "prComment": true, "historyCache": true } },
   "doctor": { "checks": ["node-version", "permissions", "paths"] }
@@ -144,6 +158,7 @@ JSON only; shipped as a fully populated example with inactive stubs. Users toggl
 - `mk ci plan` — emit CI matrix with Laminar and cache keys.
 
 Flags affecting format I/O:
+
 - `--yaml` (alias for `--yaml-in --yaml-out`)
 - `--yaml-in`, `--yaml-out` (directional)
 - `--format=auto|json|yaml` (supersedes the above when provided)
@@ -164,6 +179,7 @@ mk prompt print --shell pwsh | Invoke-Expression
 ```
 
 Design constraints:
+
 - No implicit mutation of shell config files.
 - `mk prompt off` prints a command to restore the previous prompt (tracked in `.mk/state/prompt.json`).
 - Exposes environment (`MK_LOCAL_NODE`, `MK_FORMAT_IN`, `MK_FORMAT_OUT`, current profile) as readonly variables for other scripts.
@@ -171,6 +187,7 @@ Design constraints:
 ### Output & Microcopy Style (Obsessive Edition)
 
 Guarantees:
+
 - Color by default on TTY with auto‑detect; no‑color fallback, `--no-color` respected.
 - Always print a short, one‑line status first; then details.
 - Include a remediation footer that links to a stable doc anchor.
@@ -190,6 +207,7 @@ Code: CONFIG_PARSE  Rerun: mk run --file mk.yaml --dry-run
 ```
 
 “Did you mean…” rules:
+
 - Single edit distance on subcommands and flags.
 - Suggest the top 1–2 matches; never auto‑correct without confirmation.
 
@@ -197,9 +215,9 @@ Code: CONFIG_PARSE  Rerun: mk run --file mk.yaml --dry-run
 
 ### Golden Path (Hello in 60s)
 
-1) `mk init --preset tty` → creates `mk.json`, `.mk/options.json`, tests, and `src/hello.ts`.
-2) `mk run` → runs the preset topology; TTY output appears; `mk endpoints --watch` optional via mkctl.
-3) `mk doctor` → passes or prints exact remediations with copy‑paste commands.
+1. `mk init --preset tty` → creates `mk.json`, `.mk/options.json`, tests, and `src/hello.ts`.
+2. `mk run` → runs the preset topology; TTY output appears; `mk endpoints --watch` optional via mkctl.
+3. `mk doctor` → passes or prints exact remediations with copy‑paste commands.
 
 ### “Hello Calculator” Tutorial
 
@@ -212,8 +230,18 @@ JSON authoring (default):
   "topology": {
     "nodes": [
       { "id": "calc", "module": "CalculatorServer", "runMode": "inproc", "params": {} },
-      { "id": "tty",  "module": "TTYRenderer", "runMode": "inproc", "params": { "target": "stdout" } },
-      { "id": "logs", "module": "FilesystemSink", "runMode": "inproc", "params": { "path": "logs/out.jsonl", "format": "jsonl" } }
+      {
+        "id": "tty",
+        "module": "TTYRenderer",
+        "runMode": "inproc",
+        "params": { "target": "stdout" }
+      },
+      {
+        "id": "logs",
+        "module": "FilesystemSink",
+        "runMode": "inproc",
+        "params": { "path": "logs/out.jsonl", "format": "jsonl" }
+      }
     ],
     "connections": [
       { "from": "calc.output", "to": "tty.input" },
@@ -236,6 +264,7 @@ mk run --yaml                    # respect YAML both in/out for this session
 - `mk format --dry-run` shows unified diffs and warns before overwriting.
 
 Accessibility:
+
 - Provide `--no-ansi` for plain output; ensure ASCII graphs.
 - Respect `$LANG` for number/date formatting (messages remain English v0).
 - Avoid hard‑coded red/green pairs; ensure contrast.
@@ -253,10 +282,12 @@ mk delegates topology validation to the kernel loader and maps errors to friendl
 All errors include: short code, human message, remediation steps, and a copy‑paste rerun.
 
 Scripting contract:
+
 - `--json` adds a machine payload: `{ code, message, remediation, details, docs, hint }`.
 - Exit codes are stable and documented; non‑zero on any failure.
 
 Joy gates (quantitative):
+
 - Time‑to‑first‑run (TTFR): ≤ 60s on a clean machine with Node installed.
 - Time‑to‑recovery (TTR) from a common parse error: ≤ 30s following printed fix.
 - CLI latency: `mk run --dry-run` returns in < 400 ms on the example repo.
@@ -304,9 +335,9 @@ Joy gates (quantitative):
 
 ## Open Questions
 
-1) Should `mk` subsume `mkctl` long‑term or remain complementary? (v0: complementary.)
-2) Do we require signed capsules in v0, or defer to v1? (Proposal: defer.)
-3) How opinionated should profiles be out of the box? (Proposal: dev/ci/release.)
+1. Should `mk` subsume `mkctl` long‑term or remain complementary? (v0: complementary.)
+2. Do we require signed capsules in v0, or defer to v1? (Proposal: defer.)
+3. How opinionated should profiles be out of the box? (Proposal: dev/ci/release.)
 
 ## Risks & Mitigations
 
@@ -330,7 +361,12 @@ TopologyConfig (delegated to kernel loader):
 
 ```ts
 interface TopologyConfig {
-  nodes: Array<{ id: string; module: string; runMode: 'inproc'|'worker'|'process'; params?: Record<string, unknown> }>;
+  nodes: Array<{
+    id: string;
+    module: string;
+    runMode: 'inproc' | 'worker' | 'process';
+    params?: Record<string, unknown>;
+  }>;
   connections: Array<{ from: string; to: string }>;
 }
 ```
@@ -383,6 +419,7 @@ detectFormat(content: string): 'json' | 'yaml'
 ### CLI: scripts/mk.ts
 
 Flag precedence (highest → lowest):
+
 1. `--format json|yaml|auto` (supersedes all)
 2. `--yaml` (alias for `--yaml-in --yaml-out`)
 3. `--yaml-in` or `--yaml-out` (directional)
@@ -390,13 +427,14 @@ Flag precedence (highest → lowest):
 5. Default: JSON
 
 Commands implemented:
+
 - `mk format --to json|yaml [--in-place] [--dry-run] [--file <path>]`
 - `mk help`
 
 Example usage:
+
 ```bash
 mk format --to yaml --in-place           # mk.json → mk.yaml
 mk format --to json --dry-run            # Preview conversion
 mk format --yaml-in --file mk.yaml       # Read YAML, output JSON
 ```
-
diff --git a/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v1-distribution-bootstrap.md b/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v1-distribution-bootstrap.md
index a13dda0..e435085 100644
--- a/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v1-distribution-bootstrap.md
+++ b/docs/rfcs/MK_DEV_ORCHESTRATOR_RFC_v1-distribution-bootstrap.md
@@ -11,6 +11,7 @@ Related: MK Dev Orchestrator — RFC v0 (CLI & UX)
 We want developers (and naive agents) to use `mk` from anywhere, without publishing to npm. This RFC describes a simple, robust distribution and bootstrap model that makes `mk` feel like a Go‑style single command while staying Node‑native under the hood.
 
 We propose:
+
 - A tiny, cross‑platform shim installer (`mk self install`) that places `mk` on PATH.
 - A one‑liner installer script for fresh machines (curl | bash, PowerShell variant).
 - `mk bootstrap <app-dir>` to scaffold an out‑of‑tree app and install mkolbol as a dependency (tarball/file/git tag).
@@ -35,6 +36,7 @@ This delivers a “binary‑like” experience today (via shims) and a clean pat
 ## Problem Statement
 
 Developers cloning the repo can run `node dist/scripts/mk.js …`, but building apps outside the repo requires installing mkolbol. We do not publish to npm by design. We need a frictionless way to:
+
 - “Install” `mk` once and call it anywhere.
 - Bootstrap an out‑of‑tree app that depends on mkolbol without manual wiring.
 - Switch toolchain versions, fetch releases, and stay reproducible.
@@ -66,7 +68,7 @@ Developers cloning the repo can run `node dist/scripts/mk.js …`, but building
 
 - `--from repo` (default): uses the current repo’s `dist/` (build if missing). Optionally copies into `~/.mk/toolchains/local-<commit>/` to make the shim independent of repo moves.
 - `--from tag <vX>`: fetches release tarball into `~/.mk/toolchains/<tag>/` (see `mk fetch`).
-- `--from path <dir>`: points to an existing built toolchain (advanced). 
+- `--from path <dir>`: points to an existing built toolchain (advanced).
 
 ### One‑Liner Installer (scripts/mk-install.sh)
 
@@ -83,6 +85,7 @@ Developers cloning the repo can run `node dist/scripts/mk.js …`, but building
 ```
 mk bootstrap <app-dir> [--from tarball|git|local] [--tag vX] [--tar <path>] [--yes]
 ```
+
 - Creates `<app-dir>` with:
   - `package.json` containing a dependency on mkolbol (tarball/file/git URL)
   - `src/` and a minimal starter
@@ -102,7 +105,7 @@ mk bootstrap <app-dir> [--from tarball|git|local] [--tag vX] [--tar <path>] [--y
 
 ### Single‑Exe Plan (Later)
 
-- Optional experiment: bun compile / nexe for `mk` only (CLI, no native deps). 
+- Optional experiment: bun compile / nexe for `mk` only (CLI, no native deps).
 - Keep external process/PTY features in the runtime, not inside the CLI binary.
 - Deliver per‑platform binaries under releases with the same toolchain semantics.
 
@@ -141,29 +144,35 @@ mk bootstrap <app-dir> [--from tarball|git|local] [--tag vX] [--tar <path>] [--y
 ```
 
 Notes:
+
 - `--copy`: copy the current repo toolchain into `~/.mk/toolchains/local-<commit>/` and point the shim there (stable even if repo moves).
 - `mkctl` handled automatically: `mk self install` also creates a `mkctl` shim.
 
 ## Implementation Plan
 
 Phase A — Shims & Self Install (POSIX + Windows)
+
 - Add `mk self install/uninstall/where/switch`.
 - Create POSIX/Windows shims in user bin dir; PATH instructions printed.
 - Add `mk doctor` checks for shim/toolchain.
 
 Phase B — Bootstrap
+
 - Add `mk bootstrap <app-dir>` with dependency source selection.
 - Scaffold template; set `package.json` scripts to `node node_modules/mkolbol/dist/scripts/mk.js`.
 
 Phase C — Toolchain Fetch & Switch
+
 - Add `mk fetch <tag>`; verify checksums and cache artifacts.
 - Add `mk self switch`.
 
 Phase D — One‑Liner Installer
+
 - Add `scripts/mk-install.sh` and Windows PowerShell variant.
 - Docs: top‑level README + DevEx guides.
 
 Phase E — (Optional) Single‑Exe Experiment
+
 - Explore bun compile/nexe for CLI only; document caveats.
 
 ## Acceptance Criteria
@@ -183,6 +192,7 @@ Phase E — (Optional) Single‑Exe Experiment
 ## Appendix A — Shim Templates
 
 POSIX `mk`:
+
 ```sh
 #!/usr/bin/env bash
 set -euo pipefail
@@ -191,6 +201,7 @@ exec node "$MK_TOOLCHAIN_DIR/dist/scripts/mk.js" "$@"
 ```
 
 Windows `mk.cmd`:
+
 ```bat
 @echo off
 setlocal
@@ -199,6 +210,7 @@ node "%MK_TOOLCHAIN_DIR%\dist\scripts\mk.js" %*
 ```
 
 Windows PowerShell `mk.ps1`:
+
 ```powershell
 $toolchain = "$env:USERPROFILE\AppData\Local\mkolbol\toolchains\current"
 node "$toolchain\dist\scripts\mk.js" $args
@@ -209,4 +221,3 @@ node "$toolchain\dist\scripts\mk.js" $args
 ---
 
 End of RFC.
-
diff --git a/docs/rfcs/stream-kernel/00-index.md b/docs/rfcs/stream-kernel/00-index.md
index bc54ee1..ea23bb9 100644
--- a/docs/rfcs/stream-kernel/00-index.md
+++ b/docs/rfcs/stream-kernel/00-index.md
@@ -11,16 +11,19 @@ This RFC proposes a minimal stream-based microkernel architecture (~100 lines) f
 ## Documents
 
 ### Core Design
+
 - **[01 - Philosophy](01-philosophy.md)** - Design principles, microkernel vs monolithic, mechanism vs policy
 - **[02 - Core Architecture](02-core-architecture.md)** - The ~100 line kernel API: createPipe, connect, split, merge, registry
 - **[03 - Module Types](03-module-types.md)** - Input, Source, Transform, Output, and Routing module patterns
 
-### Use Cases & Applications  
+### Use Cases & Applications
+
 - **[04 - PTY Use Cases](04-pty-use-cases.md)** - Terminal I/O hijacking, multi-modal rendering, AI integration
 - **[05 - Deployment Flexibility](05-deployment-flexibility.md)** - Single process → multi-process → distributed deployment
 - **[06 - Distributed Service Mesh](06-distributed-service-mesh.md)** - Routing servers, terminals, multi-hop routing, hairpin flows
 
 ### Supporting Systems
+
 - **[07 - StateManager/ControlPlane](07-state-manager.md)** - HMI control room for topology tracking, wiring configs, runtime introspection/control
 - **[08 - Registry Server (The Hostess)](08-registry-server.md)** - Server registry, guest book, naming convention, reservations interface, executor/probe/beacon connection testing, LLDP-inspired discovery, information mesh
 - **[09 - Roadmap](09-roadmap.md)** - Implementation phases and timeline
@@ -29,6 +32,7 @@ This RFC proposes a minimal stream-based microkernel architecture (~100 lines) f
 - **[12 - PTY Wrapper Patterns](12-pty-wrapper-patterns.md)** - Wrapping interactive TUI applications with multi-modal rendering and multi-source input
 
 ### Implementation Planning
+
 - **[External Wrapper Sprints](external-wrapper-sprints.md)** - 8-sprint implementation plan for external wrapper system (40-60 days)
 
 ## Quick Start
@@ -51,6 +55,7 @@ This RFC proposes a minimal stream-based microkernel architecture (~100 lines) f
 ## Vision
 
 Build the most flexible PTY I/O system ever created:
+
 - Hijack any terminal application's I/O
 - Multi-modal rendering: xterm.js, Canvas, Video, TTS, AI-formatted text
 - Multi-input: Keyboard, Voice, AI agents
diff --git a/docs/rfcs/stream-kernel/01-philosophy.md b/docs/rfcs/stream-kernel/01-philosophy.md
index 270fc82..731f36e 100644
--- a/docs/rfcs/stream-kernel/01-philosophy.md
+++ b/docs/rfcs/stream-kernel/01-philosophy.md
@@ -7,13 +7,15 @@ A microkernel does **one thing perfectly**: provide mechanism. All policy lives
 ### Mechanism vs Policy
 
 **Mechanism** (kernel provides):
+
 - Create pipes (data channels)
 - Connect pipes together
-- Split data to multiple destinations  
+- Split data to multiple destinations
 - Merge data from multiple sources
 - Register services
 
 **Policy** (modules decide):
+
 - What data formats to use (JSON, bytes, MCP, etc.)
 - How to parse/transform data
 - Where to route messages
@@ -31,7 +33,7 @@ The kernel is the "physical layer" - like pneumatic tubes that move packages thr
 ```typescript
 class Kernel {
   createPipe(): Pipe { ... }              // ~10 lines
-  connect(from: Pipe, to: Pipe) { ... }   // ~5 lines  
+  connect(from: Pipe, to: Pipe) { ... }   // ~5 lines
   split(from: Pipe, to: Pipe[]) { ... }   // ~10 lines
   merge(from: Pipe[], to: Pipe) { ... }   // ~10 lines
   register(name, caps, pipe) { ... }      // ~20 lines
@@ -44,9 +46,10 @@ class Kernel {
 ### 2. Protocol Agnostic
 
 The kernel works with **any** data format:
+
 - Raw bytes (terminal escape sequences)
 - JSON objects (structured data)
-- JSON-RPC messages (AI agent communication)  
+- JSON-RPC messages (AI agent communication)
 - MCP protocol (Model Context Protocol)
 - Binary data (video frames)
 - Custom protocols (your future invention)
@@ -61,7 +64,7 @@ Same kernel API works with different "wire protocols":
 // In same process
 createPipe('local')    → PassThrough stream (in-memory)
 
-// Different processes  
+// Different processes
 createPipe('unix')     → Unix domain socket
 
 // Different machines
@@ -82,8 +85,8 @@ Servers don't know where their peers are located:
 // Server code - same everywhere
 class ParserServer {
   constructor(kernel: Kernel) {
-    this.input = kernel.createPipe();   // Could be local or remote!
-    this.output = kernel.createPipe();  // Could be local or remote!
+    this.input = kernel.createPipe(); // Could be local or remote!
+    this.output = kernel.createPipe(); // Could be local or remote!
   }
 }
 ```
@@ -104,14 +107,10 @@ Example - multi-modal output (one PTY → many renderers):
 ```typescript
 const pty = new PTY(kernel);
 const xterm = new XtermRenderer(kernel);
-const canvas = new CanvasRenderer(kernel);  
+const canvas = new CanvasRenderer(kernel);
 const tts = new TTSRenderer(kernel);
 
-kernel.split(pty.output, [
-  xterm.input,
-  canvas.input,
-  tts.input
-]);
+kernel.split(pty.output, [xterm.input, canvas.input, tts.input]);
 ```
 
 **Same data flows to all renderers simultaneously.**
@@ -124,7 +123,7 @@ Even "system" services are modules:
 // Routing? Module!
 const router = new RoutingServer(kernel);
 
-// Service discovery? Module!  
+// Service discovery? Module!
 const registry = new RegistryServer(kernel);
 
 // Supervision? Module!
@@ -141,6 +140,7 @@ const mcp = new MCPRouter(kernel);
 ### ✅ Deployment Flexibility
 
 Same code, different deployment:
+
 - **Development:** Single Node.js process
 - **Testing:** Multi-process with isolation
 - **Production:** Distributed across machines
@@ -156,9 +156,9 @@ describe('Kernel', () => {
     const kernel = new Kernel();
     const p1 = kernel.createPipe();
     const p2 = kernel.createPipe();
-    
+
     kernel.connect(p1, p2);
-    
+
     p1.write('test');
     expect(p2.read()).toBe('test');
   });
@@ -172,7 +172,7 @@ describe('ParserModule', () => {
   it('parses ANSI', () => {
     const mockKernel = { createPipe: () => new PassThrough() };
     const parser = new ANSIParser(mockKernel);
-    
+
     parser.input.write('\x1b[31m');
     expect(parser.output.read()).toEqual({ color: 'red' });
   });
@@ -189,7 +189,7 @@ class HolographicRenderer {
   constructor(kernel: Kernel) {
     this.input = kernel.createPipe();
   }
-  
+
   render(data) {
     // Render to hologram!
   }
@@ -198,7 +198,7 @@ class HolographicRenderer {
 // Works with existing system - no kernel changes!
 kernel.split(pty.output, [
   xterm.input,
-  hologram.input  // New renderer!
+  hologram.input, // New renderer!
 ]);
 ```
 
@@ -210,18 +210,20 @@ kernel.split(pty.output, [
 class MCPServer {
   // Kernel knows about JSON-RPC
   private rpcHandler: JSONRPCHandler;
-  
+
   // Kernel knows about transports
   private transports: (StdioTransport | HTTPTransport)[];
-  
+
   // Kernel knows about middleware
   private middleware: (Compression | Auth | Metrics)[];
-  
+
   // Kernel knows about subscriptions
   private subscriptions: Map<string, Subscriber[]>;
-  
+
   // To add a feature: modify kernel
-  addFeature() { /* change kernel code */ }
+  addFeature() {
+    /* change kernel code */
+  }
 }
 ```
 
@@ -270,6 +272,7 @@ kernel.connect(auth.output, mcp.input);
 ## The Payoff
 
 With ~100 lines of kernel code, we get:
+
 - ✅ Works in Node.js and browsers
 - ✅ Single process → distributed deployment
 - ✅ Any protocol (JSON-RPC, MCP, custom)
diff --git a/docs/rfcs/stream-kernel/02-core-architecture.md b/docs/rfcs/stream-kernel/02-core-architecture.md
index 5e8caed..3cbbca0 100644
--- a/docs/rfcs/stream-kernel/02-core-architecture.md
+++ b/docs/rfcs/stream-kernel/02-core-architecture.md
@@ -30,7 +30,7 @@ class Kernel {
         // TODO: UnixSocketPipe implementation
         throw new Error('Not implemented');
       case 'tcp':
-        // TODO: TCPPipe implementation  
+        // TODO: TCPPipe implementation
         throw new Error('Not implemented');
     }
   }
@@ -81,12 +81,12 @@ class Kernel {
       }
 
       if (query.accepts && caps.accepts) {
-        const hasAccepts = query.accepts.some(a => caps.accepts!.includes(a));
+        const hasAccepts = query.accepts.some((a) => caps.accepts!.includes(a));
         if (!hasAccepts) matches = false;
       }
 
       if (query.produces && caps.produces) {
-        const hasProduces = query.produces.some(p => caps.produces!.includes(p));
+        const hasProduces = query.produces.some((p) => caps.produces!.includes(p));
         if (!hasProduces) matches = false;
       }
 
@@ -118,7 +118,7 @@ pipe.write({ type: 'data', value: 42 });
 
 // Read from pipe
 pipe.on('data', (data) => {
-  console.log(data);  // { type: 'data', value: 42 }
+  console.log(data); // { type: 'data', value: 42 }
 });
 ```
 
@@ -170,9 +170,9 @@ const pty = kernel.createPipe();
 
 kernel.merge([keyboard, voice, ai], pty);
 
-keyboard.write('ls\n');   // PTY receives 'ls\n'
-voice.write('cd /\n');    // PTY receives 'cd /\n'
-ai.write('pwd\n');        // PTY receives 'pwd\n'
+keyboard.write('ls\n'); // PTY receives 'ls\n'
+voice.write('cd /\n'); // PTY receives 'cd /\n'
+ai.write('pwd\n'); // PTY receives 'pwd\n'
 ```
 
 **Use case:** Multi-input (keyboard + voice + AI → single PTY)
@@ -182,12 +182,16 @@ ai.write('pwd\n');        // PTY receives 'pwd\n'
 Advertise a service for discovery:
 
 ```typescript
-kernel.register('xterm-parser', {
-  type: 'transform',
-  accepts: ['raw-ansi'],
-  produces: ['terminal-state'],
-  features: ['vt100', 'xterm-256color']
-}, parserPipe);
+kernel.register(
+  'xterm-parser',
+  {
+    type: 'transform',
+    accepts: ['raw-ansi'],
+    produces: ['terminal-state'],
+    features: ['vt100', 'xterm-256color'],
+  },
+  parserPipe,
+);
 ```
 
 **Use case:** Dynamic service discovery, capability-based routing
@@ -199,12 +203,12 @@ Find services by capabilities:
 ```typescript
 // Find all parsers that produce terminal-state
 const parsers = kernel.lookup({
-  produces: ['terminal-state']
+  produces: ['terminal-state'],
 });
 
 // Find all AI-compatible modules
 const aiModules = kernel.lookup({
-  produces: ['ai-text']
+  produces: ['ai-text'],
 });
 ```
 
@@ -256,9 +260,9 @@ const parser = new ANSIParser(kernel);
 const screen = new ScreenRenderer(kernel);
 
 // Wire up the flow
-kernel.connect(keyboard.output, pty.input);   // Keyboard → PTY
-kernel.connect(pty.output, parser.input);     // PTY → Parser
-kernel.connect(parser.output, screen.input);  // Parser → Screen
+kernel.connect(keyboard.output, pty.input); // Keyboard → PTY
+kernel.connect(pty.output, parser.input); // PTY → Parser
+kernel.connect(parser.output, screen.input); // Parser → Screen
 
 // Start typing
 // keyboard → pty → parser → screen
@@ -272,8 +276,9 @@ kernel.connect(parser.output, screen.input);  // Parser → Screen
 ### 1. Node.js Streams Do the Heavy Lifting
 
 We don't implement:
+
 - Buffering (Node.js does it)
-- Backpressure (Node.js does it)  
+- Backpressure (Node.js does it)
 - Error propagation (Node.js does it)
 - Pause/resume (Node.js does it)
 
@@ -282,6 +287,7 @@ We don't implement:
 ### 2. The Kernel Never Changes
 
 To add a new feature:
+
 1. ❌ Don't modify the kernel
 2. ✅ Create a new module
 3. ✅ Wire it up with connect/split/merge
@@ -296,7 +302,7 @@ A single `Pipe` can both read and write:
 // Write to pipe
 pipe.write(data);
 
-// Read from pipe  
+// Read from pipe
 pipe.on('data', (data) => { ... });
 ```
 
@@ -305,12 +311,13 @@ This enables request/response patterns without multiple pipes.
 ### 4. Object Mode by Default
 
 ```typescript
-createPipe({ objectMode: true })
+createPipe({ objectMode: true });
 ```
 
 Pipes carry **objects** (not just bytes), which is perfect for:
+
 - JSON-RPC messages
-- MCP protocol  
+- MCP protocol
 - Structured terminal state
 - Any JavaScript object
 
@@ -320,9 +327,9 @@ For raw bytes (PTY output), modules can convert:
 class PTY {
   constructor(kernel) {
     this.output = kernel.createPipe();
-    
+
     pty.stdout.on('data', (buffer: Buffer) => {
-      this.output.write(buffer);  // Buffer flows through pipe
+      this.output.write(buffer); // Buffer flows through pipe
     });
   }
 }
@@ -363,7 +370,7 @@ Same API, different stream implementation!
 ❌ Implement transports  
 ❌ Compress/encrypt  
 ❌ Authenticate  
-❌ Log events  
+❌ Log events
 
 **All of those are module responsibilities.**
 
@@ -372,6 +379,7 @@ Same API, different stream implementation!
 ### Overview
 
 Endpoints provide addressability and metadata for modules in the system. Each registered module has an associated endpoint that describes:
+
 - **Type** - The execution environment (inproc, worker, external, pty)
 - **Coordinates** - Location/identifier for reaching the module
 - **Metadata** - Additional context specific to the endpoint type
@@ -380,15 +388,16 @@ Endpoints provide addressability and metadata for modules in the system. Each re
 
 ```typescript
 interface HostessEndpoint {
-  type: string;           // Execution environment type
-  coordinates: string;    // Location/identifier
-  metadata?: Record<string, any>;  // Type-specific metadata
+  type: string; // Execution environment type
+  coordinates: string; // Location/identifier
+  metadata?: Record<string, any>; // Type-specific metadata
 }
 ```
 
 ### Endpoint Types
 
 **inproc** - In-process modules
+
 ```typescript
 {
   type: 'inproc',
@@ -401,6 +410,7 @@ interface HostessEndpoint {
 ```
 
 **worker** - Worker thread modules
+
 ```typescript
 {
   type: 'worker',
@@ -413,6 +423,7 @@ interface HostessEndpoint {
 ```
 
 **external** - External process via stdio
+
 ```typescript
 {
   type: 'external',
@@ -425,6 +436,7 @@ interface HostessEndpoint {
 ```
 
 **pty** - PTY-based process
+
 ```typescript
 {
   type: 'pty',
@@ -442,22 +454,24 @@ interface HostessEndpoint {
 Endpoints are registered automatically when modules are instantiated:
 
 **Via Executor:**
+
 ```typescript
 // Executor registers endpoints during node instantiation
 const executor = new Executor(kernel, hostess, stateManager);
 executor.load(topologyConfig);
-await executor.up();  // Registers endpoints for all nodes
+await executor.up(); // Registers endpoints for all nodes
 ```
 
 **Via Wrappers:**
+
 ```typescript
 // PTY wrapper registers on spawn
 const ptyWrapper = new PTYServerWrapper(kernel, hostess, manifest);
-await ptyWrapper.spawn();  // Registers pty endpoint
+await ptyWrapper.spawn(); // Registers pty endpoint
 
 // External wrapper registers on spawn
 const extWrapper = new ExternalServerWrapper(kernel, hostess, manifest);
-await extWrapper.spawn();  // Registers external endpoint
+await extWrapper.spawn(); // Registers external endpoint
 ```
 
 ### Discovery Pattern
@@ -475,6 +489,7 @@ for (const [id, endpoint] of endpoints) {
 ```
 
 **CLI Discovery:**
+
 ```bash
 # List all registered endpoints
 node dist/scripts/mkctl.js endpoints
@@ -504,6 +519,7 @@ Process adapters enable kernel pipes to communicate with external processes over
 Implements bidirectional data streaming over Unix domain sockets by wrapping a `Socket` in a Node.js `Duplex` stream.
 
 **Key Features:**
+
 - Automatic backpressure via `socket.pause()`/`socket.resume()`
 - Graceful shutdown with `_final()` hook
 - Socket lifecycle tied to stream lifecycle
@@ -580,6 +596,7 @@ Writer                  Adapter                 Socket
 Implements control-plane messaging over Unix domain sockets using JSON-line protocol.
 
 **Key Features:**
+
 - Pub/sub for control messages
 - Automatic heartbeat (1000ms interval)
 - Graceful shutdown signaling
@@ -619,7 +636,7 @@ control.subscribe('app.config', (data) => {
 control.publish('app.status', { status: 'ready' });
 
 // Shutdown
-control.shutdown();  // Sends shutdown signal, then closes
+control.shutdown(); // Sends shutdown signal, then closes
 ```
 
 **Heartbeat Mechanism:**
@@ -693,7 +710,7 @@ Gracefully terminate process:
 return new Promise((resolve) => {
   const killTimer = setTimeout(() => {
     if (proc && !proc.killed) {
-      proc.kill('SIGKILL');  // Force kill
+      proc.kill('SIGKILL'); // Force kill
     }
   }, 5000);
 
@@ -702,7 +719,7 @@ return new Promise((resolve) => {
     resolve();
   });
 
-  proc.kill('SIGTERM');  // Graceful termination
+  proc.kill('SIGTERM'); // Graceful termination
 });
 ```
 
@@ -755,14 +772,14 @@ return new Promise((resolve) => {
 
 ### Adapter Comparison
 
-| Feature | UnixPipeAdapter | UnixControlAdapter |
-|---------|----------------|-------------------|
-| **Purpose** | Data streaming | Control messaging |
-| **Protocol** | Raw bytes/objects | JSON-line |
-| **Backpressure** | Native stream | N/A |
-| **Heartbeat** | No | Yes (1000ms) |
-| **Bidirectional** | Yes | Yes |
-| **Use Case** | High-throughput data | Low-frequency control |
+| Feature           | UnixPipeAdapter      | UnixControlAdapter    |
+| ----------------- | -------------------- | --------------------- |
+| **Purpose**       | Data streaming       | Control messaging     |
+| **Protocol**      | Raw bytes/objects    | JSON-line             |
+| **Backpressure**  | Native stream        | N/A                   |
+| **Heartbeat**     | No                   | Yes (1000ms)          |
+| **Bidirectional** | Yes                  | Yes                   |
+| **Use Case**      | High-throughput data | Low-frequency control |
 
 ### Error Handling
 
@@ -787,11 +804,13 @@ control.subscribe('control.error', (err) => {
 ### Performance
 
 **UnixPipeAdapter:**
+
 - Throughput: ~500K msgs/sec (object mode)
 - Latency: <1ms (same machine)
 - Overhead: Socket + stream wrapping
 
 **UnixControlAdapter:**
+
 - Throughput: ~10K msgs/sec
 - Latency: 1-2ms
 - Overhead: JSON serialization + parsing
@@ -799,6 +818,7 @@ control.subscribe('control.error', (err) => {
 ## Next Steps
 
 See:
+
 - **[Module Types](03-module-types.md)** - How to build modules on this kernel
 - **[PTY Use Cases](04-pty-use-cases.md)** - Real-world examples
 - **[Worker Mode](worker-mode.md)** - Worker vs Process adapter comparison
diff --git a/docs/rfcs/stream-kernel/03-module-types.md b/docs/rfcs/stream-kernel/03-module-types.md
index 9bc677a..77430b9 100644
--- a/docs/rfcs/stream-kernel/03-module-types.md
+++ b/docs/rfcs/stream-kernel/03-module-types.md
@@ -9,19 +9,19 @@ Every module follows this pattern:
 ```typescript
 interface Module {
   // Input modules: only outputPipe
-  // Output modules: only inputPipe  
+  // Output modules: only inputPipe
   // Transform modules: both
   // Source modules: both (bidirectional)
   // Routing modules: manage multiple pipes
-  
-  inputPipe?: Pipe;   // Receives data
-  outputPipe?: Pipe;  // Sends data
+
+  inputPipe?: Pipe; // Receives data
+  outputPipe?: Pipe; // Sends data
 }
 ```
 
 ##
 
- 1. Input Modules
+1.  Input Modules
 
 Generate user input and push to `outputPipe`:
 
@@ -35,6 +35,7 @@ interface InputModule {
 ### Examples
 
 **Keyboard Input:**
+
 ```typescript
 class KeyboardInput {
   outputPipe: Pipe;
@@ -51,6 +52,7 @@ class KeyboardInput {
 ```
 
 **Voice Input (Speech-to-Text):**
+
 ```typescript
 class WhisperSTT {
   outputPipe: Pipe;
@@ -68,6 +70,7 @@ class WhisperSTT {
 ```
 
 **AI Agent Input:**
+
 ```typescript
 class MCPInput {
   outputPipe: Pipe;
@@ -89,14 +92,15 @@ Bidirectional: run processes, expose input/output:
 ```typescript
 interface SourceModule {
   type: 'source';
-  inputPipe: Pipe;   // Commands to send
-  outputPipe: Pipe;  // Output from process
+  inputPipe: Pipe; // Commands to send
+  outputPipe: Pipe; // Output from process
 }
 ```
 
 ### Examples
 
 **Local PTY:**
+
 ```typescript
 import * as pty from 'node-pty';
 
@@ -113,7 +117,7 @@ class LocalPTY {
       cols: 80,
       rows: 24,
       cwd: process.cwd(),
-      env: process.env
+      env: process.env,
     });
 
     shell.onData((data) => {
@@ -128,6 +132,7 @@ class LocalPTY {
 ```
 
 **Docker PTY:**
+
 ```typescript
 class DockerPTY {
   inputPipe: Pipe;
@@ -169,6 +174,7 @@ interface TransformModule {
 ### Examples
 
 **ANSI Parser:**
+
 ```typescript
 class ANSIParser {
   inputPipe: Pipe;
@@ -192,6 +198,7 @@ class ANSIParser {
 ```
 
 **AI Text Formatter:**
+
 ```typescript
 class AITextFormatter {
   inputPipe: Pipe;
@@ -229,6 +236,7 @@ interface OutputModule {
 ### Examples
 
 **Screen Renderer:**
+
 ```typescript
 class ScreenRenderer {
   inputPipe: Pipe;
@@ -249,6 +257,7 @@ class ScreenRenderer {
 ```
 
 **Canvas Renderer:**
+
 ```typescript
 class CanvasRenderer {
   inputPipe: Pipe;
@@ -271,6 +280,7 @@ class CanvasRenderer {
 ```
 
 **MP4 Recorder:**
+
 ```typescript
 class MP4Recorder {
   inputPipe: Pipe;
@@ -305,6 +315,7 @@ interface RoutingModule {
 ### Example
 
 **Routing Server:**
+
 ```typescript
 class RoutingServer {
   private kernel: Kernel;
@@ -313,11 +324,15 @@ class RoutingServer {
 
   constructor(kernel: Kernel) {
     this.kernel = kernel;
-    
-    kernel.register('router', {
-      type: 'routing',
-      features: ['service-discovery', 'multi-hop']
-    }, kernel.createPipe());
+
+    kernel.register(
+      'router',
+      {
+        type: 'routing',
+        features: ['service-discovery', 'multi-hop'],
+      },
+      kernel.createPipe(),
+    );
   }
 
   createTerminal(name: string, type: 'local' | 'network'): Terminal {
@@ -325,7 +340,7 @@ class RoutingServer {
       name,
       type,
       inputPipe: this.kernel.createPipe(),
-      outputPipe: this.kernel.createPipe()
+      outputPipe: this.kernel.createPipe(),
     };
 
     terminal.inputPipe.on('data', (envelope) => {
@@ -367,11 +382,7 @@ kernel.connect(transform2.output, sink.input);
 ### Pattern 2: Fan-Out (Multi-Modal Output)
 
 ```typescript
-kernel.split(source.output, [
-  sink1.input,
-  sink2.input,
-  sink3.input
-]);
+kernel.split(source.output, [sink1.input, sink2.input, sink3.input]);
 
 // source → sink1
 //       ↘ sink2
@@ -381,11 +392,7 @@ kernel.split(source.output, [
 ### Pattern 3: Fan-In (Multi-Input)
 
 ```typescript
-kernel.merge([
-  input1.output,
-  input2.output,
-  input3.output
-], sink.input);
+kernel.merge([input1.output, input2.output, input3.output], sink.input);
 
 // input1 ↘
 // input2 → sink
@@ -410,16 +417,20 @@ Modules advertise capabilities for dynamic discovery:
 
 ```typescript
 // Register with capabilities
-kernel.register('xterm-parser', {
-  type: 'transform',
-  accepts: ['raw-ansi'],
-  produces: ['terminal-state'],
-  features: ['vt100', 'xterm-256color', 'unicode']
-}, parserPipe);
+kernel.register(
+  'xterm-parser',
+  {
+    type: 'transform',
+    accepts: ['raw-ansi'],
+    produces: ['terminal-state'],
+    features: ['vt100', 'xterm-256color', 'unicode'],
+  },
+  parserPipe,
+);
 
 // Find compatible modules
 const parsers = kernel.lookup({
-  accepts: ['raw-ansi']
+  accepts: ['raw-ansi'],
 });
 
 // Returns Map of matching modules
@@ -488,7 +499,7 @@ Modules are testable in isolation:
 describe('ANSIParser', () => {
   it('parses color codes', () => {
     const mockKernel = {
-      createPipe: () => new PassThrough({ objectMode: true })
+      createPipe: () => new PassThrough({ objectMode: true }),
     };
 
     const parser = new ANSIParser(mockKernel);
@@ -516,6 +527,7 @@ The tutorial includes complete code examples, Hostess registration, debugging ti
 ## Next Steps
 
 See:
+
 - **[First Server Tutorial](../../devex/first-server-tutorial.md)** - Build your own module (start here!)
 - **[PTY Use Cases](04-pty-use-cases.md)** - Real-world module compositions
 - **[Distributed Service Mesh](06-distributed-service-mesh.md)** - Routing module details
diff --git a/docs/rfcs/stream-kernel/04-pty-use-cases.md b/docs/rfcs/stream-kernel/04-pty-use-cases.md
index 8232d9d..4a16e63 100644
--- a/docs/rfcs/stream-kernel/04-pty-use-cases.md
+++ b/docs/rfcs/stream-kernel/04-pty-use-cases.md
@@ -5,11 +5,13 @@ This document shows real-world examples of using the stream kernel for terminal
 ## Vision
 
 Transform terminal systems from:
+
 ```
 [Keyboard] → [PTY] → [Screen]
 ```
 
 To:
+
 ```
 [Keyboard, Voice, AI, Network] → [PTY] → [Screen, Canvas, Video, Audio, AI, Browser]
 ```
@@ -58,12 +60,7 @@ const tts = new TextToSpeech(kernel);
 kernel.connect(keyboard.output, pty.input);
 
 // Output: PTY → all renderers simultaneously
-kernel.split(pty.output, [
-  screen.input,
-  canvas.input,
-  recorder.input,
-  tts.input
-]);
+kernel.split(pty.output, [screen.input, canvas.input, recorder.input, tts.input]);
 
 // User sees:
 // - Native terminal (screen)
@@ -87,7 +84,7 @@ const aiAgent = new MCPInput(kernel);
 // Source
 const pty = new DockerPTY(kernel, {
   image: 'ubuntu:latest',
-  command: 'bash'
+  command: 'bash',
 });
 
 // Transforms
@@ -99,18 +96,11 @@ const screen = new ScreenRenderer(kernel);
 const screenshotter = new Screenshotter(kernel, { interval: 1000 });
 
 // Multi-input → PTY
-kernel.merge([
-  keyboard.output,
-  voice.output,
-  aiAgent.output
-], pty.input);
+kernel.merge([keyboard.output, voice.output, aiAgent.output], pty.input);
 
 // PTY → Parser → Outputs
 kernel.connect(pty.output, parser.input);
-kernel.split(parser.output, [
-  screen.input,
-  aiFormatter.input
-]);
+kernel.split(parser.output, [screen.input, aiFormatter.input]);
 
 // Feed screenshots and formatted text to AI
 screenshotter.on('screenshot', (img) => {
@@ -147,15 +137,9 @@ const canvasRenderer = new CanvasRenderer(kernel, document.getElementById('termi
 const domRenderer = new XtermJSRenderer(kernel, document.getElementById('xterm'));
 
 // Wire up
-kernel.merge([
-  devToolsInput.output,
-  extensionMessaging.output
-], webWorkerPTY.input);
+kernel.merge([devToolsInput.output, extensionMessaging.output], webWorkerPTY.input);
 
-kernel.split(webWorkerPTY.output, [
-  canvasRenderer.input,
-  domRenderer.input
-]);
+kernel.split(webWorkerPTY.output, [canvasRenderer.input, domRenderer.input]);
 
 // Browser extension can now:
 // - Control terminal
@@ -225,7 +209,7 @@ const screen = new ScreenRenderer(kernel);
 
 // Add recorder
 const sessionRecorder = new SessionRecorder(kernel, {
-  filename: 'session.log'
+  filename: 'session.log',
 });
 
 // Normal flow
@@ -233,15 +217,12 @@ kernel.connect(keyboard.output, pty.input);
 kernel.connect(pty.output, screen.input);
 
 // Also record everything
-kernel.split(pty.output, [
-  screen.input,
-  sessionRecorder.input
-]);
+kernel.split(pty.output, [screen.input, sessionRecorder.input]);
 
 // Later: Replay session
 const replayer = new SessionReplayer(kernel, {
   filename: 'session.log',
-  speed: 2.0  // 2x speed
+  speed: 2.0, // 2x speed
 });
 
 const replayScreen = new ScreenRenderer(kernel);
@@ -263,16 +244,16 @@ const screen = new ScreenRenderer(kernel);
 
 // AI data collectors
 const screenshotter = new Screenshotter(kernel, {
-  interval: 100,  // Every 100ms
-  outputDir: '/training-data/screenshots'
+  interval: 100, // Every 100ms
+  outputDir: '/training-data/screenshots',
 });
 
 const actionLogger = new ActionLogger(kernel, {
-  outputFile: '/training-data/actions.jsonl'
+  outputFile: '/training-data/actions.jsonl',
 });
 
 const stateExtractor = new StateExtractor(kernel, {
-  outputFile: '/training-data/states.jsonl'
+  outputFile: '/training-data/states.jsonl',
 });
 
 // Normal flow
@@ -315,18 +296,10 @@ const user2Output = new WebSocketOutput(kernel, { userId: 'bob' });
 const user3Output = new WebSocketOutput(kernel, { userId: 'charlie' });
 
 // All inputs → PTY
-kernel.merge([
-  user1Input.output,
-  user2Input.output,
-  user3Input.output
-], pty.input);
+kernel.merge([user1Input.output, user2Input.output, user3Input.output], pty.input);
 
 // PTY → All outputs
-kernel.split(pty.output, [
-  user1Output.input,
-  user2Output.input,
-  user3Output.input
-]);
+kernel.split(pty.output, [user1Output.input, user2Output.input, user3Output.input]);
 
 // Alice, Bob, and Charlie can all:
 // - Send commands
@@ -350,11 +323,11 @@ const commandFilter = new CommandFilter(kernel, {
   blocked: ['rm -rf /', 'dd if=/dev/zero'],
   alertCallback: (cmd) => {
     console.warn(`Blocked dangerous command: ${cmd}`);
-  }
+  },
 });
 
 const auditLogger = new AuditLogger(kernel, {
-  outputFile: '/var/log/terminal-audit.log'
+  outputFile: '/var/log/terminal-audit.log',
 });
 
 // Input flow: keyboard → filter → audit → PTY
@@ -383,26 +356,21 @@ const pty = new LocalPTY(kernel);
 const screen = new ScreenRenderer(kernel);
 const tts = new TextToSpeech(kernel, {
   voice: 'en-US-Neural',
-  rate: 1.2
+  rate: 1.2,
 });
 const braille = new BrailleDisplay(kernel, {
-  device: '/dev/ttyUSB0'
+  device: '/dev/ttyUSB0',
 });
 const largeText = new LargeTextRenderer(kernel, {
   fontSize: 24,
-  highContrast: true
+  highContrast: true,
 });
 
 // Input
 kernel.connect(keyboard.output, pty.input);
 
 // Multi-modal accessibility output
-kernel.split(pty.output, [
-  screen.input,
-  tts.input,
-  braille.input,
-  largeText.input
-]);
+kernel.split(pty.output, [screen.input, tts.input, braille.input, largeText.input]);
 
 // User can:
 // - See normal screen
@@ -420,6 +388,7 @@ source → transform1 → transform2 → transform3 → sink
 ```
 
 Example:
+
 ```typescript
 pty → ansiParser → textFormatter → compressionFilter → networkSender
 ```
@@ -431,6 +400,7 @@ source → [sink1, sink2, sink3, ...]
 ```
 
 Example:
+
 ```typescript
 pty → [screen, recorder, logger, aiFormatter]
 ```
@@ -442,6 +412,7 @@ pty → [screen, recorder, logger, aiFormatter]
 ```
 
 Example:
+
 ```typescript
 [keyboard, voice, aiCommands] → pty
 ```
@@ -453,6 +424,7 @@ source → router → [sink1, sink2] (based on condition)
 ```
 
 Example:
+
 ```typescript
 pty → errorDetector → [normalScreen, errorHandler]
 ```
@@ -464,11 +436,12 @@ pty → errorDetector → [normalScreen, errorHandler]
 ✅ **Composability:** Complex behaviors from simple modules  
 ✅ **Reusability:** Same modules work in different compositions  
 ✅ **Extensibility:** New use cases = new module combinations  
-✅ **Location transparency:** Modules work locally or distributed  
+✅ **Location transparency:** Modules work locally or distributed
 
 ## Next Steps
 
 See:
+
 - **[Deployment Flexibility](05-deployment-flexibility.md)** - Run these examples in different deployment modes
 - **[Distributed Service Mesh](06-distributed-service-mesh.md)** - Multi-machine use cases
 - **[Module Types](03-module-types.md)** - How to build these modules
diff --git a/docs/rfcs/stream-kernel/05-deployment-flexibility.md b/docs/rfcs/stream-kernel/05-deployment-flexibility.md
index ac52dc3..7397f84 100644
--- a/docs/rfcs/stream-kernel/05-deployment-flexibility.md
+++ b/docs/rfcs/stream-kernel/05-deployment-flexibility.md
@@ -32,6 +32,7 @@ kernel.connect(pty.output, screen.input);
 **Pipes:** `PassThrough` streams (Node.js in-memory)
 
 **Deployment:**
+
 ```bash
 # Ship as single executable
 pkg index.js --target node18-linux-x64 --output terminal-app
@@ -41,12 +42,14 @@ pkg index.js --target node18-linux-x64 --output terminal-app
 ```
 
 **Advantages:**
+
 - ✅ Simplest deployment
 - ✅ Fastest (no IPC overhead)
 - ✅ Easy to debug
 - ✅ Single binary
 
 **Disadvantages:**
+
 - ❌ No crash isolation
 - ❌ All modules in same memory space
 - ❌ Cannot scale across machines
@@ -76,7 +79,7 @@ const keyboard = new KeyboardInput(kernel);
 const screen = new ScreenRenderer(kernel);
 
 // Connect to PTY in separate process
-const ptyPipe = kernel.createPipe('unix');  // Unix domain socket!
+const ptyPipe = kernel.createPipe('unix'); // Unix domain socket!
 
 kernel.connect(keyboard.output, ptyPipe);
 kernel.connect(ptyPipe, screen.input);
@@ -95,12 +98,14 @@ kernelPTY.connect(pty.output, ipcPipe);
 **Pipes:** `UnixSocketPipe` (Unix domain sockets)
 
 **Advantages:**
+
 - ✅ Crash isolation (PTY crashes, main process survives)
 - ✅ Resource limits per process
 - ✅ Security boundaries
 - ✅ Still on same machine (fast)
 
 **Disadvantages:**
+
 - ❌ IPC overhead (minimal with Unix sockets)
 - ❌ More complex deployment
 - ❌ Cannot scale across machines
@@ -156,12 +161,14 @@ kernelC.connect(gpuProcessor.output, fromMachineA.input);
 **Pipes:** `TCPPipe` or `WebSocketPipe` (network)
 
 **Advantages:**
+
 - ✅ Scale across multiple machines
 - ✅ Specialized hardware (GPU, storage, compute)
 - ✅ Fault tolerance (machine fails, system continues)
 - ✅ Geographic distribution
 
 **Disadvantages:**
+
 - ❌ Network latency
 - ❌ More complex deployment (Docker, K8s)
 - ❌ Network failures to handle
@@ -187,6 +194,7 @@ kernel.connect(uart.output, lcd.input);
 **Pipes:** `RingBufferPipe` (zero-copy shared memory)
 
 **Advantages:**
+
 - ✅ Minimal overhead
 - ✅ Deterministic latency
 - ✅ Direct hardware access
@@ -202,16 +210,16 @@ class Kernel {
     switch (type) {
       case 'local':
         return new PassThrough({ objectMode: true });
-      
+
       case 'unix':
         return new UnixSocketPipe(socketPath);
-      
+
       case 'tcp':
         return new TCPPipe(host, port);
-      
+
       case 'websocket':
         return new WebSocketPipe(url);
-      
+
       case 'ringbuf':
         return new RingBufferPipe(sharedMemory);
     }
@@ -290,20 +298,20 @@ services:
     volumes:
       - ./config:/config
     ports:
-      - "8080:8080"
-  
+      - '8080:8080'
+
   pty:
     image: stream-kernel:latest
     environment:
       - CONFIG=pty.yml
     volumes:
       - ./config:/config
-  
+
   gpu:
     image: stream-kernel:latest
     environment:
       - CONFIG=gpu.yml
-    runtime: nvidia  # GPU access
+    runtime: nvidia # GPU access
     volumes:
       - ./config:/config
 ```
@@ -329,13 +337,13 @@ spec:
   template:
     spec:
       containers:
-      - name: frontend
-        image: stream-kernel:latest
-        env:
-        - name: CONFIG
-          value: "frontend.yml"
-        - name: PTY_SERVICE
-          value: "pty-service:9001"
+        - name: frontend
+          image: stream-kernel:latest
+          env:
+            - name: CONFIG
+              value: 'frontend.yml'
+            - name: PTY_SERVICE
+              value: 'pty-service:9001'
 
 ---
 # pty-service.yml
@@ -347,7 +355,7 @@ spec:
   selector:
     app: pty
   ports:
-  - port: 9001
+    - port: 9001
 ```
 
 **Kubernetes handles service discovery!**
@@ -392,13 +400,14 @@ Pid ! Message
 // This module runs anywhere
 class ParserServer {
   constructor(kernel: Kernel) {
-    this.input = kernel.createPipe();   // Local? Unix? TCP? Doesn't care!
-    this.output = kernel.createPipe();  // Local? Unix? TCP? Doesn't care!
+    this.input = kernel.createPipe(); // Local? Unix? TCP? Doesn't care!
+    this.output = kernel.createPipe(); // Local? Unix? TCP? Doesn't care!
   }
 }
 ```
 
 Whether it runs:
+
 - In-process
 - Different process on same machine
 - Different machine across network
@@ -412,10 +421,11 @@ Whether it runs:
 ✅ **Go distributed:** Multi-machine for scale  
 ✅ **Same code everywhere:** No rewrites  
 ✅ **Test easily:** Local deployment for testing  
-✅ **Deploy flexibly:** Choose deployment per environment  
+✅ **Deploy flexibly:** Choose deployment per environment
 
 ## Next Steps
 
 See:
+
 - **[Distributed Service Mesh](06-distributed-service-mesh.md)** - Multi-machine routing patterns
 - **[Core Architecture](02-core-architecture.md)** - The `createPipe(type)` API
diff --git a/docs/rfcs/stream-kernel/05-router.md b/docs/rfcs/stream-kernel/05-router.md
index a975acc..533b1f9 100644
--- a/docs/rfcs/stream-kernel/05-router.md
+++ b/docs/rfcs/stream-kernel/05-router.md
@@ -37,7 +37,7 @@ router.announce({
   id: 'node:timer1',
   type: 'inproc',
   coordinates: 'node:timer1',
-  metadata: { module: 'TimerSource', runMode: 'inproc' }
+  metadata: { module: 'TimerSource', runMode: 'inproc' },
 });
 
 router.list();
diff --git a/docs/rfcs/stream-kernel/06-distributed-service-mesh.md b/docs/rfcs/stream-kernel/06-distributed-service-mesh.md
index a47de8c..9344d94 100644
--- a/docs/rfcs/stream-kernel/06-distributed-service-mesh.md
+++ b/docs/rfcs/stream-kernel/06-distributed-service-mesh.md
@@ -26,6 +26,7 @@ Think of a routing server as an **airport** with **terminals** (connection point
 ```
 
 **Terminals** are connection points:
+
 - **Local:** Connect to servers in same process/machine
 - **Network:** Connect to remote machines via TCP/WebSocket
 - **Loopback:** For testing or hairpin scenarios
@@ -67,10 +68,14 @@ class RoutingServer {
     this.kernel = kernel;
     this.machineId = machineId;
 
-    kernel.register('router', {
-      type: 'routing',
-      features: ['service-discovery', 'multi-hop']
-    }, kernel.createPipe());
+    kernel.register(
+      'router',
+      {
+        type: 'routing',
+        features: ['service-discovery', 'multi-hop'],
+      },
+      kernel.createPipe(),
+    );
   }
 
   /**
@@ -82,7 +87,7 @@ class RoutingServer {
       type,
       inputPipe: this.kernel.createPipe(),
       outputPipe: this.kernel.createPipe(),
-      remoteAddress: address
+      remoteAddress: address,
     };
 
     terminal.inputPipe.on('data', (envelope: Envelope) => {
@@ -123,7 +128,7 @@ class RoutingServer {
       serviceName,
       terminal,
       machineId,
-      hops
+      hops,
     });
 
     console.log(`[Router] Route added: ${serviceName} → ${terminal} (${hops} hops)`);
@@ -134,7 +139,7 @@ class RoutingServer {
    */
   getLocalServices(): string[] {
     const services: string[] = [];
-    
+
     for (const [name, { caps }] of this.kernel.lookup({})) {
       if (caps.type !== 'routing') {
         services.push(name);
@@ -194,6 +199,7 @@ Machine A (no GPU)          Machine C (has GPU)
 ### Code Example
 
 **Machine A:**
+
 ```typescript
 const kernel = new Kernel();
 const router = new RoutingServer(kernel, 'machine-a');
@@ -220,7 +226,7 @@ const envelope = {
   source: 'pty-server@machine-a',
   destination: 'gpu-server',
   replyTo: 'mp4-encoder@machine-a',
-  data: frame
+  data: frame,
 };
 
 // Send to router
@@ -228,6 +234,7 @@ router.route(envelope);
 ```
 
 **Machine C:**
+
 ```typescript
 const kernelC = new Kernel();
 const routerC = new RoutingServer(kernelC, 'machine-c');
@@ -247,8 +254,8 @@ gpu.input.on('data', (envelope) => {
 
   const reply = {
     source: 'gpu-server@machine-c',
-    destination: envelope.replyTo,  // "mp4-encoder@machine-a"
-    data: processed
+    destination: envelope.replyTo, // "mp4-encoder@machine-a"
+    data: processed,
   };
 
   routerC.route(reply);
@@ -279,7 +286,7 @@ class RoutingServer {
       machineId: this.machineId,
       services: this.getLocalServices(),
       routes: this.getKnownRoutes(),
-      hops: 0
+      hops: 0,
     };
 
     this.broadcastToNetwork(announcement);
@@ -288,12 +295,7 @@ class RoutingServer {
   onAnnouncementReceived(announcement: any, fromTerminal: Terminal): void {
     // Learn about services on announcing machine
     for (const service of announcement.services) {
-      this.addRoute(
-        service,
-        fromTerminal.name,
-        announcement.machineId,
-        announcement.hops + 1
-      );
+      this.addRoute(service, fromTerminal.name, announcement.machineId, announcement.hops + 1);
     }
 
     // Learn about multi-hop routes
@@ -303,12 +305,7 @@ class RoutingServer {
 
       // Only add if closer route
       if (!existing || newHops < existing.hops) {
-        this.addRoute(
-          route.serviceName,
-          fromTerminal.name,
-          route.machineId,
-          newHops
-        );
+        this.addRoute(route.serviceName, fromTerminal.name, route.machineId, newHops);
       }
     }
   }
@@ -328,18 +325,21 @@ class RoutingServer {
 **After announcements propagate:**
 
 **Machine A knows:**
+
 - `pty-server` (local, 0 hops)
 - `parser-server` (via B, 1 hop)
 - `gpu-server` (via C, 1 hop)
 - `mp4-server` (local, 0 hops)
 
 **Machine B knows:**
+
 - `parser-server` (local, 0 hops)
 - `pty-server` (via A, 1 hop)
 - `gpu-server` (via C, 1 hop)
 - `gpu-server` (via A→C, 2 hops) ← Alternative route!
 
 **Machine C knows:**
+
 - `gpu-server` (local, 0 hops)
 - `pty-server` (via A, 1 hop)
 - `parser-server` (via B, 1 hop)
@@ -413,7 +413,6 @@ machines:
       - name: to-machine-b
         type: network
         address: 10.0.0.2:9002
-
 # Service discovery is automatic!
 ```
 
@@ -428,11 +427,7 @@ const router = new RoutingServer(kernel, 'machine-a');
 
 // Create terminals from config
 for (const terminalConfig of machineConfig.terminals) {
-  router.createTerminal(
-    terminalConfig.name,
-    terminalConfig.type,
-    terminalConfig.address
-  );
+  router.createTerminal(terminalConfig.name, terminalConfig.type, terminalConfig.address);
 }
 
 // Start service discovery
@@ -487,13 +482,14 @@ spec:
 ✅ **Automatic discovery** - Service mesh finds routes  
 ✅ **Location transparency** - Servers don't know where peers are  
 ✅ **Multi-hop routing** - Data flows through multiple machines  
-✅ **Hairpin/loopback** - Remote processing, local return  
+✅ **Hairpin/loopback** - Remote processing, local return
 
 **The routing server is policy, not mechanism.** The kernel provides pipes; routing server implements distributed routing as a module.
 
 ## Next Steps
 
 See:
+
 - **[Deployment Flexibility](05-deployment-flexibility.md)** - Single → multi → distributed progression
 - **[Service Registry](07-service-registry.md)** - Capability-based discovery
 - **[PTY Use Cases](04-pty-use-cases.md)** - Example: Remote GPU processing
diff --git a/docs/rfcs/stream-kernel/07-state-manager.md b/docs/rfcs/stream-kernel/07-state-manager.md
index c1880a9..f68440e 100644
--- a/docs/rfcs/stream-kernel/07-state-manager.md
+++ b/docs/rfcs/stream-kernel/07-state-manager.md
@@ -11,6 +11,7 @@ The **StateManager** (also called **ControlPlane**) is a server that tracks all
 ## The Refinery Analogy
 
 Imagine a massive oil refinery:
+
 - **Pipes everywhere** - Thousands of connections moving different products
 - **Control room** - Central HMI showing current state of all pipes, valves, flow rates
 - **Dials and controls** - Operators can modify routing and flow without entering the plant
@@ -27,6 +28,7 @@ Imagine a massive oil refinery:
 **Scenario:** User ships two systems as single binaries to different machines, then wants them to discover each other's capabilities and communicate.
 
 **Example:**
+
 ```typescript
 // Machine A - has PTY and Screen capabilities
 const kernelA = new Kernel();
@@ -58,6 +60,7 @@ stateB.connect(gpu.output, 'tcp://machine-a:9000/screen/input');
 ```
 
 **Key features:**
+
 - Dynamic capability discovery between systems
 - Runtime connection establishment across machines
 - No compile-time knowledge of topology
@@ -67,24 +70,25 @@ stateB.connect(gpu.output, 'tcp://machine-a:9000/screen/input');
 **Scenario:** User builds a single system with all routing pre-configured and compiled in. No runtime discovery needed.
 
 **Example wiring config** (`wiring.yaml`):
+
 ```yaml
 servers:
   - id: keyboard-1
     type: KeyboardInput
     capabilities: [input, keyboard]
-  
+
   - id: pty-1
     type: PTY
     capabilities: [pty, terminal]
-  
+
   - id: parser-1
     type: ANSIParser
     capabilities: [parse, ansi]
-  
+
   - id: screen-1
     type: ScreenRenderer
     capabilities: [render, screen]
-  
+
   - id: ai-formatter-1
     type: AIFormatter
     capabilities: [format, ai-text]
@@ -93,21 +97,22 @@ connections:
   # Keyboard → PTY
   - from: keyboard-1.output
     to: pty-1.input
-    
+
   # PTY → Parser
   - from: pty-1.output
     to: parser-1.input
-    
+
   # Parser → Screen (split)
   - from: parser-1.output
     to: screen-1.input
-    
+
   # Parser → AI Formatter (split)
   - from: parser-1.output
     to: ai-formatter-1.input
 ```
 
 **Compile-time validation:**
+
 ```bash
 # Lint the wiring config before building
 $ mkolbol lint wiring.yaml
@@ -125,6 +130,7 @@ Compiling system with static topology...
 ```
 
 **Runtime startup:**
+
 ```typescript
 // The compiled binary loads the wiring automatically
 const kernel = new Kernel();
@@ -138,6 +144,7 @@ state.startAll();
 ```
 
 **Key features:**
+
 - No runtime discovery needed
 - Config validated at compile time
 - Fast startup (no dynamic wiring)
@@ -151,18 +158,18 @@ StateManager maintains complete state of kernel topology:
 
 ```typescript
 interface PipeMetadata {
-  id: string;              // Unique pipe identifier
-  serverId: string;        // Which server owns this pipe
+  id: string; // Unique pipe identifier
+  serverId: string; // Which server owns this pipe
   direction: 'input' | 'output';
-  address: string;         // Addressable endpoint (e.g., 'pty-1.output')
-  flowRate?: number;       // Bytes/sec (runtime metric)
-  connected: boolean;      // Is pipe currently connected?
+  address: string; // Addressable endpoint (e.g., 'pty-1.output')
+  flowRate?: number; // Bytes/sec (runtime metric)
+  connected: boolean; // Is pipe currently connected?
 }
 
 interface ConnectionMetadata {
-  id: string;              // Unique connection identifier
-  from: string;            // Source pipe address
-  to: string[];            // Destination pipe address(es) - array for split()
+  id: string; // Unique connection identifier
+  from: string; // Source pipe address
+  to: string[]; // Destination pipe address(es) - array for split()
   type: 'direct' | 'split' | 'merge';
   establishedAt: Date;
   bytesTransferred?: number;
@@ -172,12 +179,12 @@ class StateManager {
   private pipes: Map<string, PipeMetadata> = new Map();
   private connections: Map<string, ConnectionMetadata> = new Map();
   private servers: Map<string, ServerMetadata> = new Map();
-  
+
   // Track a new pipe
   registerPipe(pipe: Pipe, metadata: PipeMetadata): void {
     this.pipes.set(metadata.id, metadata);
   }
-  
+
   // Track a new connection
   registerConnection(from: string, to: string[]): void {
     const conn: ConnectionMetadata = {
@@ -185,7 +192,7 @@ class StateManager {
       from,
       to,
       type: to.length > 1 ? 'split' : 'direct',
-      establishedAt: new Date()
+      establishedAt: new Date(),
     };
     this.connections.set(conn.id, conn);
   }
@@ -198,13 +205,13 @@ StateManager tracks all servers in the system:
 
 ```typescript
 interface ServerMetadata {
-  id: string;              // Unique server identifier (e.g., 'pty-1')
-  type: string;            // Server class name (e.g., 'PTY')
-  capabilities: string[];  // What this server can do
-  humanReadable: string;   // Description for humans/AI
-  inputPipes: string[];    // IDs of input pipes
-  outputPipes: string[];   // IDs of output pipes
-  location?: string;       // 'local' | 'tcp://host:port'
+  id: string; // Unique server identifier (e.g., 'pty-1')
+  type: string; // Server class name (e.g., 'PTY')
+  capabilities: string[]; // What this server can do
+  humanReadable: string; // Description for humans/AI
+  inputPipes: string[]; // IDs of input pipes
+  outputPipes: string[]; // IDs of output pipes
+  location?: string; // 'local' | 'tcp://host:port'
   status: 'running' | 'stopped' | 'error';
 }
 
@@ -219,7 +226,7 @@ class StateManager {
       inputPipes: this.detectPipes(server, 'input'),
       outputPipes: this.detectPipes(server, 'output'),
       location: metadata.location || 'local',
-      status: 'running'
+      status: 'running',
     };
     this.servers.set(id, fullMeta);
   }
@@ -237,26 +244,25 @@ class StateManager {
     return {
       servers: Array.from(this.servers.values()),
       pipes: Array.from(this.pipes.values()),
-      connections: Array.from(this.connections.values())
+      connections: Array.from(this.connections.values()),
     };
   }
-  
+
   // Find servers by capability
   findByCapability(capability: string): ServerMetadata[] {
-    return Array.from(this.servers.values())
-      .filter(s => s.capabilities.includes(capability));
+    return Array.from(this.servers.values()).filter((s) => s.capabilities.includes(capability));
   }
-  
+
   // Get flow metrics
   getFlowMetrics(pipeId: string): FlowMetrics {
     const pipe = this.pipes.get(pipeId);
     return {
       bytesPerSecond: pipe?.flowRate || 0,
       totalBytes: this.calculateTotalBytes(pipeId),
-      lastActivity: this.getLastActivity(pipeId)
+      lastActivity: this.getLastActivity(pipeId),
     };
   }
-  
+
   // Trace data flow path
   tracePath(fromPipeId: string, toPipeId: string): Connection[] {
     // BFS to find path through connections
@@ -275,23 +281,23 @@ class StateManager {
   async connect(fromAddress: string, toAddress: string): Promise<void> {
     const fromPipe = this.resolvePipe(fromAddress);
     const toPipe = this.resolvePipe(toAddress);
-    
+
     // Use kernel to make connection
     this.kernel.connect(fromPipe, toPipe);
-    
+
     // Track in state
     this.registerConnection(fromAddress, [toAddress]);
   }
-  
+
   // Split to multiple destinations
   async split(fromAddress: string, toAddresses: string[]): Promise<void> {
     const fromPipe = this.resolvePipe(fromAddress);
-    const toPipes = toAddresses.map(addr => this.resolvePipe(addr));
-    
+    const toPipes = toAddresses.map((addr) => this.resolvePipe(addr));
+
     this.kernel.split(fromPipe, toPipes);
     this.registerConnection(fromAddress, toAddresses);
   }
-  
+
   // Disconnect
   async disconnect(fromAddress: string, toAddress: string): Promise<void> {
     const connId = `${fromAddress}→${toAddress}`;
@@ -313,39 +319,39 @@ class StateManager {
   // Export as Mermaid diagram
   exportMermaid(): string {
     let diagram = 'graph LR\n';
-    
+
     for (const server of this.servers.values()) {
       diagram += `  ${server.id}["${server.humanReadable}"]\n`;
     }
-    
+
     for (const conn of this.connections.values()) {
       for (const to of conn.to) {
         diagram += `  ${conn.from} --> ${to}\n`;
       }
     }
-    
+
     return diagram;
   }
-  
+
   // Export as JSON for custom renderers
   exportJSON(): string {
     return JSON.stringify(this.getTopology(), null, 2);
   }
-  
+
   // Export as DOT (Graphviz)
   exportDOT(): string {
     let dot = 'digraph Topology {\n';
-    
+
     for (const server of this.servers.values()) {
       dot += `  "${server.id}" [label="${server.humanReadable}"];\n`;
     }
-    
+
     for (const conn of this.connections.values()) {
       for (const to of conn.to) {
         dot += `  "${conn.from}" -> "${to}";\n`;
       }
     }
-    
+
     dot += '}';
     return dot;
   }
@@ -360,7 +366,7 @@ YAML format for specifying static topology:
 
 ```yaml
 # wiring.yaml
-version: "1.0"
+version: '1.0'
 
 # Define all servers
 servers:
@@ -369,7 +375,7 @@ servers:
     config:
       device: /dev/input/keyboard0
     capabilities: [input, keyboard]
-    
+
   - id: pty-1
     type: PTY
     config:
@@ -377,11 +383,11 @@ servers:
       rows: 24
       cols: 80
     capabilities: [pty, terminal]
-    
+
   - id: parser-1
     type: ANSIParser
     capabilities: [parse, ansi]
-    
+
   - id: screen-1
     type: ScreenRenderer
     config:
@@ -393,17 +399,17 @@ connections:
   # Simple connections
   - from: keyboard-1.output
     to: pty-1.input
-    
+
   - from: pty-1.output
     to: parser-1.input
-    
+
   # Split (one-to-many)
   - from: parser-1.output
-    to: 
+    to:
       - screen-1.input
       - ai-formatter-1.input
     type: split
-    
+
   # Merge (many-to-one)
   - from:
       - voice-1.output
@@ -423,7 +429,7 @@ routing:
 class WiringValidator {
   validate(config: WiringConfig): ValidationResult {
     const errors: string[] = [];
-    
+
     // Check unique IDs
     const ids = new Set<string>();
     for (const server of config.servers) {
@@ -432,14 +438,14 @@ class WiringValidator {
       }
       ids.add(server.id);
     }
-    
+
     // Check connections reference valid servers
     for (const conn of config.connections) {
       const from = this.parsePipeAddress(conn.from);
       if (!ids.has(from.serverId)) {
         errors.push(`Unknown server in connection: ${from.serverId}`);
       }
-      
+
       for (const to of Array.isArray(conn.to) ? conn.to : [conn.to]) {
         const toParsed = this.parsePipeAddress(to);
         if (!ids.has(toParsed.serverId)) {
@@ -447,15 +453,15 @@ class WiringValidator {
         }
       }
     }
-    
+
     // Check for cycles (would cause deadlocks)
     if (this.hasCycles(config)) {
       errors.push('Topology contains cycles');
     }
-    
+
     return {
       valid: errors.length === 0,
-      errors
+      errors,
     };
   }
 }
@@ -468,19 +474,20 @@ Every pipe in the system has a unique address:
 ```typescript
 // Format: {server-id}.{pipe-direction}
 // Examples:
-'pty-1.output'           // PTY server's output pipe
-'parser-1.input'         // Parser server's input pipe
-'screen-1.input'         // Screen renderer's input pipe
+'pty-1.output'; // PTY server's output pipe
+'parser-1.input'; // Parser server's input pipe
+'screen-1.input'; // Screen renderer's input pipe
 
 // For remote servers:
-'tcp://machine-b:9000/gpu-1.output'  // Remote GPU server
+'tcp://machine-b:9000/gpu-1.output'; // Remote GPU server
 
 // For terminal-based routing:
-'router-1.terminal-A'    // Router's terminal A
-'router-1.terminal-B'    // Router's terminal B
+'router-1.terminal-A'; // Router's terminal A
+'router-1.terminal-B'; // Router's terminal B
 ```
 
 **Uniqueness guaranteed by:**
+
 1. Server IDs must be unique within a system
 2. Pipe directions (input/output) are unique per server
 3. Terminals on routing servers have unique names
@@ -492,35 +499,37 @@ StateManager can track metrics about data flowing through pipes:
 ```typescript
 class StateManager {
   private metrics: Map<string, PipeMetrics> = new Map();
-  
+
   // Monitor pipe activity
   monitorPipe(pipeId: string): void {
     const pipe = this.resolvePipe(pipeId);
-    
+
     let bytesTransferred = 0;
     let lastActivity = Date.now();
-    
+
     pipe.on('data', (chunk) => {
       bytesTransferred += chunk.length;
       lastActivity = Date.now();
-      
+
       this.metrics.set(pipeId, {
         bytesTransferred,
         bytesPerSecond: this.calculateRate(pipeId),
         lastActivity: new Date(lastActivity),
-        active: true
+        active: true,
       });
     });
   }
-  
+
   // Get current metrics
   getMetrics(pipeId: string): PipeMetrics {
-    return this.metrics.get(pipeId) || {
-      bytesTransferred: 0,
-      bytesPerSecond: 0,
-      lastActivity: null,
-      active: false
-    };
+    return (
+      this.metrics.get(pipeId) || {
+        bytesTransferred: 0,
+        bytesPerSecond: 0,
+        lastActivity: null,
+        active: false,
+      }
+    );
   }
 }
 ```
@@ -535,21 +544,21 @@ StateManager provides an interface for other servers to interact with the topolo
 class RoutingServer {
   constructor(
     private kernel: Kernel,
-    private stateManager: StateManager
+    private stateManager: StateManager,
   ) {}
-  
+
   async routeToCapability(data: any, capability: string): Promise<void> {
     // Ask StateManager where to send data
     const servers = this.stateManager.findByCapability(capability);
-    
+
     if (servers.length === 0) {
       throw new Error(`No server with capability: ${capability}`);
     }
-    
+
     // Route to first available
     const target = servers[0];
     const targetPipe = this.stateManager.resolvePipe(`${target.id}.input`);
-    
+
     // Send data
     targetPipe.write(data);
   }
@@ -562,22 +571,22 @@ class RoutingServer {
 class DiscoveryServer {
   constructor(
     private kernel: Kernel,
-    private stateManager: StateManager
+    private stateManager: StateManager,
   ) {}
-  
+
   async announceCapabilities(): Promise<void> {
     const topology = this.stateManager.getTopology();
-    
+
     // Broadcast to mesh network
     const announcement = {
       capabilities: this.extractAllCapabilities(topology),
-      servers: topology.servers.map(s => ({
+      servers: topology.servers.map((s) => ({
         id: s.id,
         type: s.type,
-        capabilities: s.capabilities
-      }))
+        capabilities: s.capabilities,
+      })),
     };
-    
+
     this.broadcastToMesh(announcement);
   }
 }
@@ -591,7 +600,7 @@ class DiscoveryServer {
 // ❌ WRONG - StateManager in kernel
 class Kernel {
   private stateManager: StateManager; // NO!
-  
+
   createPipe(): Pipe {
     const pipe = new PassThrough();
     this.stateManager.track(pipe); // Kernel shouldn't know about StateManager!
@@ -610,7 +619,7 @@ class StateManager {
   constructor(private kernel: Kernel) {
     // StateManager uses kernel, not vice versa
   }
-  
+
   createAndTrackPipe(): Pipe {
     const pipe = this.kernel.createPipe(); // Use kernel's mechanism
     this.trackPipe(pipe); // Add our policy/tracking
@@ -620,6 +629,7 @@ class StateManager {
 ```
 
 **Why this matters:**
+
 - Kernel stays minimal (~100 lines)
 - StateManager is optional (you can run without it)
 - Multiple StateManagers possible (different policies)
@@ -632,33 +642,47 @@ These are **three different servers**:
 ```typescript
 // StateManager: Tracks state, provides introspection/control
 class StateManager {
-  getTopology(): Topology { /* ... */ }
-  connect(from, to): void { /* ... */ }
-  getMetrics(pipe): Metrics { /* ... */ }
+  getTopology(): Topology {
+    /* ... */
+  }
+  connect(from, to): void {
+    /* ... */
+  }
+  getMetrics(pipe): Metrics {
+    /* ... */
+  }
 }
 
 // RoutingServer: Routes data based on addresses/capabilities
 class RoutingServer {
-  route(data, destination): void { /* ... */ }
-  routeByCapability(data, cap): void { /* ... */ }
+  route(data, destination): void {
+    /* ... */
+  }
+  routeByCapability(data, cap): void {
+    /* ... */
+  }
 }
 
 // DiscoveryServer: Helps servers find each other
 class DiscoveryServer {
-  announce(capabilities): void { /* ... */ }
-  discover(query): Server[] { /* ... */ }
+  announce(capabilities): void {
+    /* ... */
+  }
+  discover(query): Server[] {
+    /* ... */
+  }
 }
 ```
 
 **They work together:**
+
 ```typescript
 // RoutingServer queries StateManager to find destinations
 const servers = stateManager.findByCapability('gpu');
 router.routeTo(data, servers[0].id);
 
 // DiscoveryServer uses StateManager to announce capabilities
-const caps = stateManager.getTopology().servers
-  .flatMap(s => s.capabilities);
+const caps = stateManager.getTopology().servers.flatMap((s) => s.capabilities);
 discovery.announce(caps);
 ```
 
@@ -678,37 +702,34 @@ const parser = new ANSIParser(kernel);
 const screen = new ScreenRenderer(kernel);
 
 // Register with StateManager
-state.register(keyboard, { 
+state.register(keyboard, {
   id: 'keyboard-1',
   capabilities: ['input', 'keyboard'],
-  humanReadable: 'Primary keyboard input'
+  humanReadable: 'Primary keyboard input',
 });
 
 state.register(pty, {
-  id: 'pty-1', 
+  id: 'pty-1',
   capabilities: ['pty', 'terminal'],
-  humanReadable: 'Bash shell PTY'
+  humanReadable: 'Bash shell PTY',
 });
 
 state.register(parser, {
   id: 'parser-1',
   capabilities: ['parse', 'ansi'],
-  humanReadable: 'ANSI escape code parser'
+  humanReadable: 'ANSI escape code parser',
 });
 
 state.register(screen, {
   id: 'screen-1',
   capabilities: ['render', 'screen'],
-  humanReadable: 'Screen renderer (xterm.js)'
+  humanReadable: 'Screen renderer (xterm.js)',
 });
 
 // Wire up using StateManager
 state.connect('keyboard-1.output', 'pty-1.input');
 state.connect('pty-1.output', 'parser-1.input');
-state.split('parser-1.output', [
-  'screen-1.input',
-  'ai-formatter-1.input'
-]);
+state.split('parser-1.output', ['screen-1.input', 'ai-formatter-1.input']);
 
 // Export topology for visualization
 console.log(state.exportMermaid());
@@ -741,26 +762,26 @@ describe('Topology Validation', () => {
     const config = loadWiringConfig('wiring.yaml');
     const validator = new WiringValidator();
     const result = validator.validate(config);
-    
+
     expect(result.valid).toBe(true);
     expect(result.errors).toEqual([]);
   });
-  
+
   it('detects cycles', () => {
     const config = {
       servers: [
         { id: 'a', type: 'ServerA' },
-        { id: 'b', type: 'ServerB' }
+        { id: 'b', type: 'ServerB' },
       ],
       connections: [
         { from: 'a.output', to: 'b.input' },
-        { from: 'b.output', to: 'a.input' } // Cycle!
-      ]
+        { from: 'b.output', to: 'a.input' }, // Cycle!
+      ],
     };
-    
+
     const validator = new WiringValidator();
     const result = validator.validate(config);
-    
+
     expect(result.valid).toBe(false);
     expect(result.errors).toContain('Topology contains cycles');
   });
@@ -770,16 +791,16 @@ describe('StateManager Runtime', () => {
   it('tracks connections', () => {
     const kernel = new Kernel();
     const state = new StateManager(kernel);
-    
+
     const p1 = kernel.createPipe();
     const p2 = kernel.createPipe();
-    
+
     state.registerPipe(p1, { id: 'p1', serverId: 's1', direction: 'output' });
     state.registerPipe(p2, { id: 'p2', serverId: 's2', direction: 'input' });
-    
+
     kernel.connect(p1, p2);
     state.registerConnection('p1', ['p2']);
-    
+
     const topology = state.getTopology();
     expect(topology.connections).toHaveLength(1);
     expect(topology.connections[0].from).toBe('p1');
@@ -791,6 +812,7 @@ describe('StateManager Runtime', () => {
 ## Summary
 
 **StateManager/ControlPlane is:**
+
 - ✅ A server built on top of the kernel
 - ✅ The "HMI control room" for your pipe topology
 - ✅ Supports both compile-time (static) and runtime (dynamic) wiring
@@ -801,6 +823,7 @@ describe('StateManager Runtime', () => {
 - ✅ Testable and swappable (different StateManager implementations possible)
 
 **StateManager is NOT:**
+
 - ❌ Part of the kernel itself
 - ❌ A routing server (that's separate)
 - ❌ A discovery server (that's separate)
diff --git a/docs/rfcs/stream-kernel/08-registry-server.md b/docs/rfcs/stream-kernel/08-registry-server.md
index 2318f84..e9aa8a8 100644
--- a/docs/rfcs/stream-kernel/08-registry-server.md
+++ b/docs/rfcs/stream-kernel/08-registry-server.md
@@ -9,6 +9,7 @@ The **Registry Server** (affectionately called "The Hostess") is a server that m
 ## The Metaphor
 
 Imagine a sophisticated dinner party:
+
 - **Servers are guests** - They arrive and sign the guest book
 - **The Hostess** - Greets guests, tracks who's here, manages seating (port assignments)
 - **The StateManager** - Plans the seating chart and conversation flow (connection topology)
@@ -27,6 +28,7 @@ Three different servers, three different concerns.
 **Scenario:** User ships system as single binary with enough capability baked in so mesh would work. Second system on another machine does the same. User decides "I want each system to know about capabilities of the other system."
 
 **Flow:**
+
 1. System A boots, servers register with local Hostess A
 2. System B boots, servers register with local Hostess B
 3. Hostess A exposes registry via HTTP/LLDP interface
@@ -39,6 +41,7 @@ Three different servers, three different concerns.
 **Scenario:** User ships single system, plans it to be static, needs way to tell kernel how to "wire" things up at startup.
 
 **Flow:**
+
 1. Compile-time manifest defines: server names, terminals, flow direction
 2. Manifest compiled into each server binary
 3. Servers boot and register with Hostess using compiled manifest data
@@ -58,15 +61,15 @@ fqdn:servername:hexcode:owner:authentication:auth_mechanism:UUID
 
 ### Field Breakdown
 
-| Field | Description | Example |
-|-------|-------------|---------|
-| `fqdn` | Fully qualified domain name or hostname | `machine-a.local`, `192.168.1.100`, `localhost` |
-| `servername` | Hurd-style server name (what it does) | `pty-server`, `gpu-renderer`, `audio-out` |
-| `hexcode` | Class of server (category/type) | `0x0001` (PTY), `0x0002` (Renderer), `0x0003` (Audio) |
-| `owner` | Owner identity (compile-time, changeable at runtime) | `user-alice`, `system`, `container-xyz` |
-| `authentication` | Whether auth is required | `yes`, `no`, `optional` |
-| `auth_mechanism` | How to authenticate | `preshared-secret`, `tls-cert`, `none` |
-| `UUID` | Random unique identifier | `550e8400-e29b-41d4-a716-446655440000` |
+| Field            | Description                                          | Example                                               |
+| ---------------- | ---------------------------------------------------- | ----------------------------------------------------- |
+| `fqdn`           | Fully qualified domain name or hostname              | `machine-a.local`, `192.168.1.100`, `localhost`       |
+| `servername`     | Hurd-style server name (what it does)                | `pty-server`, `gpu-renderer`, `audio-out`             |
+| `hexcode`        | Class of server (category/type)                      | `0x0001` (PTY), `0x0002` (Renderer), `0x0003` (Audio) |
+| `owner`          | Owner identity (compile-time, changeable at runtime) | `user-alice`, `system`, `container-xyz`               |
+| `authentication` | Whether auth is required                             | `yes`, `no`, `optional`                               |
+| `auth_mechanism` | How to authenticate                                  | `preshared-secret`, `tls-cert`, `none`                |
+| `UUID`           | Random unique identifier                             | `550e8400-e29b-41d4-a716-446655440000`                |
 
 ### Example Names
 
@@ -91,22 +94,22 @@ Each server includes a manifest compiled into its binary at build time:
 
 ```typescript
 interface ServerManifest {
-  name: string;              // Human-readable server name
-  class: string;             // Hex code (e.g., "0x0001")
-  owner: string;             // Owner identity
+  name: string; // Human-readable server name
+  class: string; // Hex code (e.g., "0x0001")
+  owner: string; // Owner identity
   authentication: {
-    required: "yes" | "no" | "optional";
-    mechanism: string;       // "preshared-secret", "tls-cert", "none"
+    required: 'yes' | 'no' | 'optional';
+    mechanism: string; // "preshared-secret", "tls-cert", "none"
   };
-  terminals: Terminal[];     // Exposed connection points
-  metadata: Record<string, any>;  // Additional info
+  terminals: Terminal[]; // Exposed connection points
+  metadata: Record<string, any>; // Additional info
 }
 
 interface Terminal {
-  name: string;              // Terminal identifier (e.g., "input", "output")
-  direction: "input" | "output" | "bidirectional";
-  multiplexing: "none" | "fanout" | "fanin";  // Flow pattern
-  protocol?: string;         // Optional protocol hint (e.g., "json-rpc")
+  name: string; // Terminal identifier (e.g., "input", "output")
+  direction: 'input' | 'output' | 'bidirectional';
+  multiplexing: 'none' | 'fanout' | 'fanin'; // Flow pattern
+  protocol?: string; // Optional protocol hint (e.g., "json-rpc")
   metadata?: Record<string, any>;
 }
 ```
@@ -116,37 +119,37 @@ interface Terminal {
 ```typescript
 // PTY Server Manifest (compiled into binary)
 const manifest: ServerManifest = {
-  name: "pty-server",
-  class: "0x0001",
-  owner: "system",
+  name: 'pty-server',
+  class: '0x0001',
+  owner: 'system',
   authentication: {
-    required: "no",
-    mechanism: "none"
+    required: 'no',
+    mechanism: 'none',
   },
   terminals: [
     {
-      name: "stdin",
-      direction: "input",
-      multiplexing: "none",
-      protocol: "raw-bytes"
+      name: 'stdin',
+      direction: 'input',
+      multiplexing: 'none',
+      protocol: 'raw-bytes',
     },
     {
-      name: "stdout",
-      direction: "output",
-      multiplexing: "fanout",  // Can send to multiple renderers
-      protocol: "ansi-escape"
+      name: 'stdout',
+      direction: 'output',
+      multiplexing: 'fanout', // Can send to multiple renderers
+      protocol: 'ansi-escape',
     },
     {
-      name: "stderr",
-      direction: "output",
-      multiplexing: "fanout",
-      protocol: "ansi-escape"
-    }
+      name: 'stderr',
+      direction: 'output',
+      multiplexing: 'fanout',
+      protocol: 'ansi-escape',
+    },
   ],
   metadata: {
-    version: "1.0.0",
-    description: "PTY server for terminal emulation"
-  }
+    version: '1.0.0',
+    description: 'PTY server for terminal emulation',
+  },
 };
 ```
 
@@ -159,37 +162,37 @@ When a server starts, it registers with the Hostess by signing the guest book:
 ```typescript
 interface GuestBookEntry {
   // Identity
-  id: string;                // Full name (fqdn:servername:hex:owner:auth:mechanism:UUID)
+  id: string; // Full name (fqdn:servername:hex:owner:auth:mechanism:UUID)
   fqdn: string;
   servername: string;
   class: string;
   owner: string;
   uuid: string;
-  
+
   // Authentication
   authentication: {
-    required: "yes" | "no" | "optional";
+    required: 'yes' | 'no' | 'optional';
     mechanism: string;
   };
-  
+
   // Terminals (connection points)
   terminals: {
     [terminalName: string]: {
-      direction: "input" | "output" | "bidirectional";
-      multiplexing: "none" | "fanout" | "fanin";
-      inUse: boolean;              // Track availability
-      connectedTo?: string[];      // Connectome IDs (from StateManager)
+      direction: 'input' | 'output' | 'bidirectional';
+      multiplexing: 'none' | 'fanout' | 'fanin';
+      inUse: boolean; // Track availability
+      connectedTo?: string[]; // Connectome IDs (from StateManager)
       metadata: Record<string, any>;
-    }
+    };
   };
-  
+
   // Metadata
-  registeredAt: number;        // Timestamp
-  lastHeartbeat: number;       // For liveness checking
+  registeredAt: number; // Timestamp
+  lastHeartbeat: number; // For liveness checking
   metadata: Record<string, any>;
-  
+
   // Capabilities (what this server can do)
-  capabilities: string[];      // e.g., ["pty", "ansi-parsing", "vt100"]
+  capabilities: string[]; // e.g., ["pty", "ansi-parsing", "vt100"]
 }
 ```
 
@@ -201,41 +204,41 @@ class PTYServer {
   async start() {
     // Generate UUID
     const uuid = crypto.randomUUID();
-    
+
     // Build full name
     const hostname = os.hostname();
     const fullName = `${hostname}:pty-server:0x0001:system:no:none:${uuid}`;
-    
+
     // Register with Hostess
     await hostess.register({
       id: fullName,
       fqdn: hostname,
-      servername: "pty-server",
-      class: "0x0001",
-      owner: "system",
+      servername: 'pty-server',
+      class: '0x0001',
+      owner: 'system',
       uuid: uuid,
       authentication: {
-        required: "no",
-        mechanism: "none"
+        required: 'no',
+        mechanism: 'none',
       },
       terminals: {
         stdin: {
-          direction: "input",
-          multiplexing: "none",
+          direction: 'input',
+          multiplexing: 'none',
           inUse: false,
-          metadata: { protocol: "raw-bytes" }
+          metadata: { protocol: 'raw-bytes' },
         },
         stdout: {
-          direction: "output",
-          multiplexing: "fanout",
+          direction: 'output',
+          multiplexing: 'fanout',
           inUse: false,
-          metadata: { protocol: "ansi-escape" }
-        }
+          metadata: { protocol: 'ansi-escape' },
+        },
       },
-      capabilities: ["pty", "vt100", "ansi-parsing"],
-      metadata: { version: "1.0.0" }
+      capabilities: ['pty', 'vt100', 'ansi-parsing'],
+      metadata: { version: '1.0.0' },
     });
-    
+
     // Start heartbeat
     setInterval(() => hostess.heartbeat(fullName), 5000);
   }
@@ -252,35 +255,35 @@ The Hostess exposes a simple API via her input/output terminals:
 interface HostessAPI {
   // Register a server
   register(entry: GuestBookEntry): Promise<void>;
-  
+
   // Unregister a server
   unregister(serverId: string): Promise<void>;
-  
+
   // Query servers by filter
   query(filter: ServerFilter): Promise<GuestBookEntry[]>;
-  
+
   // Mark terminal as in use
   markInUse(serverId: string, terminalName: string, connectomeId: string): Promise<void>;
-  
+
   // Mark terminal as available
   markAvailable(serverId: string, terminalName: string): Promise<void>;
-  
+
   // Get specific server details
   getServer(serverId: string): Promise<GuestBookEntry | null>;
-  
+
   // Heartbeat (liveness check)
   heartbeat(serverId: string): Promise<void>;
-  
+
   // List all registered servers
   listAll(): Promise<GuestBookEntry[]>;
 }
 
 interface ServerFilter {
-  fqdn?: string;               // Filter by hostname
-  servername?: string;         // Filter by server name
-  class?: string;              // Filter by hex class
-  owner?: string;              // Filter by owner
-  capabilities?: string[];     // Must have ALL these capabilities
+  fqdn?: string; // Filter by hostname
+  servername?: string; // Filter by server name
+  class?: string; // Filter by hex class
+  owner?: string; // Filter by owner
+  capabilities?: string[]; // Must have ALL these capabilities
   availableTerminals?: number; // Must have N available terminals
 }
 ```
@@ -293,32 +296,24 @@ class StateManager {
   async executeWiringPlan(plan: WiringPlan) {
     // Query Hostess for available GPU renderers
     const gpuServers = await hostess.query({
-      class: "0x0002",           // GPU renderer class
-      capabilities: ["gpu", "h264"],
-      availableTerminals: 1       // Need at least 1 free terminal
+      class: '0x0002', // GPU renderer class
+      capabilities: ['gpu', 'h264'],
+      availableTerminals: 1, // Need at least 1 free terminal
     });
-    
+
     if (gpuServers.length < 4) {
-      throw new Error("Insufficient GPU servers available");
+      throw new Error('Insufficient GPU servers available');
     }
-    
+
     // Take first 4 servers
     const selected = gpuServers.slice(0, 4);
-    
+
     // Create connections
     for (const server of selected) {
-      const connection = await this.createConnection(
-        plan.source,
-        server.id,
-        "input"
-      );
-      
+      const connection = await this.createConnection(plan.source, server.id, 'input');
+
       // Report back to Hostess
-      await hostess.markInUse(
-        server.id,
-        "input",
-        connection.connectomeId
-      );
+      await hostess.markInUse(server.id, 'input', connection.connectomeId);
     }
   }
 }
@@ -328,13 +323,13 @@ class StateManager {
 
 ### Hostess vs StateManager
 
-| Concern | Hostess | StateManager |
-|---------|---------|--------------|
-| **Purpose** | Registry & availability tracking | Connection topology & wiring |
-| **Tracks** | What servers exist, their capabilities | How servers are connected |
-| **Source of truth** | Server registry, port availability | Connection graph (connectome) |
-| **Queries** | "Give me 4 GPU servers" | "What's connected to PTY output?" |
-| **Responsibilities** | Registration, heartbeat, liveness | Wiring, flow control, topology |
+| Concern              | Hostess                                | StateManager                      |
+| -------------------- | -------------------------------------- | --------------------------------- |
+| **Purpose**          | Registry & availability tracking       | Connection topology & wiring      |
+| **Tracks**           | What servers exist, their capabilities | How servers are connected         |
+| **Source of truth**  | Server registry, port availability     | Connection graph (connectome)     |
+| **Queries**          | "Give me 4 GPU servers"                | "What's connected to PTY output?" |
+| **Responsibilities** | Registration, heartbeat, liveness      | Wiring, flow control, topology    |
 
 ### The Conversation
 
@@ -349,14 +344,14 @@ Hostess: "I have 6 registered. Here are their IDs:
   - machine-c.local:gpu-renderer:0x0002:system:yes:psk:uuid5
   - machine-c.local:gpu-renderer:0x0002:system:yes:psk:uuid6"
 
-StateManager: "Perfect. I'll use the first 4. Here are the connectome IDs 
+StateManager: "Perfect. I'll use the first 4. Here are the connectome IDs
                for their input terminals:
   - uuid1.input → connectome-id-100
   - uuid2.input → connectome-id-101
   - uuid3.input → connectome-id-102
   - uuid4.input → connectome-id-103"
 
-Hostess: "Got it. I've marked those terminals as in use and recorded the 
+Hostess: "Got it. I've marked those terminals as in use and recorded the
           connectome mappings."
 ```
 
@@ -371,15 +366,15 @@ The Hostess can expose her guest book via multiple interfaces for mesh networkin
 ```typescript
 class Hostess {
   // Local pipe interface (default)
-  inputPipe: Pipe;     // Receives commands
-  outputPipe: Pipe;    // Sends responses
-  
+  inputPipe: Pipe; // Receives commands
+  outputPipe: Pipe; // Sends responses
+
   // Optional: HTTP interface for remote discovery
   httpInterface?: HTTPInterface;
-  
+
   // Optional: Shared memory interface for same-machine IPC
   shmemInterface?: SharedMemoryInterface;
-  
+
   // Optional: LLDP-style broadcast announcements
   lldpInterface?: LLDPInterface;
 }
@@ -393,34 +388,34 @@ Expose guest book over HTTP for remote systems:
 // HTTP interface for Hostess
 class HTTPInterface {
   constructor(private hostess: Hostess) {}
-  
+
   start(port: number) {
     const app = express();
-    
+
     // GET /servers - List all servers
     app.get('/servers', async (req, res) => {
       const servers = await this.hostess.listAll();
       res.json(servers);
     });
-    
+
     // GET /servers/:id - Get specific server
     app.get('/servers/:id', async (req, res) => {
       const server = await this.hostess.getServer(req.params.id);
       res.json(server || { error: 'Not found' });
     });
-    
+
     // POST /query - Query with filter
     app.post('/query', async (req, res) => {
       const results = await this.hostess.query(req.body);
       res.json(results);
     });
-    
+
     // POST /register - Remote registration
     app.post('/register', async (req, res) => {
       await this.hostess.register(req.body);
       res.json({ success: true });
     });
-    
+
     app.listen(port);
   }
 }
@@ -433,11 +428,11 @@ Inspired by LLDP (Link Layer Discovery Protocol), the Hostess can broadcast peri
 ```typescript
 class LLDPInterface {
   constructor(private hostess: Hostess) {}
-  
+
   startBroadcast(intervalMs: number = 30000) {
     setInterval(async () => {
       const servers = await this.hostess.listAll();
-      
+
       // Broadcast announcement packet
       const announcement = {
         type: 'HOSTESS_ANNOUNCEMENT',
@@ -446,18 +441,18 @@ class LLDPInterface {
         hostessId: this.hostess.id,
         serverCount: servers.length,
         capabilities: this.aggregateCapabilities(servers),
-        endpoint: `http://${os.hostname()}:${this.port}/servers`
+        endpoint: `http://${os.hostname()}:${this.port}/servers`,
       };
-      
+
       // Send via UDP multicast or other broadcast mechanism
       this.broadcast(announcement);
     }, intervalMs);
   }
-  
+
   private aggregateCapabilities(servers: GuestBookEntry[]): string[] {
     const caps = new Set<string>();
     for (const server of servers) {
-      server.capabilities.forEach(c => caps.add(c));
+      server.capabilities.forEach((c) => caps.add(c));
     }
     return Array.from(caps);
   }
@@ -481,16 +476,16 @@ hostessB.enableLLDP();
 hostessB.on('discovery', async (announcement) => {
   console.log(`Discovered Hostess on ${announcement.fqdn}`);
   console.log(`Capabilities: ${announcement.capabilities.join(', ')}`);
-  
+
   // Query remote Hostess for GPU servers
   const response = await fetch(`${announcement.endpoint}`, {
     method: 'POST',
     body: JSON.stringify({
-      class: "0x0002",  // GPU renderers
-      capabilities: ["gpu", "h264"]
-    })
+      class: '0x0002', // GPU renderers
+      capabilities: ['gpu', 'h264'],
+    }),
   });
-  
+
   const remoteGPUs = await response.json();
   console.log(`Found ${remoteGPUs.length} GPU servers on ${announcement.fqdn}`);
 });
@@ -503,20 +498,20 @@ For ultra-low-latency same-machine discovery:
 ```typescript
 class SharedMemoryInterface {
   private shmem: SharedMemoryBuffer;
-  
+
   constructor(private hostess: Hostess) {
     // Create shared memory region
     this.shmem = new SharedMemoryBuffer('/hostess-registry', 1024 * 1024); // 1MB
   }
-  
+
   async sync() {
     const servers = await this.hostess.listAll();
-    
+
     // Serialize to shared memory
     const data = msgpack.encode(servers);
     this.shmem.write(data);
   }
-  
+
   // Other processes can read directly from shared memory
   // without network overhead
 }
@@ -565,65 +560,62 @@ By exposing the Hostess via multiple interfaces, you create an **information mes
 // Hostess implementation (simplified)
 class Hostess {
   private guestBook: Map<string, GuestBookEntry> = new Map();
-  
+
   inputPipe: Pipe;
   outputPipe: Pipe;
-  
+
   constructor(kernel: Kernel) {
     this.inputPipe = kernel.createPipe();
     this.outputPipe = kernel.createPipe();
-    
+
     // Listen for commands on input pipe
     this.inputPipe.on('data', (msg) => this.handleCommand(msg));
   }
-  
+
   async handleCommand(msg: any) {
     switch (msg.command) {
       case 'register':
         await this.register(msg.entry);
         this.outputPipe.write({ success: true });
         break;
-      
+
       case 'query':
         const results = await this.query(msg.filter);
         this.outputPipe.write({ results });
         break;
-      
+
       case 'markInUse':
         await this.markInUse(msg.serverId, msg.terminal, msg.connectomeId);
         this.outputPipe.write({ success: true });
         break;
     }
   }
-  
+
   async query(filter: ServerFilter): Promise<GuestBookEntry[]> {
     const entries = Array.from(this.guestBook.values());
-    
-    return entries.filter(entry => {
+
+    return entries.filter((entry) => {
       if (filter.fqdn && entry.fqdn !== filter.fqdn) return false;
       if (filter.class && entry.class !== filter.class) return false;
       if (filter.capabilities) {
-        const hasAll = filter.capabilities.every(c => 
-          entry.capabilities.includes(c)
-        );
+        const hasAll = filter.capabilities.every((c) => entry.capabilities.includes(c));
         if (!hasAll) return false;
       }
       if (filter.availableTerminals !== undefined) {
-        const available = Object.values(entry.terminals)
-          .filter(t => !t.inUse).length;
+        const available = Object.values(entry.terminals).filter((t) => !t.inUse).length;
         if (available < filter.availableTerminals) return false;
       }
       return true;
     });
   }
-  
+
   async markInUse(serverId: string, terminalName: string, connectomeId: string) {
     const entry = this.guestBook.get(serverId);
     if (!entry) throw new Error(`Server ${serverId} not found`);
-    
+
     const terminal = entry.terminals[terminalName];
     if (!terminal) throw new Error(`Terminal ${terminalName} not found`);
-    
+
     terminal.inUse = true;
     terminal.connectedTo = terminal.connectedTo || [];
     terminal.connectedTo.push(connectomeId);
@@ -654,13 +646,13 @@ const wiringConfig = loadYAML('./wiring.yaml');
 
 // 5. Start application servers
 const ptyServer = new PTYServer();
-await ptyServer.start();  // Registers with Hostess
+await ptyServer.start(); // Registers with Hostess
 
 const gpuRenderer1 = new GPURenderer();
-await gpuRenderer1.start();  // Registers with Hostess
+await gpuRenderer1.start(); // Registers with Hostess
 
 const gpuRenderer2 = new GPURenderer();
-await gpuRenderer2.start();  // Registers with Hostess
+await gpuRenderer2.start(); // Registers with Hostess
 
 // 6. Execute wiring plan
 await stateManager.executeWiringPlan(wiringConfig);
@@ -672,38 +664,38 @@ await stateManager.executeWiringPlan(wiringConfig);
 
 ```yaml
 # wiring.yaml - Compile-time wiring specification
-version: "1.0"
+version: '1.0'
 
 connections:
   # PTY stdout → 2 GPU renderers (fanout)
   - source:
-      server: "*.pty-server.*"  # Glob pattern
-      terminal: "stdout"
+      server: '*.pty-server.*' # Glob pattern
+      terminal: 'stdout'
     targets:
-      - server: "*.gpu-renderer.*:1"  # First GPU renderer
-        terminal: "input"
-      - server: "*.gpu-renderer.*:2"  # Second GPU renderer
-        terminal: "input"
-  
+      - server: '*.gpu-renderer.*:1' # First GPU renderer
+        terminal: 'input'
+      - server: '*.gpu-renderer.*:2' # Second GPU renderer
+        terminal: 'input'
+
   # GPU outputs → MP4 encoder (fanin)
   - source:
       servers:
-        - "*.gpu-renderer.*:1"
-        - "*.gpu-renderer.*:2"
-      terminal: "output"
+        - '*.gpu-renderer.*:1'
+        - '*.gpu-renderer.*:2'
+      terminal: 'output'
     target:
-      server: "*.mp4-encoder.*"
-      terminal: "input"
-      mode: "merge"  # Combine multiple inputs
+      server: '*.mp4-encoder.*'
+      terminal: 'input'
+      mode: 'merge' # Combine multiple inputs
 
 validation:
   # Ensure these server types exist before wiring
   required_servers:
-    - class: "0x0001"  # PTY
+    - class: '0x0001' # PTY
       count: 1
-    - class: "0x0002"  # GPU renderer
+    - class: '0x0002' # GPU renderer
       count: 2
-    - class: "0x0005"  # MP4 encoder
+    - class: '0x0005' # MP4 encoder
       count: 1
 ```
 
@@ -716,15 +708,15 @@ class WiringValidator {
   async validate(config: WiringConfig, manifests: ServerManifest[]) {
     // Check all required servers are defined
     for (const req of config.validation.required_servers) {
-      const matching = manifests.filter(m => m.class === req.class);
+      const matching = manifests.filter((m) => m.class === req.class);
       if (matching.length < req.count) {
         throw new Error(
           `Wiring config requires ${req.count} servers of class ${req.class}, ` +
-          `but only ${matching.length} are defined`
+            `but only ${matching.length} are defined`,
         );
       }
     }
-    
+
     // Check all connections are valid
     for (const conn of config.connections) {
       // Validate source terminals exist
@@ -732,7 +724,7 @@ class WiringValidator {
       // Validate flow directions match
       // etc.
     }
-    
+
     return { valid: true };
   }
 }
@@ -747,14 +739,17 @@ The Hostess doesn't just track who's here - she also accepts "reservations" for
 Imagine the Hostess running a restaurant:
 
 **Local Walk-Ins (Local Reservations):**
+
 - Local StateManager: "Hey, I need a table for 4 GPU renderers"
 - Hostess: "Let me check... yes, I have 6 GPU servers available. Here are 4 for you."
 
 **Remote Phone Calls (Remote Reservations via LLDP):**
+
 - Remote Hostess B calls: "Hi! I've got a customer asking for shrimp scampi, but we specialize in Mexican food. I heard you have seafood capabilities?"
 - Hostess A: "Yes! We have a GPURenderer with H264 encoding. I can open a pipe between us so your customers can access it."
 
 **Inter-Restaurant Sharing:**
+
 - Hostesses advertise their "menu" (server capabilities) to other Hostesses
 - Remote systems discover what's available without manual configuration
 - Cross-machine capability sharing becomes automatic
@@ -767,39 +762,39 @@ The Hostess exposes a reservations interface that handles both local and remote
 interface ReservationsAPI {
   // Local reservation (walk-in)
   reserveLocal(request: ReservationRequest): Promise<Reservation>;
-  
+
   // Remote reservation (via LLDP/HTTP)
   reserveRemote(request: RemoteReservationRequest): Promise<Reservation>;
-  
+
   // Query available capabilities (for remote Hostesses)
   queryCapabilities(filter: CapabilityFilter): Promise<CapabilityAdvertisement>;
-  
+
   // Cancel reservation
   cancelReservation(reservationId: string): Promise<void>;
-  
+
   // List active reservations
   listReservations(): Promise<Reservation[]>;
 }
 
 interface ReservationRequest {
-  requestedBy: string;           // Who's making the reservation
-  serverFilter: ServerFilter;    // What kind of servers needed
-  count: number;                 // How many servers
-  duration?: number;             // How long (ms), undefined = indefinite
-  priority?: number;             // Priority level (higher = more important)
+  requestedBy: string; // Who's making the reservation
+  serverFilter: ServerFilter; // What kind of servers needed
+  count: number; // How many servers
+  duration?: number; // How long (ms), undefined = indefinite
+  priority?: number; // Priority level (higher = more important)
 }
 
 interface RemoteReservationRequest extends ReservationRequest {
-  remoteFqdn: string;            // Which remote system is requesting
+  remoteFqdn: string; // Which remote system is requesting
   connectionInfo: ConnectionInfo; // How to reach back to requester
 }
 
 interface Reservation {
-  id: string;                    // Unique reservation ID
-  servers: GuestBookEntry[];     // Reserved servers
+  id: string; // Unique reservation ID
+  servers: GuestBookEntry[]; // Reserved servers
   requestedBy: string;
-  expiresAt?: number;            // Timestamp when reservation expires
-  status: "active" | "expired" | "cancelled";
+  expiresAt?: number; // Timestamp when reservation expires
+  status: 'active' | 'expired' | 'cancelled';
 }
 ```
 
@@ -813,22 +808,22 @@ class StateManager {
   async executeWiringPlan(plan: WiringPlan) {
     // Make a reservation
     const reservation = await hostess.reserveLocal({
-      requestedBy: "StateManager",
+      requestedBy: 'StateManager',
       serverFilter: {
-        class: "0x0002",           // GPU renderer
-        capabilities: ["gpu", "h264"],
-        availableTerminals: 1
+        class: '0x0002', // GPU renderer
+        capabilities: ['gpu', 'h264'],
+        availableTerminals: 1,
       },
       count: 4,
-      duration: 60000,             // Hold for 60 seconds while wiring
-      priority: 10
+      duration: 60000, // Hold for 60 seconds while wiring
+      priority: 10,
     });
-    
+
     // Use the reserved servers
     for (const server of reservation.servers) {
-      await this.createConnection(plan.source, server.id, "input");
+      await this.createConnection(plan.source, server.id, 'input');
     }
-    
+
     // Reservation auto-released after duration or when cancelled
   }
 }
@@ -846,32 +841,32 @@ class HostessB {
     const response = await fetch('http://machine-a.local:8080/capabilities', {
       method: 'POST',
       body: JSON.stringify({
-        class: "0x0002",
-        capabilities: ["gpu", "h264"]
-      })
+        class: '0x0002',
+        capabilities: ['gpu', 'h264'],
+      }),
     });
-    
+
     const capabilities = await response.json();
-    
+
     if (capabilities.available > 0) {
       // Make remote reservation
       const reservation = await fetch('http://machine-a.local:8080/reserve', {
         method: 'POST',
         body: JSON.stringify({
-          requestedBy: "HostessB@machine-b.local",
-          remoteFqdn: "machine-b.local",
+          requestedBy: 'HostessB@machine-b.local',
+          remoteFqdn: 'machine-b.local',
           serverFilter: {
-            class: "0x0002",
-            capabilities: ["gpu", "h264"]
+            class: '0x0002',
+            capabilities: ['gpu', 'h264'],
           },
           count: 2,
           connectionInfo: {
-            preferredMethods: ["websocket", "tcp"],
-            endpoint: "ws://machine-b.local:9090"
-          }
-        })
+            preferredMethods: ['websocket', 'tcp'],
+            endpoint: 'ws://machine-b.local:9090',
+          },
+        }),
       });
-      
+
       // Now can connect local servers to remote GPU servers
     }
   }
@@ -887,10 +882,10 @@ class LLDPInterface {
   startCapabilitySharing(intervalMs: number = 60000) {
     setInterval(async () => {
       const servers = await this.hostess.listAll();
-      
+
       // Aggregate capabilities by class
       const capabilitiesByClass = this.aggregateByClass(servers);
-      
+
       // Broadcast capability advertisement
       const advertisement = {
         type: 'CAPABILITY_ADVERTISEMENT',
@@ -899,47 +894,49 @@ class LLDPInterface {
         hostessId: this.hostess.id,
         endpoint: `http://${os.hostname()}:${this.port}`,
         capabilities: capabilitiesByClass,
-        connectionMethods: this.cachedConnectionMethods  // From probing
+        connectionMethods: this.cachedConnectionMethods, // From probing
       };
-      
+
       // Send to known peers or multicast
       this.broadcast(advertisement);
     }, intervalMs);
   }
-  
+
   private aggregateByClass(servers: GuestBookEntry[]) {
-    const byClass = new Map<string, {
-      count: number;
-      availableCount: number;
-      capabilities: Set<string>;
-    }>();
-    
+    const byClass = new Map<
+      string,
+      {
+        count: number;
+        availableCount: number;
+        capabilities: Set<string>;
+      }
+    >();
+
     for (const server of servers) {
       if (!byClass.has(server.class)) {
         byClass.set(server.class, {
           count: 0,
           availableCount: 0,
-          capabilities: new Set()
+          capabilities: new Set(),
         });
       }
-      
+
       const entry = byClass.get(server.class)!;
       entry.count++;
-      
+
       // Check if server has available terminals
-      const hasAvailable = Object.values(server.terminals)
-        .some(t => !t.inUse);
+      const hasAvailable = Object.values(server.terminals).some((t) => !t.inUse);
       if (hasAvailable) entry.availableCount++;
-      
+
       // Aggregate capabilities
-      server.capabilities.forEach(c => entry.capabilities.add(c));
+      server.capabilities.forEach((c) => entry.capabilities.add(c));
     }
-    
+
     return Array.from(byClass.entries()).map(([cls, info]) => ({
       class: cls,
       totalCount: info.count,
       availableCount: info.availableCount,
-      capabilities: Array.from(info.capabilities)
+      capabilities: Array.from(info.capabilities),
     }));
   }
 }
@@ -952,6 +949,7 @@ class LLDPInterface {
 You **cannot probe yourself** to determine which connection methods work from the outside:
 
 **The Firewall Problem:**
+
 - Your machine might have firewall rules blocking certain ports/protocols
 - From inside your machine, you can't tell if external machines can reach you
 - Testing `localhost` or `127.0.0.1` tells you nothing about external connectivity
@@ -965,11 +963,13 @@ You need a **remote** system to probe **you**, while you run a **beacon** that r
 Three separate servers work together to test connectivity:
 
 **1. Executor Server (on target machine)**
+
 - Spawns the Probe Server locally in a new process
 - Provides instructions to the Probe
 - Manages Probe lifecycle
 
 **2. Beacon Server (on target machine)**
+
 - Listens on unprivileged port range (e.g., 10000-65535)
 - Skips ports already in use
 - Responds to Probe connection attempts with authentication
@@ -977,6 +977,7 @@ Three separate servers work together to test connectivity:
 - Terminates Probe when complete
 
 **3. Probe Server (spawned locally by Executor)**
+
 - Tests all IP addresses on the target machine
 - Scans across the port range
 - Authenticates with Beacon using hash + passphrase
@@ -990,19 +991,19 @@ The Probe and Beacon use hash-based authentication to prevent spoofing:
 
 ```typescript
 interface ProbeInstructions {
-  targetIpAddresses: string[];    // All IPs on this machine
-  portRangeStart: number;         // e.g., 10000
-  portRangeEnd: number;           // e.g., 65535
-  probeHash: string;              // Hash for probe to send
-  expectedResponseHash: string;   // What probe expects back
-  passphrase: string;             // Shared secret (known by probe only)
+  targetIpAddresses: string[]; // All IPs on this machine
+  portRangeStart: number; // e.g., 10000
+  portRangeEnd: number; // e.g., 65535
+  probeHash: string; // Hash for probe to send
+  expectedResponseHash: string; // What probe expects back
+  passphrase: string; // Shared secret (known by probe only)
 }
 
 interface BeaconConfig {
   portRangeStart: number;
   portRangeEnd: number;
-  beaconHash: string;             // Different from probe hash
-  passphrase: string;             // Same passphrase as probe
+  beaconHash: string; // Different from probe hash
+  passphrase: string; // Same passphrase as probe
 }
 
 // Authentication protocol
@@ -1010,15 +1011,16 @@ class Beacon {
   async handleProbeConnection(conn: Connection) {
     // 1. Receive hash from probe
     const probeHash = await conn.receive();
-    
+
     // 2. Hash it with our passphrase
-    const response = crypto.createHash('sha256')
+    const response = crypto
+      .createHash('sha256')
       .update(probeHash + this.passphrase)
       .digest('hex');
-    
+
     // 3. Send hashed response back
     await conn.send(response);
-    
+
     // Probe will verify this matches its expectedResponseHash
   }
 }
@@ -1027,13 +1029,13 @@ class Probe {
   async testConnection(ip: string, port: number) {
     try {
       const conn = await connect(ip, port);
-      
+
       // 1. Send our hash to beacon
       await conn.send(this.probeHash);
-      
+
       // 2. Receive hashed response
       const response = await conn.receive();
-      
+
       // 3. Verify it matches expected (proves beacon has passphrase)
       if (response === this.expectedResponseHash) {
         return { success: true, ip, port, latency: conn.latency };
@@ -1048,6 +1050,7 @@ class Probe {
 ```
 
 **Why different hashes?**
+
 - Beacon has `beaconHash` and `passphrase`
 - Probe has `probeHash` and `expectedResponseHash` (which equals `hash(probeHash + passphrase)`)
 - This proves both sides know the passphrase without transmitting it
@@ -1063,22 +1066,23 @@ class Executor {
     // Get all IP addresses on this machine
     const ipAddresses = this.getAllLocalIPs();
     // ['192.168.1.100', '10.0.0.5', '172.16.0.1', '127.0.0.1']
-    
+
     // Start beacon server
     const beacon = new Beacon({
       portRangeStart: 10000,
       portRangeEnd: 65535,
       beaconHash: generateHash(),
-      passphrase: generatePassphrase()
+      passphrase: generatePassphrase(),
     });
     await beacon.start();
-    
+
     // Calculate expected response
     const probeHash = generateHash();
-    const expectedResponseHash = crypto.createHash('sha256')
+    const expectedResponseHash = crypto
+      .createHash('sha256')
       .update(probeHash + beacon.passphrase)
       .digest('hex');
-    
+
     // Spawn probe in separate process
     const probe = spawn('node', ['probe-server.js'], {
       env: {
@@ -1087,21 +1091,21 @@ class Executor {
         PORT_RANGE_END: '65535',
         PROBE_HASH: probeHash,
         EXPECTED_RESPONSE_HASH: expectedResponseHash,
-        PASSPHRASE: beacon.passphrase
-      }
+        PASSPHRASE: beacon.passphrase,
+      },
     });
-    
+
     // Wait for probe to complete
     await beacon.waitForCompletion();
-    
+
     // Get results
     return beacon.getResults();
   }
-  
+
   private getAllLocalIPs(): string[] {
     const interfaces = os.networkInterfaces();
     const ips: string[] = [];
-    
+
     for (const [name, addrs] of Object.entries(interfaces)) {
       for (const addr of addrs || []) {
         if (addr.family === 'IPv4') {
@@ -1109,7 +1113,7 @@ class Executor {
         }
       }
     }
-    
+
     return ips;
   }
 }
@@ -1125,49 +1129,50 @@ class Probe {
     const ips = process.env.TARGET_IPS!.split(',');
     const portStart = parseInt(process.env.PORT_RANGE_START!);
     const portEnd = parseInt(process.env.PORT_RANGE_END!);
-    
+
     let firstWorkingConnection: Connection | null = null;
     const results: ConnectionTestResult[] = [];
-    
+
     // Test all IP/port combinations
     for (const ip of ips) {
       for (let port = portStart; port <= portEnd; port++) {
         const result = await this.testConnection(ip, port);
         results.push(result);
-        
+
         // Save first working connection for reporting
         if (result.success && !firstWorkingConnection) {
           firstWorkingConnection = result.connection;
         }
       }
     }
-    
+
     // Report all results to beacon on first working connection
     if (firstWorkingConnection) {
       await firstWorkingConnection.send({
         type: 'PROBE_RESULTS',
-        results: results.filter(r => r.success),
+        results: results.filter((r) => r.success),
         testedMatrix: {
           ips,
           portRange: [portStart, portEnd],
           totalTests: results.length,
-          successfulTests: results.filter(r => r.success).length
-        }
+          successfulTests: results.filter((r) => r.success).length,
+        },
       });
-      
+
       // Signal completion
       await firstWorkingConnection.send({
-        type: 'PROBE_COMPLETE'
+        type: 'PROBE_COMPLETE',
       });
-      
+
       // Wait for termination signal from beacon
       const terminationSignal = await firstWorkingConnection.receive();
-      
+
       // Verify termination is authenticated
-      const expectedTermination = crypto.createHash('sha256')
+      const expectedTermination = crypto
+        .createHash('sha256')
         .update('terminate' + process.env.PASSPHRASE!)
         .digest('hex');
-      
+
       if (terminationSignal.hash === expectedTermination) {
         console.log('Authenticated termination received. Exiting.');
         process.exit(0);
@@ -1182,7 +1187,7 @@ class Probe {
 class Beacon {
   private results: ConnectionTestResult[] = [];
   private completionPromise: Promise<void>;
-  
+
   async handleConnection(conn: Connection) {
     // Authenticate
     const authenticated = await this.authenticate(conn);
@@ -1190,40 +1195,41 @@ class Beacon {
       conn.close();
       return;
     }
-    
+
     // Listen for messages
     while (true) {
       const msg = await conn.receive();
-      
+
       if (msg.type === 'PROBE_RESULTS') {
         this.results = msg.results;
         console.log(`Received ${msg.results.length} working connections`);
         console.log(`Tested matrix: ${JSON.stringify(msg.testedMatrix)}`);
       }
-      
+
       if (msg.type === 'PROBE_COMPLETE') {
         console.log('Probe signaled completion');
-        
+
         // Send authenticated termination
-        const terminationHash = crypto.createHash('sha256')
+        const terminationHash = crypto
+          .createHash('sha256')
           .update('terminate' + this.passphrase)
           .digest('hex');
-        
+
         await conn.send({
           type: 'TERMINATE',
-          hash: terminationHash
+          hash: terminationHash,
         });
-        
+
         this.completionResolve();
         break;
       }
     }
   }
-  
+
   async waitForCompletion(): Promise<void> {
     return this.completionPromise;
   }
-  
+
   getResults(): ConnectionTestResult[] {
     return this.results;
   }
@@ -1239,14 +1245,14 @@ class Beacon {
 const executor = new Executor();
 const beacon = await executor.startBeacon({
   portRange: [10000, 65535],
-  passphrase: 'secret-xyz-123'
+  passphrase: 'secret-xyz-123',
 });
 
 // 2. Executor spawns Probe with instructions
 const probe = await executor.spawnProbe({
   targetIps: ['192.168.1.100', '10.0.0.5', '172.16.0.1'],
   portRange: [10000, 65535],
-  beaconPassphrase: 'secret-xyz-123'
+  beaconPassphrase: 'secret-xyz-123',
 });
 
 // 3. Probe tests all IP/port combinations
@@ -1278,6 +1284,7 @@ executor.cacheConnectionMethods(workingMethods);
 This architecture can be expanded to **remote probing**:
 
 **Current (Same-Machine):**
+
 ```
 Machine A:
   Executor → spawns Probe locally
@@ -1286,6 +1293,7 @@ Machine A:
 ```
 
 **Future (Cross-Machine):**
+
 ```
 Machine A (target):
   Executor → sends instructions to Machine B
@@ -1299,6 +1307,7 @@ Machine B (prober):
 ```
 
 **Expansion Strategy:**
+
 1. **Phase 1 (Current):** Same-machine testing to prove hash authentication and protocol
 2. **Phase 2:** Probe tests Beacon on different process on same machine (isolation)
 3. **Phase 3:** Probe on Machine B tests Beacon on Machine A (LAN)
@@ -1314,26 +1323,26 @@ Once a Probe Server tests connection methods, the Hostess caches and advertises
 interface ConnectionMethod {
   type: 'websocket' | 'tcp' | 'http' | 'unix-socket';
   endpoint: string;
-  latency: number;           // Measured latency in ms
-  throughput?: number;       // Measured throughput in bytes/sec
-  testedAt: number;          // Timestamp when tested
+  latency: number; // Measured latency in ms
+  throughput?: number; // Measured throughput in bytes/sec
+  testedAt: number; // Timestamp when tested
 }
 
 class Hostess {
   private connectionMethodCache: Map<string, ConnectionMethod[]> = new Map();
-  
+
   async cacheConnectionMethods(remoteFqdn: string, methods: ConnectionMethod[]) {
     this.connectionMethodCache.set(remoteFqdn, methods);
   }
-  
+
   async getConnectionMethods(remoteFqdn: string): Promise<ConnectionMethod[] | null> {
     const cached = this.connectionMethodCache.get(remoteFqdn);
-    
+
     // Return cached methods if they're recent (< 5 minutes old)
     if (cached && cached[0].testedAt > Date.now() - 300000) {
       return cached;
     }
-    
+
     // Otherwise, need to re-probe
     return null;
   }
@@ -1419,17 +1428,14 @@ class RemoteConnectionManager {
         continue;
       }
     }
-    
+
     // If all cached methods fail, trigger new probe
     console.log('All cached methods failed, triggering new probe...');
-    const probeResults = await this.probeServer.probeRemoteHostess(
-      advertisement.fqdn,
-      8080
-    );
-    
+    const probeResults = await this.probeServer.probeRemoteHostess(advertisement.fqdn, 8080);
+
     // Cache the new results
     await this.hostess.cacheConnectionMethods(advertisement.fqdn, probeResults);
-    
+
     // Try the new methods
     for (const method of probeResults) {
       try {
@@ -1438,7 +1444,7 @@ class RemoteConnectionManager {
         continue;
       }
     }
-    
+
     throw new Error('Unable to connect to remote Hostess');
   }
 }
@@ -1460,7 +1466,7 @@ class RemoteConnectionManager {
 Hostess A (Mexican Restaurant):
   "We have tacos, burritos, enchiladas (PTY, Audio servers)"
   "We DON'T have seafood (GPU rendering)"
-  
+
 Hostess B (Seafood Restaurant):
   "We have shrimp, lobster, fish (GPU, H264, CUDA)"
   "We DON'T have Mexican food"
@@ -1478,21 +1484,21 @@ When Local Customer at Restaurant A wants Shrimp:
 
 Connection Discovery (Executor/Probe/Beacon Pattern):
   Hostess A (first time connecting to B): "I need to find out how to reach Restaurant B"
-  
+
   Executor on Machine A: "Let me start a Beacon and spawn a Probe"
     → Beacon: Listens on ports 10000-65535 with hash authentication
     → Probe: Tests all IPs (192.168.1.100, 10.0.0.5, etc.) across port range
-  
+
   Probe discovers working connections:
     ✅ 192.168.1.100:10500 (TCP, 2ms latency) ← authenticated with beacon
     ✅ 10.0.0.5:10500 (TCP, 1ms latency) ← authenticated with beacon
     ❌ 172.16.0.1:* (blocked by firewall)
-  
+
   Probe → reports to Beacon on first working port (192.168.1.100:10500)
   Beacon → collects all results, terminates Probe with hashed "terminate" signal
-  
+
   Hostess A (caches results): "Machine B is reachable at 10.0.0.5:10500 (1ms, TCP)"
-  
+
   Next Visit: Skip probing entirely, use cached 10.0.0.5:10500 immediately!
 ```
 
diff --git a/docs/rfcs/stream-kernel/09-roadmap.md b/docs/rfcs/stream-kernel/09-roadmap.md
index d340f62..2a6a906 100644
--- a/docs/rfcs/stream-kernel/09-roadmap.md
+++ b/docs/rfcs/stream-kernel/09-roadmap.md
@@ -5,6 +5,7 @@
 **Goal:** ~100 line kernel that works in single process
 
 **Deliverables:**
+
 - [ ] Kernel implementation (createPipe, connect, split, merge, register, lookup)
 - [ ] StateManager/ControlPlane (topology tracking, wiring configs, introspection API)
 - [ ] Basic modules: KeyboardInput, LocalPTY, TerminalOutput
@@ -23,6 +24,7 @@
 **Goal:** Multi-modal output
 
 **Deliverables:**
+
 - [ ] XtermParser (ANSI → structured terminal state)
 - [ ] CanvasRenderer (HTML5 canvas output)
 - [ ] XtermJSRenderer (xterm.js integration)
@@ -38,6 +40,7 @@
 **Goal:** AI can observe and control terminals
 
 **Deliverables:**
+
 - [ ] AITextFormatter (terminal → LLM-friendly text)
 - [ ] Screenshotter (periodic screenshots)
 - [ ] WhisperSTT (speech-to-text input)
@@ -53,6 +56,7 @@
 **Goal:** Same code runs multi-process with crash isolation
 
 **Deliverables:**
+
 - [ ] Transport abstraction (`createPipe(type)`)
 - [ ] UnixSocketPipe implementation
 - [ ] Process spawning / supervision
@@ -68,6 +72,7 @@
 **Goal:** Multi-machine deployment with automatic routing
 
 **Deliverables:**
+
 - [ ] RoutingServer module
 - [ ] Terminal management (local, network, loopback)
 - [ ] Service discovery (broadcast announcements)
@@ -85,6 +90,7 @@
 **Goal:** Complete module ecosystem
 
 **Deliverables:**
+
 - [ ] DockerPTY (containerized terminals)
 - [ ] MP4Recorder (video recording)
 - [ ] TextToSpeech (audio output)
@@ -101,6 +107,7 @@
 **Goal:** Terminal runs in browser with extension support
 
 **Deliverables:**
+
 - [ ] Browser-compatible kernel (stream polyfill)
 - [ ] Chrome extension scaffolding
 - [ ] DevTools panel integration
@@ -117,6 +124,7 @@
 **Goal:** Stream kernel powers AI agent communication
 
 **Deliverables:**
+
 - [ ] MCPRouter module (Layer 3)
 - [ ] JSON-RPC transport module
 - [ ] HTTP/SSE transport module
@@ -137,14 +145,17 @@
 Some phases can be parallelized with multiple developers/agents:
 
 **Week 4-6:**
+
 - Developer A: Multi-process deployment
 - Developer B: Advanced modules (Docker, MP4, TTS)
 
 **Week 7-9:**
+
 - Developer A: Distributed service mesh
 - Developer B: Browser integration
 
 **Week 10:**
+
 - Developer A: MCP/Protocol layer
 - Developer B: Documentation, examples, tutorials
 
@@ -155,20 +166,20 @@ Some phases can be parallelized with multiple developers/agents:
 **Milestone 3 (End of Phase 3):** AI integration works  
 **Milestone 4 (End of Phase 4):** Multi-process deployment works  
 **Milestone 5 (End of Phase 5):** Distributed deployment works  
-**Milestone 6 (End of Phase 8):** Production-ready system  
+**Milestone 6 (End of Phase 8):** Production-ready system
 
 ## Success Metrics
 
-| Metric | Target |
-|--------|--------|
-| Kernel lines of code | < 150 |
-| StateManager lines of code | < 500 |
-| Kernel test coverage | > 90% |
-| StateManager test coverage | > 85% |
-| Module test coverage | > 80% |
-| Integration tests | > 20 scenarios |
-| Example applications | > 5 |
-| Documentation | Complete for all modules |
+| Metric                     | Target                   |
+| -------------------------- | ------------------------ |
+| Kernel lines of code       | < 150                    |
+| StateManager lines of code | < 500                    |
+| Kernel test coverage       | > 90%                    |
+| StateManager test coverage | > 85%                    |
+| Module test coverage       | > 80%                    |
+| Integration tests          | > 20 scenarios           |
+| Example applications       | > 5                      |
+| Documentation              | Complete for all modules |
 
 ## Risk Mitigation
 
diff --git a/docs/rfcs/stream-kernel/10-executor-server.md b/docs/rfcs/stream-kernel/10-executor-server.md
index c78ebaf..65f8af6 100644
--- a/docs/rfcs/stream-kernel/10-executor-server.md
+++ b/docs/rfcs/stream-kernel/10-executor-server.md
@@ -17,6 +17,7 @@ The Executor has three primary responsibilities:
 ### 1. Service Startup (Phase 1)
 
 When the kernel starts, the Executor:
+
 1. Reads service configuration (initially hardcoded, later from config file)
 2. Instantiates service instances
 3. Registers services with the Hostess
@@ -25,6 +26,7 @@ When the kernel starts, the Executor:
 ### 2. Probe Spawning (Phase 2)
 
 For connection testing, the Executor:
+
 1. Spawns probe servers in separate processes on request
 2. Passes connection testing instructions to probes
 3. Coordinates probe/beacon authentication
@@ -33,6 +35,7 @@ For connection testing, the Executor:
 ### 3. External Process Management (Phase 3)
 
 Future capability to:
+
 1. Spawn arbitrary external processes
 2. Monitor process health
 3. Restart failed processes
@@ -53,6 +56,7 @@ STREAM KERNEL (Pure plumbing)
 ```
 
 **Why this matters:**
+
 - Can be replaced with different implementations
 - Can run on a separate machine
 - Can be tested in isolation
@@ -62,20 +66,21 @@ STREAM KERNEL (Pure plumbing)
 
 The Executor is distinct from other infrastructure servers:
 
-| Server | Responsibility |
-|--------|---------------|
-| **Kernel** | Pipes, connections, basic registry |
-| **Executor** | Service startup, probe spawning, process management |
-| **Hostess** | Server registry, capability tracking, availability |
+| Server           | Responsibility                                           |
+| ---------------- | -------------------------------------------------------- |
+| **Kernel**       | Pipes, connections, basic registry                       |
+| **Executor**     | Service startup, probe spawning, process management      |
+| **Hostess**      | Server registry, capability tracking, availability       |
 | **StateManager** | Topology tracking, wiring configs, connection management |
-| **Probe** | Connection method testing |
-| **Beacon** | Connection endpoint listening, authentication |
+| **Probe**        | Connection method testing                                |
+| **Beacon**       | Connection endpoint listening, authentication            |
 
 ## Phase 1: Service Startup
 
 ### Minimal Implementation
 
 The initial Executor is ~50-100 lines that:
+
 1. Instantiates services from hardcoded list
 2. Calls `hostess.register()` for each service
 3. Waits for all services to be ready
@@ -86,16 +91,16 @@ The initial Executor is ~50-100 lines that:
 class Executor {
   constructor(
     private kernel: Kernel,
-    private hostess: HostessServer
+    private hostess: HostessServer,
   ) {}
 
   async start() {
     const services = this.getServiceList();
-    
+
     for (const serviceDef of services) {
       const service = this.instantiate(serviceDef);
       await service.initialize();
-      
+
       await this.hostess.register({
         name: serviceDef.name,
         fqdn: serviceDef.fqdn,
@@ -104,13 +109,13 @@ class Executor {
         auth: serviceDef.auth,
         mechanism: serviceDef.authMechanism,
         uuid: serviceDef.uuid,
-        terminals: service.getTerminals()
+        terminals: service.getTerminals(),
       });
     }
-    
+
     console.log(`Executor: Started ${services.length} services`);
   }
-  
+
   private getServiceList(): ServiceDefinition[] {
     return [
       {
@@ -121,7 +126,7 @@ class Executor {
         auth: 'no',
         authMechanism: 'none',
         uuid: crypto.randomUUID(),
-        factory: () => new PTYServer(this.kernel)
+        factory: () => new PTYServer(this.kernel),
       },
       {
         name: 'renderer-server',
@@ -131,11 +136,11 @@ class Executor {
         auth: 'no',
         authMechanism: 'none',
         uuid: crypto.randomUUID(),
-        factory: () => new RendererServer(this.kernel)
-      }
+        factory: () => new RendererServer(this.kernel),
+      },
     ];
   }
-  
+
   private instantiate(def: ServiceDefinition): Server {
     return def.factory();
   }
@@ -152,6 +157,7 @@ await executor.start();
 ```
 
 **Advantages:**
+
 - Simple to implement
 - Easy to test
 - No config file parsing
@@ -185,18 +191,18 @@ class Executor {
         PORT_END: request.portRange.end.toString(),
         PROBE_HASH: request.probeHash,
         PASSPHRASE: request.passphrase,
-        EXPECTED_BEACON_HASH: request.beaconHash
-      }
+        EXPECTED_BEACON_HASH: request.beaconHash,
+      },
     });
-    
+
     return await probe.waitForResults();
   }
-  
+
   private spawnProcess(config: ProcessConfig): Process {
     const child = spawn(config.command, config.args, {
-      env: { ...process.env, ...config.env }
+      env: { ...process.env, ...config.env },
     });
-    
+
     return new Process(child);
   }
 }
@@ -233,14 +239,14 @@ class Executor {
       command: config.command,
       args: config.args,
       env: config.env,
-      cwd: config.cwd
+      cwd: config.cwd,
     });
-    
+
     this.monitorProcess(process);
-    
+
     return new ManagedProcess(process, config);
   }
-  
+
   private monitorProcess(process: Process) {
     process.on('exit', (code) => {
       if (config.restart && code !== 0) {
@@ -255,26 +261,29 @@ class Executor {
 ### Use Cases
 
 **Docker containers:** Spawn containerized services
+
 ```typescript
 await executor.spawnExternal({
   command: 'docker',
-  args: ['run', '-p', '8080:8080', 'my-service']
+  args: ['run', '-p', '8080:8080', 'my-service'],
 });
 ```
 
 **GPU servers:** Start remote GPU processing
+
 ```typescript
 await executor.spawnExternal({
   command: 'python',
-  args: ['gpu_server.py']
+  args: ['gpu_server.py'],
 });
 ```
 
 **PTY applications:** Launch terminal applications
+
 ```typescript
 await executor.spawnExternal({
   command: 'bash',
-  env: { TERM: 'xterm-256color' }
+  env: { TERM: 'xterm-256color' },
 });
 ```
 
@@ -341,7 +350,7 @@ Services are specified in code:
 ```typescript
 const services = [
   { name: 'pty-server', class: '0x0001', factory: () => new PTYServer(kernel) },
-  { name: 'renderer', class: '0x0002', factory: () => new RendererServer(kernel) }
+  { name: 'renderer', class: '0x0002', factory: () => new RendererServer(kernel) },
 ];
 ```
 
@@ -360,7 +369,7 @@ services:
     auth_mechanism: none
     command: node
     args: [pty-server.js]
-    
+
   - name: renderer-server
     fqdn: localhost
     class: 0x0002
@@ -380,7 +389,7 @@ await executor.addService({
   name: 'gpu-server',
   class: '0x0003',
   command: 'python',
-  args: ['gpu_server.py']
+  args: ['gpu_server.py'],
 });
 ```
 
@@ -393,11 +402,11 @@ class Executor {
   validateWiringConfig(config: WiringConfig): ValidationResult {
     const availableServices = this.getServiceList();
     const errors: string[] = [];
-    
+
     for (const connection of config.connections) {
-      const sourceExists = availableServices.some(s => s.name === connection.source);
-      const targetExists = availableServices.some(s => s.name === connection.target);
-      
+      const sourceExists = availableServices.some((s) => s.name === connection.source);
+      const targetExists = availableServices.some((s) => s.name === connection.target);
+
       if (!sourceExists) {
         errors.push(`Source service not found: ${connection.source}`);
       }
@@ -405,7 +414,7 @@ class Executor {
         errors.push(`Target service not found: ${connection.target}`);
       }
     }
-    
+
     return { valid: errors.length === 0, errors };
   }
 }
@@ -425,13 +434,13 @@ describe('Executor', () => {
     const kernel = new MockKernel();
     const hostess = new MockHostess();
     const executor = new Executor(kernel, hostess);
-    
+
     await executor.start();
-    
+
     expect(hostess.registeredServices).toHaveLength(2);
     expect(hostess.registeredServices[0].name).toBe('pty-server');
   });
-  
+
   it('should spawn probe with correct configuration', async () => {
     const executor = new Executor(kernel, hostess);
     const request: ProbeRequest = {
@@ -439,19 +448,19 @@ describe('Executor', () => {
       portRange: { start: 10000, end: 10100 },
       beaconHash: 'abc123',
       probeHash: 'def456',
-      passphrase: 'secret'
+      passphrase: 'secret',
     };
-    
+
     const mockSpawn = jest.spyOn(executor as any, 'spawnProcess');
     await executor.spawnProbe(request);
-    
+
     expect(mockSpawn).toHaveBeenCalledWith(
       expect.objectContaining({
         env: expect.objectContaining({
           PROBE_HASH: 'def456',
-          PASSPHRASE: 'secret'
-        })
-      })
+          PASSPHRASE: 'secret',
+        }),
+      }),
     );
   });
 });
@@ -466,13 +475,11 @@ it('should register services with hostess on startup', async () => {
   const kernel = new Kernel();
   const hostess = new HostessServer(kernel);
   const executor = new Executor(kernel, hostess);
-  
+
   await executor.start();
-  
+
   const services = await hostess.listServices();
-  expect(services).toContainEqual(
-    expect.objectContaining({ name: 'pty-server' })
-  );
+  expect(services).toContainEqual(expect.objectContaining({ name: 'pty-server' }));
 });
 ```
 
@@ -483,12 +490,14 @@ it('should register services with hostess on startup', async () => {
 **Scenario:** User ships two systems, wants them to discover each other
 
 **Machine A:**
+
 ```typescript
 const executor = new Executor(kernel, hostess);
 await executor.start();
 ```
 
 **Machine B:**
+
 ```typescript
 const executor = new Executor(kernel, hostess);
 await executor.start();
@@ -501,6 +510,7 @@ Both Executors start their local services. Hostesses communicate via LLDP. Conne
 **Scenario:** User needs compile-time wiring specification
 
 **wiring-config.yaml:**
+
 ```yaml
 connections:
   - source: pty-server.output
@@ -510,6 +520,7 @@ connections:
 ```
 
 **Startup:**
+
 ```typescript
 const executor = new Executor(kernel, hostess);
 await executor.start();
@@ -542,6 +553,7 @@ await stateManager.applyWiring(wiringConfig);
 ### Why Not in Kernel?
 
 Service startup is **policy**, not **mechanism**:
+
 - Different systems need different services
 - Service configuration changes, kernel doesn't
 - Testing: Can test kernel without any services
@@ -560,6 +572,7 @@ Service startup is **policy**, not **mechanism**:
 ### Why Not Supervisor Pattern?
 
 The Executor **starts** services, but doesn't **supervise** them:
+
 - Supervision = monitoring, restarting on failure
 - That's a different concern (SupervisorServer)
 - Executor does one thing: lifecycle management
@@ -567,6 +580,7 @@ The Executor **starts** services, but doesn't **supervise** them:
 ## Implementation Checklist
 
 **Phase 1: Minimal Service Startup**
+
 - [ ] Executor class with hardcoded service list
 - [ ] Service instantiation
 - [ ] Hostess registration
@@ -574,6 +588,7 @@ The Executor **starts** services, but doesn't **supervise** them:
 - [ ] Integration test with Hostess
 
 **Phase 2: Probe Spawning**
+
 - [ ] ProbeRequest interface
 - [ ] Process spawning utility
 - [ ] Probe lifecycle management
@@ -582,6 +597,7 @@ The Executor **starts** services, but doesn't **supervise** them:
 - [ ] Integration test: Executor → Probe → Beacon
 
 **Phase 3: Config File Loading**
+
 - [ ] YAML config parser
 - [ ] Service definition validation
 - [ ] Config-driven service instantiation
@@ -589,6 +605,7 @@ The Executor **starts** services, but doesn't **supervise** them:
 - [ ] Unit tests for config loading
 
 **Phase 4: External Process Management**
+
 - [ ] External process spawning
 - [ ] Process health monitoring
 - [ ] Restart on failure
@@ -606,12 +623,14 @@ The Executor is a minimal server (~50-100 lines initially) that:
 5. ✅ **Manages process lifecycle** (future)
 
 **Key principles:**
+
 - Not kernel code - just another server
 - Follows microkernel philosophy
 - Testable in isolation
 - Swappable implementation
 
 **Integration:**
+
 - Works with Hostess for service registry
 - Works with StateManager for topology wiring
 - Spawns Probe for connection testing
diff --git a/docs/rfcs/stream-kernel/11-external-wrapper.md b/docs/rfcs/stream-kernel/11-external-wrapper.md
index 0a82162..1b3ab4d 100644
--- a/docs/rfcs/stream-kernel/11-external-wrapper.md
+++ b/docs/rfcs/stream-kernel/11-external-wrapper.md
@@ -32,55 +32,55 @@ This RFC defines the architecture for wrapping external executables (npm package
 ```typescript
 interface ExternalServerWrapper {
   // Module interface (standard for all servers)
-  inputPipe: Pipe;     // Commands/data to external process
-  outputPipe: Pipe;    // Output from external process
-  
+  inputPipe: Pipe; // Commands/data to external process
+  outputPipe: Pipe; // Output from external process
+
   // Lifecycle management
   spawn(): Promise<void>;
   shutdown(): Promise<void>;
   restart(): Promise<void>;
-  
+
   // Status
   isRunning(): boolean;
   getProcessInfo(): ProcessInfo;
-  
+
   // Configuration
   manifest: ServerManifest;
 }
 
 interface ServerManifest {
   // Identity (for Hostess registration)
-  name: string;              // e.g., "sql-server"
-  fqdn: string;              // e.g., "localhost"
-  class: string;             // e.g., "0xFFFF" (external wrapper class)
-  owner: string;             // e.g., "system" or "user"
-  uuid: string;              // Unique identifier
-  
+  name: string; // e.g., "sql-server"
+  fqdn: string; // e.g., "localhost"
+  class: string; // e.g., "0xFFFF" (external wrapper class)
+  owner: string; // e.g., "system" or "user"
+  uuid: string; // Unique identifier
+
   // External process configuration
-  command: string;           // Executable path or name
-  args: string[];            // Command-line arguments
-  env: Record<string, string>;  // Environment variables
-  cwd: string;               // Working directory
-  
+  command: string; // Executable path or name
+  args: string[]; // Command-line arguments
+  env: Record<string, string>; // Environment variables
+  cwd: string; // Working directory
+
   // I/O configuration
   ioMode: 'stdio' | 'pty' | 'socket' | 'file';
-  
+
   // Terminals (for Hostess registration)
   terminals: TerminalDefinition[];
-  
+
   // Capabilities
   capabilities: ServiceCapabilities;
-  
+
   // Lifecycle policies
   restart: 'always' | 'on-failure' | 'never';
-  restartDelay: number;      // ms between restarts
-  maxRestarts: number;       // Max restart attempts
+  restartDelay: number; // ms between restarts
+  maxRestarts: number; // Max restart attempts
 }
 
 interface TerminalDefinition {
-  name: string;              // e.g., "input", "output", "error"
+  name: string; // e.g., "input", "output", "error"
   direction: 'input' | 'output' | 'bidirectional';
-  protocol: string;          // e.g., "raw-bytes", "json-rpc", "sql"
+  protocol: string; // e.g., "raw-bytes", "json-rpc", "sql"
 }
 
 interface ProcessInfo {
@@ -102,20 +102,20 @@ For non-interactive programs:
 ```typescript
 class StdioWrapper implements ExternalServerWrapper {
   private process: ChildProcess;
-  
+
   async spawn(): Promise<void> {
     this.process = spawn(this.manifest.command, this.manifest.args, {
       stdio: ['pipe', 'pipe', 'pipe'],
       env: this.manifest.env,
-      cwd: this.manifest.cwd
+      cwd: this.manifest.cwd,
     });
-    
+
     // Connect stdout to outputPipe
     this.process.stdout.pipe(this.outputPipe);
-    
+
     // Connect inputPipe to stdin
     this.inputPipe.pipe(this.process.stdin);
-    
+
     // Optional: stderr handling
     this.process.stderr.on('data', (data) => {
       this.errorPipe?.write(data);
@@ -125,6 +125,7 @@ class StdioWrapper implements ExternalServerWrapper {
 ```
 
 **Use cases:**
+
 - CLI tools that read stdin, write stdout
 - Data processors (filters, formatters)
 - Batch processing scripts
@@ -140,8 +141,8 @@ const sqlWrapper = new StdioWrapper({
   ioMode: 'stdio',
   terminals: [
     { name: 'input', direction: 'input', protocol: 'sql' },
-    { name: 'output', direction: 'output', protocol: 'json' }
-  ]
+    { name: 'output', direction: 'output', protocol: 'json' },
+  ],
 });
 ```
 
@@ -152,25 +153,25 @@ For TUI applications (see [RFC 12](12-pty-wrapper-patterns.md) for details):
 ```typescript
 class PTYWrapper implements ExternalServerWrapper {
   private ptyProcess: IPty;
-  
+
   async spawn(): Promise<void> {
     this.ptyProcess = pty.spawn(this.manifest.command, this.manifest.args, {
       name: 'xterm-256color',
       cols: 80,
       rows: 24,
       env: this.manifest.env,
-      cwd: this.manifest.cwd
+      cwd: this.manifest.cwd,
     });
-    
+
     this.ptyProcess.onData((data) => {
       this.outputPipe.write(Buffer.from(data));
     });
-    
+
     this.inputPipe.on('data', (data) => {
       this.ptyProcess.write(data.toString());
     });
   }
-  
+
   resize(cols: number, rows: number): void {
     this.ptyProcess.resize(cols, rows);
   }
@@ -178,6 +179,7 @@ class PTYWrapper implements ExternalServerWrapper {
 ```
 
 **Use cases:**
+
 - TUI applications (vim, htop, Claude Code)
 - Interactive shells (bash, zsh)
 - Terminal-based UIs
@@ -190,20 +192,20 @@ For network services:
 class SocketWrapper implements ExternalServerWrapper {
   private process: ChildProcess;
   private socket: Socket;
-  
+
   async spawn(): Promise<void> {
     // Start the external process
     this.process = spawn(this.manifest.command, this.manifest.args, {
       env: this.manifest.env,
-      cwd: this.manifest.cwd
+      cwd: this.manifest.cwd,
     });
-    
+
     // Wait for socket to be ready
     await this.waitForSocket(this.manifest.socketPath);
-    
+
     // Connect to socket
     this.socket = connect(this.manifest.socketPath);
-    
+
     // Bridge socket ↔ pipes
     this.socket.pipe(this.outputPipe);
     this.inputPipe.pipe(this.socket);
@@ -212,6 +214,7 @@ class SocketWrapper implements ExternalServerWrapper {
 ```
 
 **Use cases:**
+
 - Database servers (PostgreSQL, Redis)
 - Message queues (RabbitMQ)
 - Web servers
@@ -228,15 +231,15 @@ const standardEnv = {
   MKOLBOL_SERVER_NAME: manifest.name,
   MKOLBOL_SERVER_UUID: manifest.uuid,
   MKOLBOL_SERVER_CLASS: manifest.class,
-  
+
   // Hostess information
   MKOLBOL_HOSTESS_URL: hostessUrl,
-  
+
   // Terminal definitions (JSON)
   MKOLBOL_TERMINALS: JSON.stringify(manifest.terminals),
-  
+
   // User-provided environment
-  ...manifest.env
+  ...manifest.env,
 };
 ```
 
@@ -252,7 +255,7 @@ const wrapper = new StdioWrapper({
     DATABASE_URL: 'sqlite:///data/db.sqlite',
     LOG_LEVEL: 'info',
     // Standard vars added automatically
-  }
+  },
 });
 ```
 
@@ -267,16 +270,20 @@ const wrapper = new StdioWrapper({
   name: 'transcoder',
   command: 'ffmpeg',
   args: [
-    '-i', '${INPUT_FILE}',        // Template replaced at spawn
-    '-c:v', 'libx264',
-    '-preset', 'fast',
-    '-f', 'mp4',
-    '${OUTPUT_FILE}'
+    '-i',
+    '${INPUT_FILE}', // Template replaced at spawn
+    '-c:v',
+    'libx264',
+    '-preset',
+    'fast',
+    '-f',
+    'mp4',
+    '${OUTPUT_FILE}',
   ],
   env: {
     INPUT_FILE: '/tmp/input.mov',
-    OUTPUT_FILE: '/tmp/output.mp4'
-  }
+    OUTPUT_FILE: '/tmp/output.mp4',
+  },
 });
 ```
 
@@ -286,13 +293,15 @@ Pass arguments from inputPipe:
 
 ```typescript
 // Send command via pipe
-wrapper.inputPipe.write(JSON.stringify({
-  command: 'transcode',
-  args: {
-    INPUT_FILE: '/videos/source.mov',
-    OUTPUT_FILE: '/videos/output.mp4'
-  }
-}));
+wrapper.inputPipe.write(
+  JSON.stringify({
+    command: 'transcode',
+    args: {
+      INPUT_FILE: '/videos/source.mov',
+      OUTPUT_FILE: '/videos/output.mp4',
+    },
+  }),
+);
 
 // Wrapper spawns new process with injected args
 ```
@@ -312,23 +321,23 @@ export const SERVER_MANIFEST: ServerManifest = {
   owner: 'system',
   uuid: '550e8400-e29b-41d4-a716-446655440000',
   command: 'ffmpeg',
-  args: ['-version'],  // Default args
+  args: ['-version'], // Default args
   env: {},
   cwd: '/opt/video-processor',
   ioMode: 'stdio',
   terminals: [
     { name: 'input', direction: 'input', protocol: 'video-commands' },
-    { name: 'output', direction: 'output', protocol: 'video-stream' }
+    { name: 'output', direction: 'output', protocol: 'video-stream' },
   ],
   capabilities: {
     type: 'transform',
     accepts: ['video/mp4', 'video/mov'],
     produces: ['video/mp4'],
-    features: ['transcode', 'resize', 'compress']
+    features: ['transcode', 'resize', 'compress'],
   },
   restart: 'on-failure',
   restartDelay: 5000,
-  maxRestarts: 3
+  maxRestarts: 3,
 };
 ```
 
@@ -347,7 +356,7 @@ args:
   - node_modules/.bin/sql-server
 env:
   DATABASE_PATH: /data/db.sqlite
-  MAX_CONNECTIONS: "100"
+  MAX_CONNECTIONS: '100'
 ioMode: stdio
 terminals:
   - name: input
@@ -394,27 +403,27 @@ class ExternalServerWrapper {
       class: this.manifest.class,
       owner: this.manifest.owner,
       uuid: this.manifest.uuid,
-      terminals: this.manifest.terminals.map(t => ({
+      terminals: this.manifest.terminals.map((t) => ({
         name: t.name,
         direction: t.direction,
         protocol: t.protocol,
         inUse: false,
-        connectomeId: null
+        connectomeId: null,
       })),
       capabilities: this.manifest.capabilities,
       metadata: {
         pid: this.getProcessInfo().pid,
         uptime: this.getProcessInfo().uptime,
-        wrapperType: this.manifest.ioMode
-      }
+        wrapperType: this.manifest.ioMode,
+      },
     };
-    
+
     await hostess.register(entry);
-    
+
     // Start heartbeat
     this.startHeartbeat();
   }
-  
+
   private startHeartbeat(): void {
     setInterval(() => {
       hostess.heartbeat(this.manifest.uuid);
@@ -440,20 +449,20 @@ For external servers that don't speak mkolbol protocols:
 
 ```typescript
 class TranslationLayer {
-  inputPipe: Pipe;    // Receives mkolbol protocol
-  outputPipe: Pipe;   // Sends mkolbol protocol
-  
+  inputPipe: Pipe; // Receives mkolbol protocol
+  outputPipe: Pipe; // Sends mkolbol protocol
+
   private externalWrapper: ExternalServerWrapper;
-  
+
   constructor(wrapper: ExternalServerWrapper, translator: Translator) {
     this.externalWrapper = wrapper;
-    
+
     // Translate mkolbol → external protocol
     this.inputPipe.on('data', (mkolbolData) => {
       const externalData = translator.toExternal(mkolbolData);
       wrapper.inputPipe.write(externalData);
     });
-    
+
     // Translate external → mkolbol protocol
     wrapper.outputPipe.on('data', (externalData) => {
       const mkolbolData = translator.fromExternal(externalData);
@@ -471,7 +480,7 @@ const sqlWrapper = new StdioWrapper({
   name: 'sql-server',
   command: 'sql-server-binary',
   args: [],
-  ioMode: 'stdio'
+  ioMode: 'stdio',
 });
 
 // Translation layer converts JSON → binary
@@ -510,23 +519,23 @@ const sqlServer = new StdioWrapper({
   args: ['node_modules/.bin/sqlite-server', '--db', 'data.db'],
   env: {
     MAX_CONNECTIONS: '10',
-    LOG_LEVEL: 'info'
+    LOG_LEVEL: 'info',
   },
   cwd: '/opt/db',
   ioMode: 'stdio',
   terminals: [
     { name: 'query', direction: 'input', protocol: 'sql' },
-    { name: 'results', direction: 'output', protocol: 'json' }
+    { name: 'results', direction: 'output', protocol: 'json' },
   ],
   capabilities: {
     type: 'source',
     accepts: ['sql-query'],
     produces: ['json-result'],
-    features: ['transactions', 'prepared-statements']
+    features: ['transactions', 'prepared-statements'],
   },
   restart: 'on-failure',
   restartDelay: 5000,
-  maxRestarts: 3
+  maxRestarts: 3,
 });
 
 // Spawn and register
@@ -548,29 +557,31 @@ const imageProcessor = new StdioWrapper({
   class: '0xFFFF',
   owner: 'user',
   uuid: uuidv4(),
-  command: '/usr/bin/convert',  // ImageMagick
+  command: '/usr/bin/convert', // ImageMagick
   args: [
-    '-',              // Read from stdin
-    '-resize', '800x600',
-    '-quality', '85',
-    'png:-'          // Write to stdout
+    '-', // Read from stdin
+    '-resize',
+    '800x600',
+    '-quality',
+    '85',
+    'png:-', // Write to stdout
   ],
   env: {},
   cwd: '/tmp',
   ioMode: 'stdio',
   terminals: [
     { name: 'input', direction: 'input', protocol: 'image-binary' },
-    { name: 'output', direction: 'output', protocol: 'image-binary' }
+    { name: 'output', direction: 'output', protocol: 'image-binary' },
   ],
   capabilities: {
     type: 'transform',
     accepts: ['image/jpeg', 'image/png', 'image/gif'],
     produces: ['image/png'],
-    features: ['resize', 'convert', 'compress']
+    features: ['resize', 'convert', 'compress'],
   },
   restart: 'never',
   restartDelay: 0,
-  maxRestarts: 0
+  maxRestarts: 0,
 });
 
 // Use in pipeline
@@ -588,7 +599,7 @@ const restAPI = new SocketWrapper({
   args: ['api-server.js'],
   env: { PORT: '3000' },
   ioMode: 'socket',
-  socketPath: 'http://localhost:3000'
+  socketPath: 'http://localhost:3000',
 });
 
 // Translate HTTP ↔ Streams
@@ -612,50 +623,50 @@ describe('StdioWrapper', () => {
       name: 'test',
       command: 'cat',
       args: [],
-      ioMode: 'stdio'
+      ioMode: 'stdio',
     });
-    
+
     await wrapper.spawn();
-    
+
     expect(wrapper.isRunning()).toBe(true);
     expect(wrapper.getProcessInfo().pid).toBeGreaterThan(0);
   });
-  
+
   it('should pipe data through external process', async () => {
     const wrapper = new StdioWrapper({
       name: 'test',
-      command: 'cat',  // Echo stdin to stdout
+      command: 'cat', // Echo stdin to stdout
       args: [],
-      ioMode: 'stdio'
+      ioMode: 'stdio',
     });
-    
+
     await wrapper.spawn();
-    
+
     const output: Buffer[] = [];
     wrapper.outputPipe.on('data', (data) => output.push(data));
-    
+
     wrapper.inputPipe.write('Hello, World!');
-    
-    await new Promise(resolve => setTimeout(resolve, 100));
-    
+
+    await new Promise((resolve) => setTimeout(resolve, 100));
+
     expect(Buffer.concat(output).toString()).toBe('Hello, World!');
   });
-  
+
   it('should restart on failure when configured', async () => {
     const wrapper = new StdioWrapper({
       name: 'test',
       command: 'bash',
-      args: ['-c', 'exit 1'],  // Exits immediately
+      args: ['-c', 'exit 1'], // Exits immediately
       ioMode: 'stdio',
       restart: 'on-failure',
       restartDelay: 100,
-      maxRestarts: 3
+      maxRestarts: 3,
     });
-    
+
     await wrapper.spawn();
-    
-    await new Promise(resolve => setTimeout(resolve, 500));
-    
+
+    await new Promise((resolve) => setTimeout(resolve, 500));
+
     expect(wrapper.getProcessInfo().restartCount).toBeGreaterThan(0);
   });
 });
@@ -668,15 +679,15 @@ Test with Hostess and Executor:
 ```typescript
 it('should register with Hostess on spawn', async () => {
   const executor = new Executor(kernel, hostess);
-  
+
   const wrapper = new StdioWrapper({
     name: 'test-server',
     command: 'cat',
-    ioMode: 'stdio'
+    ioMode: 'stdio',
   });
-  
+
   await executor.spawnWrapper(wrapper);
-  
+
   const servers = await hostess.query({ name: 'test-server' });
   expect(servers).toHaveLength(1);
   expect(servers[0].name).toBe('test-server');
@@ -694,20 +705,20 @@ class Executor {
   async spawnWrapper(wrapper: ExternalServerWrapper): Promise<void> {
     // Spawn external process
     await wrapper.spawn();
-    
+
     // Register with Hostess
     await this.hostess.register({
       id: wrapper.manifest.uuid,
       servername: wrapper.manifest.name,
       class: wrapper.manifest.class,
       terminals: wrapper.manifest.terminals,
-      capabilities: wrapper.manifest.capabilities
+      capabilities: wrapper.manifest.capabilities,
     });
-    
+
     // Monitor health
     this.monitorWrapper(wrapper);
   }
-  
+
   private monitorWrapper(wrapper: ExternalServerWrapper): void {
     setInterval(() => {
       if (!wrapper.isRunning() && wrapper.manifest.restart !== 'never') {
@@ -726,14 +737,14 @@ Wrappers register as external servers:
 ```typescript
 // Query for external wrappers
 const wrappers = await hostess.query({
-  class: '0xFFFF'  // External wrapper class
+  class: '0xFFFF', // External wrapper class
 });
 
 // Query by capability
 const sqlServers = await hostess.query({
   capabilities: {
-    accepts: ['sql-query']
-  }
+    accepts: ['sql-query'],
+  },
 });
 ```
 
@@ -747,13 +758,13 @@ const config: WiringConfig = {
   connections: [
     {
       source: 'client-server.output',
-      target: 'sql-wrapper.query'  // External wrapper terminal
+      target: 'sql-wrapper.query', // External wrapper terminal
     },
     {
       source: 'sql-wrapper.results',
-      target: 'client-server.input'
-    }
-  ]
+      target: 'client-server.input',
+    },
+  ],
 };
 
 // Topology visualization shows wrapped processes
@@ -767,6 +778,7 @@ const mermaid = stateManager.exportMermaid();
 ### Sandboxing (Out of Scope)
 
 Wrapper doesn't provide sandboxing. Use OS-level mechanisms:
+
 - Docker containers
 - systemd units with restrictions
 - AppArmor/SELinux profiles
@@ -779,12 +791,12 @@ Never pass secrets in environment variables visible to `ps`:
 ```typescript
 // BAD: Secret visible in process list
 const wrapper = new StdioWrapper({
-  env: { DATABASE_PASSWORD: 'secret123' }
+  env: { DATABASE_PASSWORD: 'secret123' },
 });
 
 // GOOD: Pass secrets via secure input
 const wrapper = new StdioWrapper({
-  env: { DATABASE_PASSWORD_FILE: '/run/secrets/db_password' }
+  env: { DATABASE_PASSWORD_FILE: '/run/secrets/db_password' },
 });
 ```
 
@@ -809,6 +821,7 @@ class SQLTranslator implements Translator {
 ### Process Overhead
 
 Each wrapper spawns a process:
+
 - Typical overhead: 5-10 MB RAM
 - Startup time: 10-100 ms
 - Consider pooling for short-lived tasks
@@ -816,6 +829,7 @@ Each wrapper spawns a process:
 ### Pipe Buffering
 
 Node.js streams buffer automatically:
+
 - Default buffer: 16 KB
 - Adjust with `highWaterMark` option
 - Monitor backpressure
@@ -823,6 +837,7 @@ Node.js streams buffer automatically:
 ### Translation Overhead
 
 Translation layers add latency:
+
 - Typical overhead: 0.1-1 ms per message
 - Use binary protocols when possible
 - Cache translations for repeated data
@@ -854,18 +869,21 @@ The External Server Wrapper architecture enables:
 6. ✅ **Standard lifecycle** - Spawn, restart, shutdown, monitoring
 
 **Key principles:**
+
 - Wrapper is just another module type
 - Follows microkernel philosophy (mechanism, not policy)
 - Testable in isolation
 - Composable with other modules
 
 **Integration:**
+
 - Executor spawns wrappers
 - Hostess tracks wrapped servers
 - StateManager wires wrapper terminals
 - Kernel provides pipe plumbing (unchanged)
 
 See also:
+
 - **[RFC 12: PTY Wrapper Patterns](12-pty-wrapper-patterns.md)** - Wrapping interactive TUI applications
 - **[RFC 10: Executor Server](10-executor-server.md)** - External process lifecycle management
 - **[RFC 08: Registry Server](08-registry-server.md)** - Server registration and discovery
diff --git a/docs/rfcs/stream-kernel/12-pty-wrapper-patterns.md b/docs/rfcs/stream-kernel/12-pty-wrapper-patterns.md
index d0799eb..0d68fb9 100644
--- a/docs/rfcs/stream-kernel/12-pty-wrapper-patterns.md
+++ b/docs/rfcs/stream-kernel/12-pty-wrapper-patterns.md
@@ -33,34 +33,34 @@ This RFC defines patterns for wrapping interactive terminal applications (TUI ap
 ```typescript
 interface PTYServerWrapper extends ExternalServerWrapper {
   // Standard module interface
-  inputPipe: Pipe;     // Commands/keystrokes to PTY
-  outputPipe: Pipe;    // ANSI output from PTY
-  
+  inputPipe: Pipe; // Commands/keystrokes to PTY
+  outputPipe: Pipe; // ANSI output from PTY
+
   // PTY-specific
   ptyProcess: IPty;
   terminalSize: { cols: number; rows: number };
-  
+
   // PTY operations
   resize(cols: number, rows: number): void;
   sendSignal(signal: string): void;
-  
+
   // Manifest with PTY settings
   manifest: PTYManifest;
 }
 
 interface PTYManifest extends ServerManifest {
-  ioMode: 'pty';  // Always PTY mode
-  
+  ioMode: 'pty'; // Always PTY mode
+
   // PTY configuration
-  terminalType: string;        // e.g., 'xterm-256color'
-  initialCols: number;         // e.g., 80
-  initialRows: number;         // e.g., 24
-  enableFlow: boolean;         // XON/XOFF flow control
+  terminalType: string; // e.g., 'xterm-256color'
+  initialCols: number; // e.g., 80
+  initialRows: number; // e.g., 24
+  enableFlow: boolean; // XON/XOFF flow control
   encoding: 'utf8' | 'binary'; // Character encoding
-  
+
   // Application-specific
-  shell: string;               // e.g., 'bash', 'zsh'
-  shellArgs: string[];         // Shell arguments
+  shell: string; // e.g., 'bash', 'zsh'
+  shellArgs: string[]; // Shell arguments
 }
 ```
 
@@ -75,49 +75,45 @@ class BasicPTYWrapper {
   inputPipe: Pipe;
   outputPipe: Pipe;
   private ptyProcess: IPty;
-  
+
   constructor(kernel: Kernel, manifest: PTYManifest) {
     this.inputPipe = kernel.createPipe();
     this.outputPipe = kernel.createPipe();
     this.manifest = manifest;
   }
-  
+
   async spawn(): Promise<void> {
     // Spawn PTY process
-    this.ptyProcess = pty.spawn(
-      this.manifest.shell || 'bash',
-      this.manifest.shellArgs || [],
-      {
-        name: this.manifest.terminalType || 'xterm-256color',
-        cols: this.manifest.initialCols || 80,
-        rows: this.manifest.initialRows || 24,
-        cwd: this.manifest.cwd || process.cwd(),
-        env: this.manifest.env || process.env
-      }
-    );
-    
+    this.ptyProcess = pty.spawn(this.manifest.shell || 'bash', this.manifest.shellArgs || [], {
+      name: this.manifest.terminalType || 'xterm-256color',
+      cols: this.manifest.initialCols || 80,
+      rows: this.manifest.initialRows || 24,
+      cwd: this.manifest.cwd || process.cwd(),
+      env: this.manifest.env || process.env,
+    });
+
     // PTY output → outputPipe
     this.ptyProcess.onData((data: string) => {
       this.outputPipe.write(Buffer.from(data));
     });
-    
+
     // inputPipe → PTY input
     this.inputPipe.on('data', (data: Buffer) => {
       this.ptyProcess.write(data.toString());
     });
-    
+
     // Handle process exit
     this.ptyProcess.onExit(({ exitCode, signal }) => {
       console.log(`PTY exited: code=${exitCode}, signal=${signal}`);
       this.outputPipe.end();
     });
   }
-  
+
   resize(cols: number, rows: number): void {
     this.ptyProcess.resize(cols, rows);
     this.terminalSize = { cols, rows };
   }
-  
+
   sendSignal(signal: string): void {
     this.ptyProcess.kill(signal);
   }
@@ -138,7 +134,7 @@ const bashPTY = new BasicPTYWrapper(kernel, {
   shell: 'bash',
   terminalType: 'xterm-256color',
   initialCols: 80,
-  initialRows: 24
+  initialRows: 24,
 });
 
 // Output
@@ -167,11 +163,11 @@ const keyboard = new KeyboardInput(kernel);
 // PTY wrapper for Claude Code
 const claudeCodePTY = new BasicPTYWrapper(kernel, {
   name: 'claude-code',
-  shell: 'claude-code',  // Claude Code CLI
+  shell: 'claude-code', // Claude Code CLI
   shellArgs: [],
   terminalType: 'xterm-256color',
   initialCols: 120,
-  initialRows: 40
+  initialRows: 40,
 });
 
 // Multiple renderers
@@ -180,7 +176,7 @@ const ttsRenderer = new TextToSpeechRenderer(kernel);
 const mp4Renderer = new MP4Recorder(kernel, {
   fps: 30,
   width: 1200,
-  height: 800
+  height: 800,
 });
 const mcpRenderer = new MCPRenderer(kernel);
 const webrtcRenderer = new WebRTCRenderer(kernel);
@@ -190,11 +186,11 @@ kernel.connect(keyboard.output, claudeCodePTY.input);
 
 // Output: PTY → all renderers simultaneously
 kernel.split(claudeCodePTY.output, [
-  passthroughRenderer.input,  // Human sees it
-  ttsRenderer.input,          // TTS describes changes
-  mp4Renderer.input,          // Records video
-  mcpRenderer.input,          // LLM-friendly format
-  webrtcRenderer.input        // Streams to remote
+  passthroughRenderer.input, // Human sees it
+  ttsRenderer.input, // TTS describes changes
+  mp4Renderer.input, // Records video
+  mcpRenderer.input, // LLM-friendly format
+  webrtcRenderer.input, // Streams to remote
 ]);
 
 await claudeCodePTY.spawn();
@@ -224,18 +220,14 @@ const vimPTY = new BasicPTYWrapper(kernel, {
   name: 'vim-session',
   shell: 'vim',
   shellArgs: ['document.txt'],
-  terminalType: 'xterm-256color'
+  terminalType: 'xterm-256color',
 });
 
 // Output
 const screen = new ScreenRenderer(kernel);
 
 // Multi-input → PTY
-kernel.merge([
-  keyboard.output,
-  voiceInput.output,
-  aiAgent.output
-], vimPTY.input);
+kernel.merge([keyboard.output, voiceInput.output, aiAgent.output], vimPTY.input);
 
 // PTY → screen
 kernel.connect(vimPTY.output, screen.input);
@@ -258,10 +250,10 @@ Raw ANSI to terminal:
 ```typescript
 class PassthroughRenderer {
   inputPipe: Pipe;
-  
+
   constructor(kernel: Kernel) {
     this.inputPipe = kernel.createPipe();
-    
+
     this.inputPipe.on('data', (data: Buffer) => {
       // Write raw ANSI to stdout
       process.stdout.write(data);
@@ -279,34 +271,34 @@ class TextToSpeechRenderer {
   inputPipe: Pipe;
   private parser: ANSIParser;
   private prevState: TerminalState;
-  
+
   constructor(kernel: Kernel) {
     this.inputPipe = kernel.createPipe();
     this.parser = new ANSIParser();
-    
+
     this.inputPipe.on('data', (data: Buffer) => {
       const newState = this.parser.parse(data);
       const changes = this.detectChanges(this.prevState, newState);
-      
+
       if (changes.text) {
         this.speak(changes.text);
       }
-      
+
       this.prevState = newState;
     });
   }
-  
+
   private detectChanges(prev: TerminalState, curr: TerminalState) {
     // Detect what changed
     const newText = this.extractNewText(prev, curr);
     const cursorMoved = this.cursorMoved(prev, curr);
-    
+
     return {
       text: newText,
-      cursorMoved: cursorMoved
+      cursorMoved: cursorMoved,
     };
   }
-  
+
   private speak(text: string): void {
     // Use text-to-speech API
     const utterance = new SpeechSynthesisUtterance(text);
@@ -325,7 +317,7 @@ class MP4Recorder {
   private canvas: OffscreenCanvas;
   private encoder: VideoEncoder;
   private parser: ANSIParser;
-  
+
   constructor(kernel: Kernel, options: { fps: number; width: number; height: number }) {
     this.inputPipe = kernel.createPipe();
     this.canvas = new OffscreenCanvas(options.width, options.height);
@@ -333,27 +325,27 @@ class MP4Recorder {
       codec: 'avc1.42001E',
       width: options.width,
       height: options.height,
-      framerate: options.fps
+      framerate: options.fps,
     });
-    
+
     this.parser = new ANSIParser();
-    
+
     // Capture frames at specified FPS
     setInterval(() => this.captureFrame(), 1000 / options.fps);
-    
+
     this.inputPipe.on('data', (data: Buffer) => {
       const state = this.parser.parse(data);
       this.renderToCanvas(state);
     });
   }
-  
+
   private renderToCanvas(state: TerminalState): void {
     const ctx = this.canvas.getContext('2d');
-    
+
     // Clear canvas
     ctx.fillStyle = '#000000';
     ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
-    
+
     // Render terminal cells
     ctx.font = '16px monospace';
     for (let y = 0; y < state.rows; y++) {
@@ -364,14 +356,14 @@ class MP4Recorder {
       }
     }
   }
-  
+
   private captureFrame(): void {
-    const imageData = this.canvas.getContext('2d').getImageData(
-      0, 0, this.canvas.width, this.canvas.height
-    );
+    const imageData = this.canvas
+      .getContext('2d')
+      .getImageData(0, 0, this.canvas.width, this.canvas.height);
     this.encoder.encode(imageData);
   }
-  
+
   async save(filename: string): Promise<void> {
     await this.encoder.flush();
     await this.encoder.finalize(filename);
@@ -388,19 +380,19 @@ class MCPRenderer {
   inputPipe: Pipe;
   outputPipe: Pipe;
   private parser: ANSIParser;
-  
+
   constructor(kernel: Kernel) {
     this.inputPipe = kernel.createPipe();
     this.outputPipe = kernel.createPipe();
     this.parser = new ANSIParser();
-    
+
     this.inputPipe.on('data', (data: Buffer) => {
       const state = this.parser.parse(data);
       const formatted = this.formatForLLM(state);
       this.outputPipe.write(JSON.stringify(formatted));
     });
   }
-  
+
   private formatForLLM(state: TerminalState): any {
     return {
       type: 'terminal_state',
@@ -408,35 +400,33 @@ class MCPRenderer {
       content: {
         // Plain text (no ANSI)
         text: this.extractPlainText(state),
-        
+
         // Cursor position
         cursor: {
           row: state.cursorY,
-          col: state.cursorX
+          col: state.cursorX,
         },
-        
+
         // Visible region
         viewport: {
           rows: state.rows,
           cols: state.cols,
-          scrollback: state.scrollback
+          scrollback: state.scrollback,
         },
-        
+
         // Semantic structure
         sections: this.detectSections(state),
-        
+
         // UI elements
         menu: this.detectMenu(state),
         statusBar: this.detectStatusBar(state),
-        activeWindow: this.detectActiveWindow(state)
-      }
+        activeWindow: this.detectActiveWindow(state),
+      },
     };
   }
-  
+
   private extractPlainText(state: TerminalState): string {
-    return state.cells.map(row => 
-      row.map(cell => cell.char).join('')
-    ).join('\n');
+    return state.cells.map((row) => row.map((cell) => cell.char).join('')).join('\n');
   }
 }
 ```
@@ -451,34 +441,34 @@ class WebRTCRenderer {
   private peerConnection: RTCPeerConnection;
   private canvas: OffscreenCanvas;
   private parser: ANSIParser;
-  
+
   constructor(kernel: Kernel) {
     this.inputPipe = kernel.createPipe();
     this.canvas = new OffscreenCanvas(1200, 800);
     this.parser = new ANSIParser();
-    
+
     // Set up WebRTC
     this.peerConnection = new RTCPeerConnection({
-      iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
+      iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
     });
-    
+
     // Capture canvas stream
     const stream = this.canvas.captureStream(30); // 30 fps
-    stream.getTracks().forEach(track => {
+    stream.getTracks().forEach((track) => {
       this.peerConnection.addTrack(track, stream);
     });
-    
+
     this.inputPipe.on('data', (data: Buffer) => {
       const state = this.parser.parse(data);
       this.renderToCanvas(state);
     });
   }
-  
+
   private renderToCanvas(state: TerminalState): void {
     // Same as MP4Recorder rendering
     // Canvas is captured by WebRTC stream
   }
-  
+
   async connect(remoteOffer: RTCSessionDescriptionInit): Promise<RTCSessionDescriptionInit> {
     await this.peerConnection.setRemoteDescription(remoteOffer);
     const answer = await this.peerConnection.createAnswer();
@@ -495,27 +485,27 @@ class WebRTCRenderer {
 ```typescript
 class ANSIParser {
   private state: TerminalState;
-  
+
   constructor() {
     this.state = {
-      cells: Array(24).fill(null).map(() => 
-        Array(80).fill({ char: ' ', fg: null, bg: null })
-      ),
+      cells: Array(24)
+        .fill(null)
+        .map(() => Array(80).fill({ char: ' ', fg: null, bg: null })),
       cursorX: 0,
       cursorY: 0,
       rows: 24,
       cols: 80,
-      scrollback: []
+      scrollback: [],
     };
   }
-  
+
   parse(data: Buffer): TerminalState {
     const str = data.toString();
     let i = 0;
-    
+
     while (i < str.length) {
       const char = str[i];
-      
+
       if (char === '\x1b') {
         // ANSI escape sequence
         const seq = this.parseEscapeSequence(str, i);
@@ -535,30 +525,30 @@ class ANSIParser {
         this.state.cells[this.state.cursorY][this.state.cursorX] = {
           char: char,
           fg: this.state.currentFg,
-          bg: this.state.currentBg
+          bg: this.state.currentBg,
         };
         this.state.cursorX++;
         i++;
       }
-      
+
       // Handle scrolling
       if (this.state.cursorY >= this.state.rows) {
         this.scroll();
       }
     }
-    
+
     return this.state;
   }
-  
+
   private parseEscapeSequence(str: string, start: number): EscapeSequence {
     // Parse ANSI escape sequences
     // Examples:
     // \x1b[31m - Set foreground to red
     // \x1b[2J  - Clear screen
     // \x1b[H   - Move cursor to home
-    
+
     let i = start + 1; // Skip \x1b
-    
+
     if (str[i] === '[') {
       // CSI sequence
       i++;
@@ -568,18 +558,18 @@ class ANSIParser {
         i++;
       }
       const cmd = str[i];
-      
+
       return {
         type: 'csi',
-        params: params.split(';').map(p => parseInt(p) || 0),
+        params: params.split(';').map((p) => parseInt(p) || 0),
         cmd: cmd,
-        length: i - start + 1
+        length: i - start + 1,
       };
     }
-    
+
     return { type: 'unknown', length: 1 };
   }
-  
+
   private handleEscapeSequence(seq: EscapeSequence): void {
     if (seq.type === 'csi') {
       switch (seq.cmd) {
@@ -599,7 +589,7 @@ class ANSIParser {
       }
     }
   }
-  
+
   private handleSGR(params: number[]): void {
     for (const param of params) {
       if (param >= 30 && param <= 37) {
@@ -626,19 +616,19 @@ class ANSIParser {
 class ResizablePTYWrapper extends BasicPTYWrapper {
   constructor(kernel: Kernel, manifest: PTYManifest) {
     super(kernel, manifest);
-    
+
     // Listen for resize events
     process.stdout.on('resize', () => {
       const { columns, rows } = process.stdout;
       this.resize(columns, rows);
     });
   }
-  
+
   resize(cols: number, rows: number): void {
     // Resize PTY
     this.ptyProcess.resize(cols, rows);
     this.terminalSize = { cols, rows };
-    
+
     // Notify renderers of resize
     this.outputPipe.emit('resize', { cols, rows });
   }
@@ -651,17 +641,17 @@ class ResizablePTYWrapper extends BasicPTYWrapper {
 class MP4Recorder {
   constructor(kernel: Kernel, options: MP4Options) {
     this.inputPipe = kernel.createPipe();
-    
+
     // Handle resize events
     this.inputPipe.on('resize', ({ cols, rows }) => {
       this.updateCanvasSize(cols, rows);
     });
   }
-  
+
   private updateCanvasSize(cols: number, rows: number): void {
-    const charWidth = 10;  // pixels per char
+    const charWidth = 10; // pixels per char
     const charHeight = 20; // pixels per line
-    
+
     this.canvas.width = cols * charWidth;
     this.canvas.height = rows * charHeight;
   }
@@ -676,24 +666,24 @@ class MP4Recorder {
 class SignalAwarePTYWrapper extends BasicPTYWrapper {
   constructor(kernel: Kernel, manifest: PTYManifest) {
     super(kernel, manifest);
-    
+
     // Handle Ctrl+C (SIGINT)
     process.on('SIGINT', () => {
       this.ptyProcess.kill('SIGINT');
     });
-    
+
     // Handle Ctrl+Z (SIGTSTP)
     process.on('SIGTSTP', () => {
       this.ptyProcess.kill('SIGTSTP');
     });
-    
+
     // Handle terminal close (SIGHUP)
     process.on('SIGHUP', () => {
       this.ptyProcess.kill('SIGHUP');
       this.shutdown();
     });
   }
-  
+
   sendSignal(signal: string): void {
     this.ptyProcess.kill(signal);
   }
@@ -725,14 +715,14 @@ const claudeCode = new PTYWrapper(kernel, {
   ioMode: 'pty',
   terminals: [
     { name: 'input', direction: 'input', protocol: 'ansi' },
-    { name: 'output', direction: 'output', protocol: 'ansi' }
+    { name: 'output', direction: 'output', protocol: 'ansi' },
   ],
   capabilities: {
     type: 'source',
     accepts: ['keyboard-input', 'ansi-commands'],
     produces: ['ansi-output'],
-    features: ['tui', 'interactive', 'code-editing']
-  }
+    features: ['tui', 'interactive', 'code-editing'],
+  },
 });
 
 // Renderers
@@ -743,12 +733,7 @@ const mcp = new MCPRenderer(kernel);
 
 // Wire it up
 kernel.connect(keyboard.output, claudeCode.input);
-kernel.split(claudeCode.output, [
-  screen.input,
-  tts.input,
-  mp4.input,
-  mcp.input
-]);
+kernel.split(claudeCode.output, [screen.input, tts.input, mp4.input, mcp.input]);
 
 // Start
 await claudeCode.spawn();
@@ -770,10 +755,10 @@ const keyboard = new KeyboardInput(kernel);
 const voice = new WhisperSTT(kernel, {
   commands: {
     'save file': ':w\n',
-    'quit': ':q\n',
+    quit: ':q\n',
     'delete line': 'dd',
-    'undo': 'u'
-  }
+    undo: 'u',
+  },
 });
 const aiAgent = new MCPInput(kernel);
 
@@ -785,18 +770,14 @@ const vim = new PTYWrapper(kernel, {
   terminalType: 'xterm-256color',
   initialCols: 80,
   initialRows: 24,
-  ioMode: 'pty'
+  ioMode: 'pty',
 });
 
 // Output
 const screen = new PassthroughRenderer(kernel);
 
 // Wire it up
-kernel.merge([
-  keyboard.output,
-  voice.output,
-  aiAgent.output
-], vim.input);
+kernel.merge([keyboard.output, voice.output, aiAgent.output], vim.input);
 
 kernel.connect(vim.output, screen.input);
 
@@ -821,7 +802,7 @@ const htop = new PTYWrapper(kernel, {
   terminalType: 'xterm-256color',
   initialCols: 120,
   initialRows: 40,
-  ioMode: 'pty'
+  ioMode: 'pty',
 });
 
 // Local screen
@@ -831,10 +812,7 @@ const screen = new PassthroughRenderer(kernel);
 const webrtc = new WebRTCRenderer(kernel);
 
 // Split output
-kernel.split(htop.output, [
-  screen.input,
-  webrtc.input
-]);
+kernel.split(htop.output, [screen.input, webrtc.input]);
 
 // Start
 await htop.spawn();
@@ -854,47 +832,47 @@ describe('PTYWrapper', () => {
     const wrapper = new PTYWrapper(kernel, {
       name: 'test',
       shell: 'bash',
-      ioMode: 'pty'
+      ioMode: 'pty',
     });
-    
+
     await wrapper.spawn();
-    
+
     expect(wrapper.isRunning()).toBe(true);
     expect(wrapper.ptyProcess).toBeDefined();
   });
-  
+
   it('should pipe data bidirectionally', async () => {
     const wrapper = new PTYWrapper(kernel, {
       name: 'test',
       shell: 'cat',
-      ioMode: 'pty'
+      ioMode: 'pty',
     });
-    
+
     await wrapper.spawn();
-    
+
     const output: Buffer[] = [];
     wrapper.outputPipe.on('data', (data) => output.push(data));
-    
+
     wrapper.inputPipe.write('hello\n');
-    
-    await new Promise(resolve => setTimeout(resolve, 100));
-    
+
+    await new Promise((resolve) => setTimeout(resolve, 100));
+
     expect(Buffer.concat(output).toString()).toContain('hello');
   });
-  
+
   it('should handle resize', async () => {
     const wrapper = new PTYWrapper(kernel, {
       name: 'test',
       shell: 'bash',
       initialCols: 80,
       initialRows: 24,
-      ioMode: 'pty'
+      ioMode: 'pty',
     });
-    
+
     await wrapper.spawn();
-    
+
     wrapper.resize(120, 40);
-    
+
     expect(wrapper.terminalSize).toEqual({ cols: 120, rows: 40 });
   });
 });
@@ -905,35 +883,32 @@ describe('PTYWrapper', () => {
 ```typescript
 it('should split PTY output to multiple renderers', async () => {
   const kernel = new Kernel();
-  
+
   const pty = new PTYWrapper(kernel, {
     name: 'test',
     shell: 'echo',
     shellArgs: ['hello'],
-    ioMode: 'pty'
+    ioMode: 'pty',
   });
-  
+
   const renderer1 = new PassthroughRenderer(kernel);
   const renderer2 = new PassthroughRenderer(kernel);
-  
+
   const output1: Buffer[] = [];
   const output2: Buffer[] = [];
-  
+
   renderer1.inputPipe.on('data', (data) => output1.push(data));
   renderer2.inputPipe.on('data', (data) => output2.push(data));
-  
-  kernel.split(pty.output, [
-    renderer1.input,
-    renderer2.input
-  ]);
-  
+
+  kernel.split(pty.output, [renderer1.input, renderer2.input]);
+
   await pty.spawn();
-  
-  await new Promise(resolve => setTimeout(resolve, 200));
-  
+
+  await new Promise((resolve) => setTimeout(resolve, 200));
+
   const str1 = Buffer.concat(output1).toString();
   const str2 = Buffer.concat(output2).toString();
-  
+
   expect(str1).toContain('hello');
   expect(str2).toContain('hello');
 });
@@ -947,9 +922,9 @@ PTYWrapper extends ExternalServerWrapper:
 
 ```typescript
 class PTYWrapper extends ExternalServerWrapper {
-  ioMode: 'pty';  // Always PTY mode
+  ioMode: 'pty'; // Always PTY mode
   ptyProcess: IPty;
-  
+
   async spawn(): Promise<void> {
     // Spawn via node-pty instead of child_process
     this.ptyProcess = pty.spawn(this.manifest.shell, this.manifest.shellArgs, {
@@ -957,13 +932,13 @@ class PTYWrapper extends ExternalServerWrapper {
       cols: this.manifest.initialCols,
       rows: this.manifest.initialRows,
       env: this.manifest.env,
-      cwd: this.manifest.cwd
+      cwd: this.manifest.cwd,
     });
-    
+
     // Same pipe connections as base wrapper
     this.ptyProcess.onData((data) => this.outputPipe.write(Buffer.from(data)));
     this.inputPipe.on('data', (data) => this.ptyProcess.write(data.toString()));
-    
+
     // Register with Hostess
     await this.registerWithHostess();
   }
@@ -979,16 +954,16 @@ class Executor {
   async spawnPTYWrapper(manifest: PTYManifest): Promise<PTYWrapper> {
     const wrapper = new PTYWrapper(this.kernel, manifest);
     await wrapper.spawn();
-    
+
     // Register with Hostess
     await this.hostess.register({
       id: manifest.uuid,
       servername: manifest.name,
       class: manifest.class,
       terminals: manifest.terminals,
-      capabilities: manifest.capabilities
+      capabilities: manifest.capabilities,
     });
-    
+
     return wrapper;
   }
 }
@@ -1004,17 +979,17 @@ const config: WiringConfig = {
   connections: [
     {
       source: 'keyboard-input.output',
-      target: 'claude-code-pty.input'
+      target: 'claude-code-pty.input',
     },
     {
       source: 'claude-code-pty.output',
-      target: 'screen-renderer.input'
+      target: 'screen-renderer.input',
     },
     {
       source: 'claude-code-pty.output',
-      target: 'tts-renderer.input'
-    }
-  ]
+      target: 'tts-renderer.input',
+    },
+  ],
 };
 
 // Apply wiring
@@ -1038,6 +1013,7 @@ const mermaid = stateManager.exportMermaid();
 ### Multi-Modal Rendering Overhead
 
 Each renderer adds:
+
 - PassthroughRenderer: ~0.1ms
 - MP4Recorder: ~5-10ms (encoding overhead)
 - TextToSpeech: ~50-100ms (synthesis latency)
@@ -1080,18 +1056,21 @@ PTY wrapper patterns enable:
 7. ✅ **Terminal resize** - Dynamic size changes (SIGWINCH)
 
 **Key principles:**
+
 - PTYWrapper extends ExternalServerWrapper
 - Each renderer is a separate module
 - Use kernel's split()/merge() for topology
 - Location transparent - works locally or distributed
 
 **Integration:**
+
 - Executor spawns PTY wrappers
 - Hostess registers PTY servers
 - StateManager wires PTY connections
 - Kernel provides pipe plumbing
 
 See also:
+
 - **[RFC 11: External Server Wrapper](11-external-wrapper.md)** - Base wrapper architecture
 - **[RFC 04: PTY Use Cases](04-pty-use-cases.md)** - Real-world PTY usage examples
 - **[RFC 03: Module Types](03-module-types.md)** - Module composition patterns
diff --git a/docs/rfcs/stream-kernel/ansi-parser.md b/docs/rfcs/stream-kernel/ansi-parser.md
index 767782b..7ef89fb 100644
--- a/docs/rfcs/stream-kernel/ansi-parser.md
+++ b/docs/rfcs/stream-kernel/ansi-parser.md
@@ -7,6 +7,7 @@ The ANSI Parser is a core component of the Stream Kernel that interprets ANSI es
 ## Architecture
 
 The parser follows a streaming architecture:
+
 - **Input**: Raw byte streams containing ANSI escape sequences
 - **Processing**: State machine-based parsing with batched character handling
 - **Output**: Structured events representing terminal operations (print, cursor, erase, style, mode, reset)
@@ -14,12 +15,14 @@ The parser follows a streaming architecture:
 ## Phase 1 (P1) - Core Implementation
 
 ### Supported Features
+
 - **Basic CSI sequences**: Cursor movement (H, f, A, B, C, D, G), clearing (J, K)
 - **SGR (Select Graphic Rendition)**: Colors (30-37, 40-47, 90-97, 100-107), bold, underline, inverse
 - **Control characters**: Line feed (`\n`), carriage return (`\r`), tab (`\t`), backspace (`\b`)
 - **Terminal state**: Cursor position, color state, screen buffer
 
 ### Architecture
+
 - Event-driven parser with state machine
 - Modular sequence handlers
 - Terminal state management
@@ -31,12 +34,14 @@ The parser follows a streaming architecture:
 **Implementation**: Multi-byte UTF-8 character parsing with proper width detection.
 
 **Features**:
+
 - **UTF-8 decoding**: Handles 1-4 byte UTF-8 sequences correctly
 - **Wide character detection**: East Asian width (EAW) support for CJK characters
 - **Character width calculation**: Returns 1 or 2 based on Unicode code point ranges
 - **Cursor advancement**: Properly advances cursor by character width
 
 **Supported ranges**:
+
 - Hangul Jamo (U+1100-U+115F)
 - CJK characters (U+2E80-U+A4CF, U+AC00-U+D7A3, U+F900-U+FAFF)
 - Fullwidth forms (U+FF00-U+FF60, U+FFE0-U+FFE6)
@@ -44,6 +49,7 @@ The parser follows a streaming architecture:
 - CJK Extension planes (U+20000-U+3FFFD)
 
 **Methods**:
+
 ```typescript
 private readUTF8Char(index: number): { char: string; length: number }
 private getCharWidth(char: string): number
@@ -54,11 +60,13 @@ private getCharWidth(char: string): number
 **Implementation**: DEC private mode set/reset sequences for terminal behavior control.
 
 **Supported modes**:
+
 - **Mode 25**: Cursor visibility (DECTCEM)
   - `CSI ? 25 h` - Show cursor (DECSET)
   - `CSI ? 25 l` - Hide cursor (DECRST)
 
 **State tracking**:
+
 ```typescript
 interface AnsiParserState {
   cursorVisible: boolean;
@@ -67,14 +75,15 @@ interface AnsiParserState {
 ```
 
 **Events**:
+
 ```typescript
 {
   type: 'mode',
-  data: { 
-    action: 'set' | 'reset', 
-    mode: number, 
-    name: string, 
-    value: boolean 
+  data: {
+    action: 'set' | 'reset',
+    mode: number,
+    name: string,
+    value: boolean
   }
 }
 ```
@@ -84,6 +93,7 @@ interface AnsiParserState {
 **Sequence**: `ESC c`
 
 **Behavior**: Full terminal reset
+
 - Clears all terminal state
 - Resets cursor to (0, 0)
 - Clears screen buffer
@@ -91,6 +101,7 @@ interface AnsiParserState {
 - Clears scrollback
 
 **Event**:
+
 ```typescript
 {
   type: 'reset',
@@ -103,10 +114,12 @@ interface AnsiParserState {
 **Implementation**: Consumes OSC sequences without processing.
 
 **Supported terminators**:
+
 - BEL (`\x07`)
 - ST (`ESC \`)
 
 **Common sequences** (consumed but ignored):
+
 - `OSC 0 ; title ST` - Set window title
 - `OSC 2 ; title ST` - Set window title
 
@@ -115,6 +128,7 @@ interface AnsiParserState {
 ### Scrollback Buffer
 
 **Configuration**:
+
 ```typescript
 interface AnsiParserOptions {
   scrollbackLimit?: number; // Default: 1000
@@ -124,6 +138,7 @@ const parser = new AnsiParser({ scrollbackLimit: 5000 });
 ```
 
 **Storage**:
+
 ```typescript
 interface ScrollbackLine {
   content: string;
@@ -133,12 +148,14 @@ interface ScrollbackLine {
 ```
 
 **Behavior**:
+
 - Lines pushed to scrollback on line feed
 - FIFO buffer with configurable limit
 - Preserves style information per line
 - Timestamped for debugging/replay
 
 **Methods**:
+
 ```typescript
 getScrollback(): ScrollbackLine[]
 ```
@@ -148,6 +165,7 @@ getScrollback(): ScrollbackLine[]
 **Purpose**: Enable terminal state inspection, debugging, and export.
 
 **Snapshot**:
+
 ```typescript
 interface TerminalSnapshot {
   state: AnsiParserState;
@@ -159,6 +177,7 @@ const snapshot = parser.snapshot();
 ```
 
 **Export formats**:
+
 ```typescript
 // JSON export (includes full state and styling)
 const json = parser.exportJSON();
@@ -168,6 +187,7 @@ const text = parser.exportPlainText();
 ```
 
 **Use cases**:
+
 - Session recording
 - Terminal state debugging
 - Log export
@@ -176,23 +196,28 @@ const text = parser.exportPlainText();
 ### Performance Improvements
 
 **Character batching**:
+
 - Accumulates printable characters before emitting events
 - Reduces event count by ~70% for text-heavy output
 - Tracks batch start position for efficient rendering
 
 **Optimized parsing**:
+
 - Character code comparison instead of string operations
 - Pre-allocated buffers where possible
 - Reduced string allocations in hot paths
 
 **Efficient parameter parsing**:
+
 ```typescript
 private parseParams(paramStr: string): number[]
 ```
+
 - Manual integer parsing without `split()` and `parseInt()`
 - Reduces allocations in CSI parameter handling
 
 **Benchmarks** (from T6454):
+
 - Baseline: ~2.5ms for 10k character input
 - Optimized: ~0.8ms for 10k character input
 - **3x improvement** in text-heavy scenarios
@@ -242,6 +267,7 @@ interface AnsiParserEvent {
 ```
 
 **Event types**:
+
 - **print**: Character(s) to render at position
 - **cursor**: Cursor movement
 - **erase**: Screen or line clearing
@@ -252,6 +278,7 @@ interface AnsiParserEvent {
 ## Testing
 
 Comprehensive test coverage in `tests/parsers/ansiParser.spec.ts`:
+
 - UTF-8 and wide character handling
 - DECSET/DECRST mode switching
 - RIS full reset
@@ -270,6 +297,7 @@ Comprehensive test coverage in `tests/parsers/ansiParser.spec.ts`:
 **Background**: `CSI 48 ; 5 ; n m` where n = 0-255
 
 **Color ranges**:
+
 - **0-15**: Standard ANSI colors (same as 30-37, 90-97)
 - **16-231**: 6x6x6 RGB color cube (216 colors)
   - Formula: `16 + 36*r + 6*g + b` where r,g,b ∈ [0,5]
@@ -278,10 +306,12 @@ Comprehensive test coverage in `tests/parsers/ansiParser.spec.ts`:
 Palette indices resolve to precomputed `#RRGGBB` hex strings so renderers receive the exact color value without recomputing the xterm look-up table on every event.
 
 **Example**:
+
 ```typescript
-parser.parse(Buffer.from('\x1b[38;5;196mBright Red Text'));  // Color 196 = #ff0000
-parser.parse(Buffer.from('\x1b[48;5;21mDeep Blue BG'));      // Color 21 = #0000ff
+parser.parse(Buffer.from('\x1b[38;5;196mBright Red Text')); // Color 196 = #ff0000
+parser.parse(Buffer.from('\x1b[48;5;21mDeep Blue BG')); // Color 21 = #0000ff
 ```
+
 Run `npx tsx examples/ansi-parser-p3.ts` to see the resolved hex colors printed alongside the emitted style events.
 
 ### Truecolor (24-bit RGB) Support
@@ -292,6 +322,7 @@ Run `npx tsx examples/ansi-parser-p3.ts` to see the resolved hex colors printed
 **Background**: `CSI 48 ; 2 ; r ; g ; b m` where r,g,b ∈ [0,255]
 
 **Features**:
+
 - Full 24-bit color depth (16.7 million colors)
 - RGB values converted to hex format (#RRGGBB)
 - Values clamped to [0, 255] range
@@ -299,8 +330,9 @@ Run `npx tsx examples/ansi-parser-p3.ts` to see the resolved hex colors printed
 - Compatible with standard SGR reset (0)
 
 **Example**:
+
 ```typescript
-parser.parse(Buffer.from('\x1b[38;2;255;128;64mOrange Text'));    // RGB(255,128,64) = #ff8040
+parser.parse(Buffer.from('\x1b[38;2;255;128;64mOrange Text')); // RGB(255,128,64) = #ff8040
 parser.parse(Buffer.from('\x1b[48;2;32;64;128mBlue Background')); // RGB(32,64,128) = #204080
 ```
 
@@ -320,6 +352,7 @@ parser.parse(Buffer.from('\x1b[48;2;32;64;128mBlue Background')); // RGB(32,64,1
 When auto-wrap is enabled, printable characters that reach the configured column count automatically roll the cursor to the next line. With auto-wrap disabled the cursor stays on the right-most cell. Screen inverse updates the parser's `screenInverse` flag so renderers can swap foreground/background colors as needed.
 
 **State tracking**:
+
 ```typescript
 interface TerminalState {
   autoWrap: boolean;
@@ -329,14 +362,16 @@ interface TerminalState {
 ```
 
 **Example**:
+
 ```typescript
-parser.parse(Buffer.from('\x1b[?7l'));  // Disable auto-wrap
+parser.parse(Buffer.from('\x1b[?7l')); // Disable auto-wrap
 parser.parse(Buffer.from('Long text that stays on the same line'));
-parser.parse(Buffer.from('\x1b[?7h'));  // Re-enable wrapping
+parser.parse(Buffer.from('\x1b[?7h')); // Re-enable wrapping
 
-parser.parse(Buffer.from('\x1b[?5h'));  // Enable screen inverse
-parser.parse(Buffer.from('\x1b[?5l'));  // Disable screen inverse
+parser.parse(Buffer.from('\x1b[?5h')); // Enable screen inverse
+parser.parse(Buffer.from('\x1b[?5l')); // Disable screen inverse
 ```
+
 The same sample script (`examples/ansi-parser-p3.ts`) toggles DECAWM and DECSCNM so you can observe the `autoWrap` and `screenInverse` flags changing in real time.
 
 ### Resize Support
@@ -344,17 +379,20 @@ The same sample script (`examples/ansi-parser-p3.ts`) toggles DECAWM and DECSCNM
 **Implementation**: Dynamic terminal dimensions via constructor options and runtime resize calls.
 
 **Features**:
+
 - Terminal dimensions set at construction: `new AnsiParser({ rows: 24, cols: 80 })`
 - Dimensions can be updated in-place via `parser.resize(newCols, newRows)`
 - Cursor position is clamped to remain within the active viewport after every resize
 - Scrollback and style state persist across dimension changes
 
 **Behavior**:
+
 - **Larger dimensions**: Provides extra room while retaining existing state
 - **Smaller dimensions**: Cursor is clamped to the new bounds; auto-wrap controls content flow
 - **Deterministic**: Same input produces same output for the same configuration
 
 **Example**:
+
 ```typescript
 const parser = new AnsiParser({ rows: 24, cols: 80 });
 parser.parse(Buffer.from('Content'));
@@ -367,23 +405,27 @@ parser.parse(Buffer.from('More content across a wider terminal'));
 parser.resize(40, 10);
 parser.parse(Buffer.from('Tighter layout with automatic wrapping when enabled'));
 ```
+
 `examples/ansi-parser-p3.ts` emits the `resize` event and logs the new `getDimensions()` result so you can watch the clamping and state updates.
 
 ### Performance Considerations
 
 **Benchmarks** (P3 features):
+
 - 256-color sequences: ~0.9ms for 300 color changes
 - Truecolor sequences: ~1.2ms for 200 RGB colors
 - DEC mode switches: ~0.5ms for 250 mode changes
 - Mixed P3 features: ~1.5ms for 50 complex sequences
 
 **Optimizations**:
+
 - RGB to hex conversion cached
 - 256-color palette pre-computed
 - Mode state changes tracked without reallocations
 - Parameter parsing optimized for color sequences
 
 **Performance guards**:
+
 - Test suite includes determinism tests
 - Benchmarks track regression
 - Large palette/truecolor sequence tests assert throughput stays within budget
@@ -394,12 +436,14 @@ Execute `npx vitest run --reporter=default tests/transforms/ansiParser.performan
 ## Roadmap
 
 ### Phase 1 (P1) - ✅ Complete
+
 - Core CSI sequences
 - Basic SGR support
 - Terminal state management
 - Control character handling
 
 ### Phase 2 (P2) - ✅ Complete
+
 - UTF-8 and wide character support
 - DECSET/DECRST (mode 25)
 - RIS (full reset)
@@ -409,6 +453,7 @@ Execute `npx vitest run --reporter=default tests/transforms/ansiParser.performan
 - Performance optimizations
 
 ### Phase 3 (P3) - ✅ Complete
+
 - **256-Color Support (SGR 38;5 and 48;5)**:
   - `CSI 38 ; 5 ; n m` - Set foreground to 256-color palette
   - `CSI 48 ; 5 ; n m` - Set background to 256-color palette
@@ -440,6 +485,7 @@ Execute `npx vitest run --reporter=default tests/transforms/ansiParser.performan
   - Deterministic test coverage for all sequences
 
 ### Phase 4 (P4) - Planned
+
 - **Additional CSI sequences**:
   - ICH, DCH, IL, DL (insert/delete)
 - **Enhanced scrollback**:
@@ -450,6 +496,7 @@ Execute `npx vitest run --reporter=default tests/transforms/ansiParser.performan
   - Lazy rendering integration
 
 ### Future
+
 - xterm.js compatibility layer
 - VT100/VT220 test suite compliance
 - Terminal capability negotiation (terminfo)
@@ -467,7 +514,7 @@ const parser = new AnsiParser({ scrollbackLimit: 5000 });
 
 ptyStream.on('data', (chunk) => {
   const events = parser.parse(chunk.toString());
-  
+
   for (const event of events) {
     switch (event.type) {
       case 'print':
diff --git a/docs/rfcs/stream-kernel/external-wrapper-sprints.md b/docs/rfcs/stream-kernel/external-wrapper-sprints.md
index d32e5b7..dd23425 100644
--- a/docs/rfcs/stream-kernel/external-wrapper-sprints.md
+++ b/docs/rfcs/stream-kernel/external-wrapper-sprints.md
@@ -13,16 +13,16 @@ This document outlines the implementation sprints for the External Server Wrappe
 
 ## Sprint Overview
 
-| Sprint | Duration | Focus Area | Key Deliverables |
-|--------|----------|------------|------------------|
-| 1 | 5-7 days | External Wrapper Core | `ExternalServerWrapper` base class, Hostess registration |
-| 2 | 5-7 days | PTY Wrapper Foundation | `PTYServerWrapper`, node-pty integration, basic passthrough |
-| 3 | 5-7 days | Multi-Modal Output Foundation | Passthrough renderer, ANSI parser, split() integration |
-| 4 | 7-10 days | Advanced Renderers | TTS, MP4, MCP, Screenshot, WebRTC renderers |
-| 5 | 5-7 days | npm Package Integration | npm wrapper patterns, dependency management, examples |
-| 6 | 5-7 days | C Program/Binary Wrappers | C program patterns, executable discovery, cross-platform |
-| 7 | 5-7 days | Process Lifecycle & Supervision | Health monitoring, restart policies, graceful shutdown |
-| 8 | 5-7 days | Protocol Translation (Optional) | Translation layer framework, standard adapters |
+| Sprint | Duration  | Focus Area                      | Key Deliverables                                            |
+| ------ | --------- | ------------------------------- | ----------------------------------------------------------- |
+| 1      | 5-7 days  | External Wrapper Core           | `ExternalServerWrapper` base class, Hostess registration    |
+| 2      | 5-7 days  | PTY Wrapper Foundation          | `PTYServerWrapper`, node-pty integration, basic passthrough |
+| 3      | 5-7 days  | Multi-Modal Output Foundation   | Passthrough renderer, ANSI parser, split() integration      |
+| 4      | 7-10 days | Advanced Renderers              | TTS, MP4, MCP, Screenshot, WebRTC renderers                 |
+| 5      | 5-7 days  | npm Package Integration         | npm wrapper patterns, dependency management, examples       |
+| 6      | 5-7 days  | C Program/Binary Wrappers       | C program patterns, executable discovery, cross-platform    |
+| 7      | 5-7 days  | Process Lifecycle & Supervision | Health monitoring, restart policies, graceful shutdown      |
+| 8      | 5-7 days  | Protocol Translation (Optional) | Translation layer framework, standard adapters              |
 
 ## Sprint 1: External Wrapper Core
 
@@ -30,6 +30,7 @@ This document outlines the implementation sprints for the External Server Wrappe
 **Goal:** Implement basic external server wrapper with Hostess registration
 
 ### Prerequisites
+
 - Core kernel implemented (RFC 02)
 - Executor server implemented (RFC 10)
 - Hostess server implemented (RFC 08)
@@ -37,6 +38,7 @@ This document outlines the implementation sprints for the External Server Wrappe
 ### Deliverables
 
 #### 1. `ExternalServerWrapper` Base Class
+
 ```typescript
 // src/wrappers/ExternalServerWrapper.ts
 export class ExternalServerWrapper implements Server {
@@ -44,38 +46,52 @@ export class ExternalServerWrapper implements Server {
   outputPipe: Pipe;
   manifest: ServerManifest;
   private process: ChildProcess | null = null;
-  
+
   constructor(kernel: Kernel, manifest: ServerManifest) {
     this.inputPipe = kernel.createPipe();
     this.outputPipe = kernel.createPipe();
     this.manifest = manifest;
   }
-  
-  async spawn(): Promise<void> { /* ... */ }
-  async shutdown(): Promise<void> { /* ... */ }
-  async restart(): Promise<void> { /* ... */ }
-  isRunning(): boolean { /* ... */ }
-  getProcessInfo(): ProcessInfo { /* ... */ }
+
+  async spawn(): Promise<void> {
+    /* ... */
+  }
+  async shutdown(): Promise<void> {
+    /* ... */
+  }
+  async restart(): Promise<void> {
+    /* ... */
+  }
+  isRunning(): boolean {
+    /* ... */
+  }
+  getProcessInfo(): ProcessInfo {
+    /* ... */
+  }
 }
 ```
 
 #### 2. Environment Variable & CLI Argument Handling
-- Standard environment variables (MKOLBOL_*)
+
+- Standard environment variables (MKOLBOL\_\*)
 - Template string replacement in arguments
 - Environment variable merging with user-provided values
 
 #### 3. Simple stdio Wrapping
+
 - Non-PTY process spawning
 - stdin/stdout/stderr pipe connections
 - Process exit handling
 
 #### 4. Hostess Registration
+
 - Server manifest format
 - Registration on spawn
 - Heartbeat mechanism
 - Deregistration on shutdown
 
 #### 5. Server Manifest Schema
+
 ```typescript
 interface ServerManifest {
   name: string;
@@ -97,6 +113,7 @@ interface ServerManifest {
 ```
 
 ### Unit Tests
+
 ```typescript
 describe('ExternalServerWrapper', () => {
   it('should spawn external process');
@@ -110,6 +127,7 @@ describe('ExternalServerWrapper', () => {
 ```
 
 ### Integration Tests
+
 ```typescript
 describe('ExternalServerWrapper Integration', () => {
   it('should register with Hostess on spawn');
@@ -120,6 +138,7 @@ describe('ExternalServerWrapper Integration', () => {
 ```
 
 ### Success Criteria
+
 - ✅ Wrap a simple Node.js script that reads/writes stdio
 - ✅ Script registers with Hostess automatically
 - ✅ Environment variables passed correctly
@@ -129,13 +148,14 @@ describe('ExternalServerWrapper Integration', () => {
 - ✅ All integration tests passing
 
 ### Example Usage
+
 ```typescript
 const wrapper = new ExternalServerWrapper(kernel, {
   name: 'echo-server',
   command: 'cat',
   args: [],
   ioMode: 'stdio',
-  env: { LOG_LEVEL: 'info' }
+  env: { LOG_LEVEL: 'info' },
 });
 
 await wrapper.spawn();
@@ -151,41 +171,53 @@ wrapper.inputPipe.write('Hello, World!');
 **Goal:** Implement PTY wrapper for interactive terminal applications
 
 ### Prerequisites
+
 - Sprint 1 completed (ExternalServerWrapper)
 - node-pty package installed
 
 ### Deliverables
 
 #### 1. `PTYServerWrapper` Class
+
 ```typescript
 // src/wrappers/PTYServerWrapper.ts
 export class PTYServerWrapper extends ExternalServerWrapper {
   ptyProcess: IPty;
   terminalSize: { cols: number; rows: number };
-  
-  async spawn(): Promise<void> { /* ... */ }
-  resize(cols: number, rows: number): void { /* ... */ }
-  sendSignal(signal: string): void { /* ... */ }
+
+  async spawn(): Promise<void> {
+    /* ... */
+  }
+  resize(cols: number, rows: number): void {
+    /* ... */
+  }
+  sendSignal(signal: string): void {
+    /* ... */
+  }
 }
 ```
 
 #### 2. node-pty Integration
+
 - PTY process spawning
 - Terminal type configuration (xterm-256color)
 - Initial terminal size
 - Character encoding (utf8/binary)
 
 #### 3. Basic ANSI Passthrough (tmux-like)
+
 - Raw ANSI data piping
 - No parsing or interpretation
 - Direct stdout rendering
 
 #### 4. Terminal Resize Handling
+
 - SIGWINCH signal handling
 - Dynamic resize via `ptyProcess.resize()`
 - Resize event propagation to renderers
 
 #### 5. PTY Manifest Extensions
+
 ```typescript
 interface PTYManifest extends ServerManifest {
   ioMode: 'pty';
@@ -200,6 +232,7 @@ interface PTYManifest extends ServerManifest {
 ```
 
 ### Unit Tests
+
 ```typescript
 describe('PTYServerWrapper', () => {
   it('should spawn PTY process');
@@ -211,6 +244,7 @@ describe('PTYServerWrapper', () => {
 ```
 
 ### Integration Tests
+
 ```typescript
 describe('PTYServerWrapper Integration', () => {
   it('should register PTY server with Hostess');
@@ -220,6 +254,7 @@ describe('PTYServerWrapper Integration', () => {
 ```
 
 ### Success Criteria
+
 - ✅ Wrap bash in PTY
 - ✅ Keyboard input → wrapper → shell works
 - ✅ Shell output → wrapper → screen works
@@ -230,6 +265,7 @@ describe('PTYServerWrapper Integration', () => {
 - ✅ All integration tests passing
 
 ### Example Usage
+
 ```typescript
 const bashPTY = new PTYServerWrapper(kernel, {
   name: 'bash-session',
@@ -237,7 +273,7 @@ const bashPTY = new PTYServerWrapper(kernel, {
   terminalType: 'xterm-256color',
   initialCols: 80,
   initialRows: 24,
-  ioMode: 'pty'
+  ioMode: 'pty',
 });
 
 await bashPTY.spawn();
@@ -258,17 +294,19 @@ kernel.connect(bashPTY.output, screen.input);
 **Goal:** Enable splitting PTY output to multiple renderers
 
 ### Prerequisites
+
 - Sprint 2 completed (PTYServerWrapper)
 - Kernel's split() primitive implemented
 
 ### Deliverables
 
 #### 1. Passthrough Renderer
+
 ```typescript
 // src/renderers/PassthroughRenderer.ts
 export class PassthroughRenderer {
   inputPipe: Pipe;
-  
+
   constructor(kernel: Kernel) {
     this.inputPipe = kernel.createPipe();
     this.inputPipe.on('data', (data) => {
@@ -279,6 +317,7 @@ export class PassthroughRenderer {
 ```
 
 #### 2. ANSI Parser Module
+
 ```typescript
 // src/parsers/ANSIParser.ts
 export class ANSIParser {
@@ -289,11 +328,12 @@ export class ANSIParser {
 ```
 
 #### 3. Logger Renderer
+
 ```typescript
 // src/renderers/LoggerRenderer.ts
 export class LoggerRenderer {
   inputPipe: Pipe;
-  
+
   constructor(kernel: Kernel, logFile: string) {
     this.inputPipe = kernel.createPipe();
     this.inputPipe.on('data', (data) => {
@@ -304,11 +344,13 @@ export class LoggerRenderer {
 ```
 
 #### 4. Split Integration Examples
+
 - One PTY → multiple renderers
 - Example: bash → [passthrough, logger]
 - Example: vim → [passthrough, recorder]
 
 #### 5. Terminal State Tracking
+
 ```typescript
 interface TerminalState {
   cells: Cell[][];
@@ -323,6 +365,7 @@ interface TerminalState {
 ```
 
 ### Unit Tests
+
 ```typescript
 describe('PassthroughRenderer', () => {
   it('should render raw ANSI to stdout');
@@ -342,6 +385,7 @@ describe('LoggerRenderer', () => {
 ```
 
 ### Integration Tests
+
 ```typescript
 describe('Multi-Modal Output', () => {
   it('should split PTY output to 2+ renderers');
@@ -351,6 +395,7 @@ describe('Multi-Modal Output', () => {
 ```
 
 ### Success Criteria
+
 - ✅ One PTY source fans out to multiple renderers using split()
 - ✅ Passthrough renderer works correctly
 - ✅ Logger renderer captures all output
@@ -360,23 +405,21 @@ describe('Multi-Modal Output', () => {
 - ✅ All integration tests passing
 
 ### Example Usage
+
 ```typescript
 const kernel = new Kernel();
 
 const bashPTY = new PTYServerWrapper(kernel, {
   name: 'bash',
   shell: 'bash',
-  ioMode: 'pty'
+  ioMode: 'pty',
 });
 
 const passthrough = new PassthroughRenderer(kernel);
 const logger = new LoggerRenderer(kernel, '/tmp/session.log');
 
 // Split output to both renderers
-kernel.split(bashPTY.output, [
-  passthrough.input,
-  logger.input
-]);
+kernel.split(bashPTY.output, [passthrough.input, logger.input]);
 
 await bashPTY.spawn();
 // Now bash output goes to screen AND log file
@@ -390,26 +433,35 @@ await bashPTY.spawn();
 **Goal:** Implement TTS, MP4, MCP, Screenshot, and WebRTC renderers
 
 ### Prerequisites
+
 - Sprint 3 completed (Multi-Modal Output Foundation)
 - ANSI parser implemented
 
 ### Deliverables
 
 #### 1. Text-to-Speech Renderer
+
 ```typescript
 // src/renderers/TextToSpeechRenderer.ts
 export class TextToSpeechRenderer {
   inputPipe: Pipe;
   private parser: ANSIParser;
   private prevState: TerminalState;
-  
-  constructor(kernel: Kernel, options: TTSOptions) { /* ... */ }
-  private detectChanges(prev: TerminalState, curr: TerminalState) { /* ... */ }
-  private speak(text: string): void { /* ... */ }
+
+  constructor(kernel: Kernel, options: TTSOptions) {
+    /* ... */
+  }
+  private detectChanges(prev: TerminalState, curr: TerminalState) {
+    /* ... */
+  }
+  private speak(text: string): void {
+    /* ... */
+  }
 }
 ```
 
 **Features:**
+
 - Detect text changes in terminal
 - Describe cursor movements
 - Read menu changes aloud
@@ -417,21 +469,31 @@ export class TextToSpeechRenderer {
 - Configurable verbosity
 
 #### 2. MP4 Recorder
+
 ```typescript
 // src/renderers/MP4Recorder.ts
 export class MP4Recorder {
   inputPipe: Pipe;
   private canvas: OffscreenCanvas;
   private encoder: VideoEncoder;
-  
-  constructor(kernel: Kernel, options: MP4Options) { /* ... */ }
-  private renderToCanvas(state: TerminalState): void { /* ... */ }
-  private captureFrame(): void { /* ... */ }
-  async save(filename: string): Promise<void> { /* ... */ }
+
+  constructor(kernel: Kernel, options: MP4Options) {
+    /* ... */
+  }
+  private renderToCanvas(state: TerminalState): void {
+    /* ... */
+  }
+  private captureFrame(): void {
+    /* ... */
+  }
+  async save(filename: string): Promise<void> {
+    /* ... */
+  }
 }
 ```
 
 **Features:**
+
 - Render ANSI to off-screen canvas
 - Capture frames at configurable FPS (default: 30)
 - Encode as H.264/MP4
@@ -439,21 +501,31 @@ export class MP4Recorder {
 - Configurable resolution
 
 #### 3. MCP Renderer (LLM-Friendly)
+
 ```typescript
 // src/renderers/MCPRenderer.ts
 export class MCPRenderer {
   inputPipe: Pipe;
   outputPipe: Pipe;
   private parser: ANSIParser;
-  
-  constructor(kernel: Kernel) { /* ... */ }
-  private formatForLLM(state: TerminalState): any { /* ... */ }
-  private extractPlainText(state: TerminalState): string { /* ... */ }
-  private detectSections(state: TerminalState): Section[] { /* ... */ }
+
+  constructor(kernel: Kernel) {
+    /* ... */
+  }
+  private formatForLLM(state: TerminalState): any {
+    /* ... */
+  }
+  private extractPlainText(state: TerminalState): string {
+    /* ... */
+  }
+  private detectSections(state: TerminalState): Section[] {
+    /* ... */
+  }
 }
 ```
 
 **Features:**
+
 - Strip ANSI codes
 - Extract plain text
 - Detect UI sections (menu, status bar, content)
@@ -462,19 +534,27 @@ export class MCPRenderer {
 - JSON output format
 
 #### 4. Screenshot Renderer
+
 ```typescript
 // src/renderers/ScreenshotRenderer.ts
 export class ScreenshotRenderer {
   inputPipe: Pipe;
   private canvas: OffscreenCanvas;
-  
-  constructor(kernel: Kernel, options: ScreenshotOptions) { /* ... */ }
-  async captureScreenshot(): Promise<Buffer> { /* ... */ }
-  async saveScreenshot(filename: string): Promise<void> { /* ... */ }
+
+  constructor(kernel: Kernel, options: ScreenshotOptions) {
+    /* ... */
+  }
+  async captureScreenshot(): Promise<Buffer> {
+    /* ... */
+  }
+  async saveScreenshot(filename: string): Promise<void> {
+    /* ... */
+  }
 }
 ```
 
 **Features:**
+
 - Capture terminal state as PNG
 - Manual or periodic screenshots
 - Configurable interval
@@ -482,20 +562,28 @@ export class ScreenshotRenderer {
 - Multiple format support (PNG, JPEG)
 
 #### 5. WebRTC Renderer
+
 ```typescript
 // src/renderers/WebRTCRenderer.ts
 export class WebRTCRenderer {
   inputPipe: Pipe;
   private peerConnection: RTCPeerConnection;
   private canvas: OffscreenCanvas;
-  
-  constructor(kernel: Kernel) { /* ... */ }
-  private renderToCanvas(state: TerminalState): void { /* ... */ }
-  async connect(remoteOffer: RTCSessionDescriptionInit): Promise<RTCSessionDescriptionInit> { /* ... */ }
+
+  constructor(kernel: Kernel) {
+    /* ... */
+  }
+  private renderToCanvas(state: TerminalState): void {
+    /* ... */
+  }
+  async connect(remoteOffer: RTCSessionDescriptionInit): Promise<RTCSessionDescriptionInit> {
+    /* ... */
+  }
 }
 ```
 
 **Features:**
+
 - Stream terminal to remote viewers
 - Real-time rendering
 - Low latency (target: <100ms)
@@ -503,6 +591,7 @@ export class WebRTCRenderer {
 - STUN/TURN server integration
 
 ### Unit Tests
+
 ```typescript
 describe('TextToSpeechRenderer', () => {
   it('should detect text changes');
@@ -534,6 +623,7 @@ describe('WebRTCRenderer', () => {
 ```
 
 ### Integration Tests
+
 ```typescript
 describe('Advanced Renderers Integration', () => {
   it('should use Claude Code with all renderers simultaneously');
@@ -543,6 +633,7 @@ describe('Advanced Renderers Integration', () => {
 ```
 
 ### Success Criteria
+
 - ✅ Claude Code wrapper → [passthrough, TTS, MP4, MCP] all working
 - ✅ TTS describes UI changes audibly
 - ✅ MP4 records full session as video
@@ -554,6 +645,7 @@ describe('Advanced Renderers Integration', () => {
 - ✅ All integration tests passing
 
 ### Example Usage
+
 ```typescript
 const kernel = new Kernel();
 
@@ -563,7 +655,7 @@ const claudeCode = new PTYServerWrapper(kernel, {
   terminalType: 'xterm-256color',
   initialCols: 120,
   initialRows: 40,
-  ioMode: 'pty'
+  ioMode: 'pty',
 });
 
 // All renderers
@@ -574,13 +666,7 @@ const mcp = new MCPRenderer(kernel);
 const webrtc = new WebRTCRenderer(kernel);
 
 // Split to all renderers
-kernel.split(claudeCode.output, [
-  passthrough.input,
-  tts.input,
-  mp4.input,
-  mcp.input,
-  webrtc.input
-]);
+kernel.split(claudeCode.output, [passthrough.input, tts.input, mp4.input, mcp.input, webrtc.input]);
 
 await claudeCode.spawn();
 
@@ -600,11 +686,13 @@ await claudeCode.spawn();
 **Goal:** Define patterns for wrapping npm packages as servers
 
 ### Prerequisites
+
 - Sprint 1 completed (ExternalServerWrapper)
 
 ### Deliverables
 
 #### 1. npm Wrapper Patterns Documentation
+
 - How to wrap npm CLI tools
 - How to wrap npm servers
 - Package discovery (node_modules/.bin)
@@ -612,7 +700,9 @@ await claudeCode.spawn();
 - Environment setup
 
 #### 2. npm CLI Tool Example
+
 Wrap an existing npm CLI tool:
+
 ```typescript
 const cliWrapper = new ExternalServerWrapper(kernel, {
   name: 'prettier-server',
@@ -620,12 +710,14 @@ const cliWrapper = new ExternalServerWrapper(kernel, {
   args: ['node_modules/.bin/prettier', '--stdin-filepath', 'file.js'],
   env: {},
   cwd: process.cwd(),
-  ioMode: 'stdio'
+  ioMode: 'stdio',
 });
 ```
 
 #### 3. npm Server Example
+
 Wrap an npm package that provides a server:
+
 ```typescript
 const sqlServer = new ExternalServerWrapper(kernel, {
   name: 'sqlite-server',
@@ -633,23 +725,25 @@ const sqlServer = new ExternalServerWrapper(kernel, {
   args: ['node_modules/.bin/sqlite-server', '--db', 'data.db'],
   env: {
     MAX_CONNECTIONS: '10',
-    LOG_LEVEL: 'info'
+    LOG_LEVEL: 'info',
   },
   cwd: '/opt/db',
   ioMode: 'stdio',
   terminals: [
     { name: 'query', direction: 'input', protocol: 'sql' },
-    { name: 'results', direction: 'output', protocol: 'json' }
-  ]
+    { name: 'results', direction: 'output', protocol: 'json' },
+  ],
 });
 ```
 
 #### 4. Package.json Integration
+
 - How to declare wrapper as dependency
 - How to include in build process
 - How to distribute wrapped servers
 
 #### 5. Wrapper Factory Pattern
+
 ```typescript
 class NPMWrapperFactory {
   static createWrapper(packageName: string, config: NPMWrapperConfig): ExternalServerWrapper {
@@ -659,19 +753,21 @@ class NPMWrapperFactory {
       command: 'node',
       args: [binPath, ...config.args],
       env: config.env,
-      ioMode: config.ioMode || 'stdio'
+      ioMode: config.ioMode || 'stdio',
     });
   }
 }
 ```
 
 ### Documentation Deliverables
+
 - `docs/guides/wrapping-npm-packages.md`
 - Example: Wrapping prettier
 - Example: Wrapping a SQL server npm package
 - Example: Wrapping a REST API npm package
 
 ### Success Criteria
+
 - ✅ Third-party npm package runs as first-class mkolbol server
 - ✅ Wrapper discovers package in node_modules
 - ✅ Dependencies resolved correctly
@@ -680,6 +776,7 @@ class NPMWrapperFactory {
 - ✅ Wrapper factory pattern working
 
 ### Example npm Packages to Wrap
+
 1. **prettier** (CLI tool)
 2. **better-sqlite3** (database)
 3. **express** (web server)
@@ -694,18 +791,22 @@ class NPMWrapperFactory {
 **Goal:** Define patterns for wrapping C programs and arbitrary binaries
 
 ### Prerequisites
+
 - Sprint 1 completed (ExternalServerWrapper)
 
 ### Deliverables
 
 #### 1. C Program Wrapper Patterns Documentation
+
 - Executable discovery (PATH, absolute paths)
 - Library dependency handling (LD_LIBRARY_PATH)
 - Cross-platform considerations
 - Binary permissions
 
 #### 2. Simple C Program Example
+
 Wrap a simple C program:
+
 ```typescript
 const catWrapper = new ExternalServerWrapper(kernel, {
   name: 'cat-server',
@@ -713,51 +814,62 @@ const catWrapper = new ExternalServerWrapper(kernel, {
   args: [],
   env: {},
   cwd: '/tmp',
-  ioMode: 'stdio'
+  ioMode: 'stdio',
 });
 ```
 
 #### 3. ImageMagick Example
+
 Wrap ImageMagick for image processing:
+
 ```typescript
 const imageProcessor = new ExternalServerWrapper(kernel, {
   name: 'image-processor',
   command: '/usr/bin/convert',
   args: [
-    '-',              // Read from stdin
-    '-resize', '800x600',
-    '-quality', '85',
-    'png:-'          // Write to stdout
+    '-', // Read from stdin
+    '-resize',
+    '800x600',
+    '-quality',
+    '85',
+    'png:-', // Write to stdout
   ],
   env: {},
   cwd: '/tmp',
   ioMode: 'stdio',
   terminals: [
     { name: 'input', direction: 'input', protocol: 'image-binary' },
-    { name: 'output', direction: 'output', protocol: 'image-binary' }
-  ]
+    { name: 'output', direction: 'output', protocol: 'image-binary' },
+  ],
 });
 ```
 
 #### 4. ffmpeg Example
+
 Wrap ffmpeg for video processing:
+
 ```typescript
 const ffmpegWrapper = new ExternalServerWrapper(kernel, {
   name: 'video-transcoder',
   command: '/usr/bin/ffmpeg',
   args: [
-    '-i', 'pipe:0',           // Read from stdin
-    '-c:v', 'libx264',
-    '-preset', 'fast',
-    '-f', 'mp4',
-    'pipe:1'                  // Write to stdout
+    '-i',
+    'pipe:0', // Read from stdin
+    '-c:v',
+    'libx264',
+    '-preset',
+    'fast',
+    '-f',
+    'mp4',
+    'pipe:1', // Write to stdout
   ],
   env: {},
-  ioMode: 'stdio'
+  ioMode: 'stdio',
 });
 ```
 
 #### 5. Executable Discovery Utility
+
 ```typescript
 class ExecutableDiscovery {
   static findExecutable(name: string): string | null {
@@ -775,6 +887,7 @@ class ExecutableDiscovery {
 ```
 
 ### Documentation Deliverables
+
 - `docs/guides/wrapping-c-programs.md`
 - Example: Wrapping cat/grep/sed
 - Example: Wrapping ImageMagick
@@ -782,6 +895,7 @@ class ExecutableDiscovery {
 - Cross-platform guide (Linux/macOS/Windows)
 
 ### Success Criteria
+
 - ✅ Arbitrary C executable runs as first-class mkolbol server
 - ✅ Executable discovery works
 - ✅ Library dependencies handled
@@ -790,6 +904,7 @@ class ExecutableDiscovery {
 - ✅ Examples for various C programs working
 
 ### Example C Programs to Wrap
+
 1. **cat/grep/sed** (text processing)
 2. **ImageMagick** (image processing)
 3. **ffmpeg** (video processing)
@@ -804,12 +919,14 @@ class ExecutableDiscovery {
 **Goal:** Implement health monitoring, restart policies, and supervision
 
 ### Prerequisites
+
 - Sprint 1 completed (ExternalServerWrapper)
 - Executor server implemented
 
 ### Deliverables
 
 #### 1. Health Monitoring
+
 ```typescript
 class HealthMonitor {
   checkHealth(wrapper: ExternalServerWrapper): HealthStatus {
@@ -819,53 +936,54 @@ class HealthMonitor {
       uptime: wrapper.getProcessInfo().uptime,
       memoryUsage: wrapper.getProcessInfo().memoryUsage,
       cpuUsage: wrapper.getProcessInfo().cpuUsage,
-      healthy: this.isHealthy(wrapper)
+      healthy: this.isHealthy(wrapper),
     };
   }
-  
+
   private isHealthy(wrapper: ExternalServerWrapper): boolean {
     // Custom health check logic
-    return wrapper.isRunning() && 
-           wrapper.getProcessInfo().uptime > 0;
+    return wrapper.isRunning() && wrapper.getProcessInfo().uptime > 0;
   }
 }
 ```
 
 #### 2. Restart Policies
+
 ```typescript
 class RestartPolicy {
   shouldRestart(wrapper: ExternalServerWrapper, exitCode: number): boolean {
     const { restart, restartCount, maxRestarts } = wrapper.manifest;
-    
+
     if (restart === 'never') return false;
     if (restart === 'always') return restartCount < maxRestarts;
     if (restart === 'on-failure') {
       return exitCode !== 0 && restartCount < maxRestarts;
     }
-    
+
     return false;
   }
 }
 ```
 
 #### 3. Graceful Shutdown
+
 ```typescript
 class ExternalServerWrapper {
   async shutdown(timeout: number = 5000): Promise<void> {
     if (!this.isRunning()) return;
-    
+
     // Try graceful shutdown first (SIGTERM)
     this.sendSignal('SIGTERM');
-    
+
     // Wait for process to exit
     const exited = await this.waitForExit(timeout);
-    
+
     if (!exited) {
       // Force kill (SIGKILL)
       this.sendSignal('SIGKILL');
       await this.waitForExit(1000);
     }
-    
+
     // Deregister from Hostess
     await this.deregisterFromHostess();
   }
@@ -873,38 +991,39 @@ class ExternalServerWrapper {
 ```
 
 #### 4. Supervisor Module
+
 ```typescript
 class Supervisor {
   private wrappers: Map<string, ExternalServerWrapper> = new Map();
   private healthMonitor: HealthMonitor;
   private restartPolicy: RestartPolicy;
-  
+
   constructor(kernel: Kernel) {
     this.healthMonitor = new HealthMonitor();
     this.restartPolicy = new RestartPolicy();
-    
+
     // Check health periodically
     setInterval(() => this.checkAllHealth(), 5000);
   }
-  
+
   register(wrapper: ExternalServerWrapper): void {
     this.wrappers.set(wrapper.manifest.uuid, wrapper);
   }
-  
+
   private async checkAllHealth(): Promise<void> {
     for (const [uuid, wrapper] of this.wrappers) {
       const health = this.healthMonitor.checkHealth(wrapper);
-      
+
       if (!health.healthy) {
         console.log(`Wrapper ${wrapper.manifest.name} unhealthy, considering restart...`);
-        
+
         if (this.restartPolicy.shouldRestart(wrapper, health.exitCode || 0)) {
           await this.restart(wrapper);
         }
       }
     }
   }
-  
+
   private async restart(wrapper: ExternalServerWrapper): Promise<void> {
     console.log(`Restarting ${wrapper.manifest.name}...`);
     await wrapper.restart();
@@ -913,16 +1032,17 @@ class Supervisor {
 ```
 
 #### 5. Integration with Executor
+
 ```typescript
 class Executor {
   private supervisor: Supervisor;
-  
+
   constructor(kernel: Kernel, hostess: Hostess) {
     this.kernel = kernel;
     this.hostess = hostess;
     this.supervisor = new Supervisor(kernel);
   }
-  
+
   async spawnWrapper(wrapper: ExternalServerWrapper): Promise<void> {
     await wrapper.spawn();
     await this.hostess.register(wrapper.manifest);
@@ -932,6 +1052,7 @@ class Executor {
 ```
 
 ### Unit Tests
+
 ```typescript
 describe('HealthMonitor', () => {
   it('should check wrapper health');
@@ -953,6 +1074,7 @@ describe('Supervisor', () => {
 ```
 
 ### Success Criteria
+
 - ✅ Wrapped process crashes → auto-restarts → Hostess re-registration
 - ✅ Health monitoring detects unhealthy processes
 - ✅ Restart policies work correctly (always, on-failure, never)
@@ -962,6 +1084,7 @@ describe('Supervisor', () => {
 - ✅ All unit tests passing
 
 ### Example Usage
+
 ```typescript
 const wrapper = new ExternalServerWrapper(kernel, {
   name: 'unstable-server',
@@ -969,7 +1092,7 @@ const wrapper = new ExternalServerWrapper(kernel, {
   args: ['app.js'],
   restart: 'on-failure',
   restartDelay: 5000,
-  maxRestarts: 3
+  maxRestarts: 3,
 });
 
 const supervisor = new Supervisor(kernel);
@@ -987,11 +1110,13 @@ supervisor.register(wrapper);
 **Goal:** Build framework for protocol translation layers
 
 ### Prerequisites
+
 - Sprint 1 completed (ExternalServerWrapper)
 
 ### Deliverables
 
 #### 1. Translation Layer Interface
+
 ```typescript
 interface Translator {
   toExternal(mkolbolData: any): any;
@@ -1003,17 +1128,17 @@ class TranslationLayer {
   outputPipe: Pipe;
   private externalWrapper: ExternalServerWrapper;
   private translator: Translator;
-  
+
   constructor(wrapper: ExternalServerWrapper, translator: Translator) {
     this.externalWrapper = wrapper;
     this.translator = translator;
-    
+
     // mkolbol → external
     this.inputPipe.on('data', (data) => {
       const translated = this.translator.toExternal(data);
       wrapper.inputPipe.write(translated);
     });
-    
+
     // external → mkolbol
     wrapper.outputPipe.on('data', (data) => {
       const translated = this.translator.fromExternal(data);
@@ -1024,12 +1149,13 @@ class TranslationLayer {
 ```
 
 #### 2. JSON Translator
+
 ```typescript
 class JSONTranslator implements Translator {
   toExternal(mkolbolData: any): string {
     return JSON.stringify(mkolbolData);
   }
-  
+
   fromExternal(externalData: Buffer): any {
     return JSON.parse(externalData.toString());
   }
@@ -1037,61 +1163,66 @@ class JSONTranslator implements Translator {
 ```
 
 #### 3. HTTP Translator
+
 ```typescript
 class HTTPTranslator implements Translator {
   toExternal(mkolbolData: any): string {
     // Convert mkolbol message to HTTP request
-    return `POST / HTTP/1.1\r\n` +
-           `Content-Type: application/json\r\n` +
-           `Content-Length: ${JSON.stringify(mkolbolData.body).length}\r\n` +
-           `\r\n` +
-           JSON.stringify(mkolbolData.body);
+    return (
+      `POST / HTTP/1.1\r\n` +
+      `Content-Type: application/json\r\n` +
+      `Content-Length: ${JSON.stringify(mkolbolData.body).length}\r\n` +
+      `\r\n` +
+      JSON.stringify(mkolbolData.body)
+    );
   }
-  
+
   fromExternal(externalData: Buffer): any {
     // Parse HTTP response
     const response = this.parseHTTPResponse(externalData.toString());
     return {
       statusCode: response.statusCode,
       headers: response.headers,
-      body: JSON.parse(response.body)
+      body: JSON.parse(response.body),
     };
   }
 }
 ```
 
 #### 4. SQL Translator
+
 ```typescript
 class SQLTranslator implements Translator {
   toExternal(mkolbolData: any): string {
     // Convert mkolbol query to SQL
     return mkolbolData.query;
   }
-  
+
   fromExternal(externalData: Buffer): any {
     // Parse SQL result
     return {
       rows: this.parseResults(externalData),
-      rowCount: this.countRows(externalData)
+      rowCount: this.countRows(externalData),
     };
   }
 }
 ```
 
 #### 5. Protobuf Translator
+
 ```typescript
 class ProtobufTranslator implements Translator {
   private schema: any;
-  
+
   constructor(schemaPath: string) {
     this.schema = this.loadSchema(schemaPath);
   }
-  
+
   toExternal(mkolbolData: any): Buffer {
     // Encode as protobuf
     return this.schema.encode(mkolbolData);
   }
-  
+
   fromExternal(externalData: Buffer): any {
     // Decode protobuf
     return this.schema.decode(externalData);
@@ -1100,12 +1231,14 @@ class ProtobufTranslator implements Translator {
 ```
 
 ### Documentation Deliverables
+
 - `docs/guides/protocol-translation.md`
 - Example: Wrapping REST API as stream server
 - Example: Wrapping database with custom protocol
 - Example: Wrapping gRPC service
 
 ### Unit Tests
+
 ```typescript
 describe('TranslationLayer', () => {
   it('should translate bidirectionally');
@@ -1124,6 +1257,7 @@ describe('HTTPTranslator', () => {
 ```
 
 ### Success Criteria
+
 - ✅ HTTP API wrapped as stream server with translation
 - ✅ Translation layer transparent to other servers
 - ✅ Standard translators work correctly
@@ -1132,6 +1266,7 @@ describe('HTTPTranslator', () => {
 - ✅ All unit tests passing
 
 ### Example Usage
+
 ```typescript
 // Wrap REST API with translation
 const restAPI = new ExternalServerWrapper(kernel, {
@@ -1139,7 +1274,7 @@ const restAPI = new ExternalServerWrapper(kernel, {
   command: 'node',
   args: ['api-server.js'],
   env: { PORT: '3000' },
-  ioMode: 'socket'
+  ioMode: 'socket',
 });
 
 const httpTranslator = new HTTPTranslator();
@@ -1164,7 +1299,7 @@ graph TD
     S6[Sprint 6: C Programs]
     S7[Sprint 7: Lifecycle]
     S8[Sprint 8: Translation]
-    
+
     S1 --> S2
     S1 --> S5
     S1 --> S6
@@ -1177,6 +1312,7 @@ graph TD
 **Critical Path:** Sprint 1 → Sprint 2 → Sprint 3 → Sprint 4 (28-34 days)
 
 **Parallel Work Opportunities:**
+
 - Sprint 5 (npm) can start after Sprint 1
 - Sprint 6 (C programs) can start after Sprint 1
 - Sprint 7 (lifecycle) can start after Sprint 1
@@ -1219,26 +1355,31 @@ graph TD
 ## Success Metrics
 
 ### Sprint 1-2 (Core Functionality)
+
 - ✅ Wrap 3+ different external executables
 - ✅ All examples pass integration tests
 - ✅ Hostess registration working
 
 ### Sprint 3-4 (Multi-Modal)
+
 - ✅ Claude Code with 5 renderers simultaneously
 - ✅ No dropped frames/data
 - ✅ All renderers produce correct output
 
 ### Sprint 5-6 (Integration Patterns)
+
 - ✅ 5+ npm packages wrapped successfully
 - ✅ 5+ C programs wrapped successfully
 - ✅ Documentation clear and complete
 
 ### Sprint 7 (Reliability)
+
 - ✅ Process crashes recovered automatically
 - ✅ Health monitoring detects issues within 5s
 - ✅ Graceful shutdown completes within 5s
 
 ### Sprint 8 (Translation)
+
 - ✅ 3+ protocol translators working
 - ✅ Translation transparent to other servers
 - ✅ Custom translator framework usable
@@ -1248,18 +1389,21 @@ graph TD
 ## Post-Sprint Activities
 
 ### Documentation
+
 - Update main README with wrapper examples
 - Create quickstart guide
 - Write tutorial videos/screencasts
 - Document best practices
 
 ### Testing
+
 - Performance benchmarks
 - Load testing (many wrappers)
 - Cross-platform validation
 - Long-running stability tests
 
 ### Community
+
 - Blog posts about architecture
 - Conference talks
 - Open-source release
diff --git a/docs/rfcs/stream-kernel/worker-mode.md b/docs/rfcs/stream-kernel/worker-mode.md
index ab7af87..eaf415f 100644
--- a/docs/rfcs/stream-kernel/worker-mode.md
+++ b/docs/rfcs/stream-kernel/worker-mode.md
@@ -52,9 +52,9 @@ const { port1: outputPort1, port2: outputPort2 } = new MessageChannel();
 const worker = new Worker('./module.js', {
   workerData: {
     inputPort: inputPort2,
-    outputPort: outputPort2
+    outputPort: outputPort2,
   },
-  transferList: [inputPort2, outputPort2]
+  transferList: [inputPort2, outputPort2],
 });
 
 // Create pipes from main-thread ports
@@ -82,27 +82,27 @@ inputPipe.on('data', (data) => {
 
 ## Comparison: Worker vs Process Pipes
 
-| Feature | Worker Pipes (MessagePort) | Process Pipes (stdio) |
-|---------|---------------------------|------------------------|
-| **Transport** | Structured messages via `MessagePort` | Byte streams via stdin/stdout |
-| **Object Mode** | Native support (serialization via structured clone) | Requires manual serialization (JSON/msgpack) |
-| **Backpressure** | Protocol-level (`pause`/`resume` messages) | Native stream backpressure |
-| **Latency** | Lower (same process, shared memory for transferables) | Higher (IPC overhead, kernel involvement) |
-| **Isolation** | Shared memory space, lighter isolation | Full process isolation |
-| **Setup** | `MessageChannel` pair | `spawn()` with `stdio: ['pipe', 'pipe', 'pipe']` |
-| **Teardown** | `port.close()` | `process.kill()`, wait for exit |
+| Feature          | Worker Pipes (MessagePort)                            | Process Pipes (stdio)                            |
+| ---------------- | ----------------------------------------------------- | ------------------------------------------------ |
+| **Transport**    | Structured messages via `MessagePort`                 | Byte streams via stdin/stdout                    |
+| **Object Mode**  | Native support (serialization via structured clone)   | Requires manual serialization (JSON/msgpack)     |
+| **Backpressure** | Protocol-level (`pause`/`resume` messages)            | Native stream backpressure                       |
+| **Latency**      | Lower (same process, shared memory for transferables) | Higher (IPC overhead, kernel involvement)        |
+| **Isolation**    | Shared memory space, lighter isolation                | Full process isolation                           |
+| **Setup**        | `MessageChannel` pair                                 | `spawn()` with `stdio: ['pipe', 'pipe', 'pipe']` |
+| **Teardown**     | `port.close()`                                        | `process.kill()`, wait for exit                  |
 
 ### Process Pipe Example (External Module)
 
 ```typescript
 // Spawn external process with stdio pipes
 const process = spawn(command, args, {
-  stdio: ['pipe', 'pipe', 'pipe']
+  stdio: ['pipe', 'pipe', 'pipe'],
 });
 
 // Direct stream piping (Node.js native)
-inputPipe.pipe(process.stdin);     // Kernel → Process
-process.stdout.pipe(outputPipe);   // Process → Kernel
+inputPipe.pipe(process.stdin); // Kernel → Process
+process.stdout.pipe(outputPipe); // Process → Kernel
 
 // Native backpressure via Node.js streams
 // No explicit protocol needed
@@ -111,12 +111,14 @@ process.stdout.pipe(outputPipe);   // Process → Kernel
 ### Key Differences
 
 **Worker Pipes:**
+
 - Require explicit backpressure protocol (`pause`/`resume` messages)
 - Support structured clone for object mode (dates, typed arrays, etc.)
 - Lower overhead for high-frequency message passing
 - Automatic serialization of complex objects
 
 **Process Pipes:**
+
 - Native backpressure via kernel buffer management
 - Raw byte streams (Buffer by default)
 - Higher isolation and crash resilience
@@ -194,8 +196,8 @@ Process pipes use native Node.js stream backpressure:
 
 ```typescript
 // Node.js handles backpressure automatically
-inputPipe.pipe(process.stdin);        // Automatic pause/resume
-process.stdout.pipe(outputPipe);      // Automatic buffering
+inputPipe.pipe(process.stdin); // Automatic pause/resume
+process.stdout.pipe(outputPipe); // Automatic buffering
 
 // No explicit protocol needed
 // write() returns false when buffer is full
@@ -316,12 +318,14 @@ process.on('exit', (code, signal) => {
 ## Performance Characteristics
 
 ### Worker Pipes
+
 - **Throughput**: ~1M messages/sec (object mode)
 - **Latency**: <1ms (same process)
 - **Overhead**: Structured clone serialization
 - **Best for**: High-frequency, structured data
 
 ### Process Pipes
+
 - **Throughput**: ~100K messages/sec (depends on serialization)
 - **Latency**: 1-5ms (IPC overhead)
 - **Overhead**: Process spawn, context switches
@@ -330,12 +334,14 @@ process.on('exit', (code, signal) => {
 ## Use Cases
 
 ### When to Use Worker Pipes
+
 - Transform modules processing structured objects
 - High-frequency data pipelines
 - Shared memory via transferables (TypedArrays, ArrayBuffers)
 - Modules requiring thread-level isolation only
 
 ### When to Use Process Pipes
+
 - External executables (Python, Go, etc.)
 - Modules requiring full crash isolation
 - PTY-based modules (shells, editors)
@@ -344,6 +350,7 @@ process.on('exit', (code, signal) => {
 ## Implementation Status
 
 **Implemented:**
+
 - ✅ WorkerPipeAdapter (MessagePort Duplex)
 - ✅ Backpressure protocol (pause/resume)
 - ✅ Bidirectional data flow
@@ -352,6 +359,7 @@ process.on('exit', (code, signal) => {
 - ✅ Integration with Executor
 
 **Planned:**
+
 - ⏳ UnixPipeAdapter (Unix domain sockets)
 - ⏳ TCPPipeAdapter (TCP sockets)
 - ⏳ WebSocketPipeAdapter (browser support)
diff --git a/docs/testing/ci.md b/docs/testing/ci.md
index a097a82..3a88050 100644
--- a/docs/testing/ci.md
+++ b/docs/testing/ci.md
@@ -25,17 +25,20 @@ Tests are gated with environment flags to control experimental features:
 **Pool:** `--pool=threads` (vitest tinypool worker threads)
 
 **Excluded tests:**
+
 - `ptyServerWrapper.spec.ts` - Requires PTY isolation
 - `multiModalOutput.spec.ts` - Requires PTY
 - `endpointsList.spec.ts` - Requires process spawning
 - `processMode.spec.ts` - Requires process isolation
 
 **Run command:**
+
 ```bash
 npm run test:ci
 ```
 
 **Direct vitest command:**
+
 ```bash
 npx vitest run \
   --pool=threads \
@@ -44,6 +47,7 @@ npx vitest run \
 ```
 
 **Characteristics:**
+
 - Fast execution (parallel workers)
 - Shared process space (lighter weight)
 - Safe for pure functions, transforms, and kernel logic
@@ -58,6 +62,7 @@ npx vitest run \
 **Pool:** `--pool=forks --poolOptions.forks.singleFork=true`
 
 **Included tests:**
+
 - `tests/wrappers/ptyServerWrapper.spec.ts` - PTY wrapper lifecycle
 - `tests/integration/multiModalOutput.spec.ts` - PTY output parsing
 - `tests/integration/endpointsList.spec.ts` - Endpoint registration
@@ -66,11 +71,13 @@ npx vitest run \
 - `tests/integration/workerMode.spec.ts` - Worker threads (gated)
 
 **Run command:**
+
 ```bash
 npm run test:pty
 ```
 
 **Direct vitest command:**
+
 ```bash
 npx vitest run \
   --pool=forks \
@@ -85,6 +92,7 @@ npx vitest run \
 ```
 
 **Characteristics:**
+
 - Isolated process per test suite
 - Single fork mode (`singleFork=true`) prevents concurrency issues
 - Required for PTY (node-pty) which needs real process lifecycle
@@ -99,6 +107,7 @@ npx vitest run \
 **Purpose:** Enable Unix process adapter tests (pipes, PTY control, teardown).
 
 **Gated tests:**
+
 - `tests/integration/processUnix.spec.ts`
   - `UnixPipeAdapter` - stdio/stdout/stderr pipe lifecycle
   - `UnixControlAdapter` - PTY control (resize, signal)
@@ -110,6 +119,7 @@ npx vitest run \
   - Comparable scenarios
 
 **Usage:**
+
 ```bash
 # Run forks lane with process-mode (REQUIRED)
 npm run test:pty
@@ -122,6 +132,7 @@ MK_PROCESS_EXPERIMENTAL=1 npx vitest run \
 ```
 
 **Implementation:**
+
 ```typescript
 // Tests skip if gate is not set
 describe.skipIf(!process.env.MK_PROCESS_EXPERIMENTAL)('UnixPipeAdapter', () => {
@@ -130,6 +141,7 @@ describe.skipIf(!process.env.MK_PROCESS_EXPERIMENTAL)('UnixPipeAdapter', () => {
 ```
 
 **CI behavior:**
+
 - Forks lane **REQUIRES** `MK_PROCESS_EXPERIMENTAL=1` (no longer optional)
 - Process-mode tests run in main forks lane (not experimental step)
 - Ensures adapter parity and PTY control coverage
@@ -141,6 +153,7 @@ describe.skipIf(!process.env.MK_PROCESS_EXPERIMENTAL)('UnixPipeAdapter', () => {
 **Purpose:** Gate worker thread module tests (not currently run in CI).
 
 **Gated tests:**
+
 - `tests/integration/workerMode.spec.ts`
   - Timer → Worker(Uppercase) → Console topology
   - Worker node lifecycle (up → run → down)
@@ -149,6 +162,7 @@ describe.skipIf(!process.env.MK_PROCESS_EXPERIMENTAL)('UnixPipeAdapter', () => {
   - Worker endpoint registration
 
 **Usage (when ready):**
+
 ```bash
 # Enable gate and run test
 MK_WORKER_EXPERIMENTAL=1 npx vitest run \
@@ -156,11 +170,15 @@ MK_WORKER_EXPERIMENTAL=1 npx vitest run \
 ```
 
 **Implementation:**
+
 ```typescript
 // Tests skip if gate is not set
-it.skipIf(!process.env.MK_WORKER_EXPERIMENTAL)('should execute Timer → Worker(Uppercase) → Console topology', async () => {
-  // ... test logic
-});
+it.skipIf(!process.env.MK_WORKER_EXPERIMENTAL)(
+  'should execute Timer → Worker(Uppercase) → Console topology',
+  async () => {
+    // ... test logic
+  },
+);
 ```
 
 **Why disabled:** Worker-mode is experimental and not yet needed for P0 PTY metasurface product.
@@ -172,12 +190,14 @@ Location: `.github/workflows/tests.yml`
 ### Job Matrix
 
 **Strategy:**
+
 - `fail-fast: false` (continue all matrix combinations even if one fails)
 - Node versions: `[20, 24]`
 
 ### Steps
 
 1. **Checkout + Setup**
+
    ```yaml
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
@@ -186,6 +206,7 @@ Location: `.github/workflows/tests.yml`
    ```
 
 2. **Threads lane** (continue-on-error: true)
+
    ```bash
    npx vitest run \
      --pool=threads \
@@ -196,6 +217,7 @@ Location: `.github/workflows/tests.yml`
    ```
 
 3. **Forks lane** (continue-on-error: true)
+
    ```bash
    npx vitest run \
      --pool=forks \
@@ -211,6 +233,7 @@ Location: `.github/workflows/tests.yml`
    ```
 
 4. **Process-mode experimental** (continue-on-error: true)
+
    ```bash
    MK_PROCESS_EXPERIMENTAL=1 npx vitest run \
      --pool=forks \
@@ -221,6 +244,7 @@ Location: `.github/workflows/tests.yml`
    ```
 
 5. **Laminar summary/trends** (if: always, continue-on-error: true)
+
    ```bash
    npm run lam -- summary > reports/LAMINAR_SUMMARY.txt
    npm run lam -- trends --top 10 > reports/LAMINAR_TRENDS.txt
@@ -242,11 +266,13 @@ Location: `.github/workflows/tests.yml`
 ### Viewing CI Results
 
 **GitHub Actions:**
+
 1. Navigate to [Actions tab](https://github.com/anteew/mkolbol/actions)
 2. Click on workflow run
 3. Download artifacts: `laminar-reports-20` or `laminar-reports-24`
 
 **Artifacts include:**
+
 - `threads_raw.log` - Full output from threads lane
 - `forks_raw.log` - Full output from forks lane
 - `reports/summary.jsonl` - Structured test results
@@ -296,6 +322,7 @@ npm run lam:dogfood:pty
 ```
 
 **Dogfooding scripts location:**
+
 - `scripts/dogfood-ci.ts` - Threads lane
 - `scripts/dogfood-pty.ts` - Forks lane (with MK_PROCESS_EXPERIMENTAL)
 
@@ -324,6 +351,7 @@ npx vitest run tests/kernel.spec.ts -t "connect moves data"
 **Symptom:** `ptyServerWrapper.spec.ts` fails with isolation or concurrency errors.
 
 **Solution:** PTY tests require process isolation. Use forks lane:
+
 ```bash
 npm run test:pty
 ```
@@ -333,6 +361,7 @@ npm run test:pty
 **Symptom:** Tests in `processUnix.spec.ts` show as skipped.
 
 **Solution:** Process-mode is now **required**. Use `npm run test:pty` (sets `MK_PROCESS_EXPERIMENTAL=1` automatically):
+
 ```bash
 npm run test:pty
 ```
@@ -342,6 +371,7 @@ npm run test:pty
 **Symptom:** `Maximum call stack size exceeded` or worker pool errors.
 
 **Solution:** Use `--pool=threads` explicitly (already in `test:ci` script):
+
 ```bash
 npx vitest run --pool=threads
 ```
@@ -351,6 +381,7 @@ npx vitest run --pool=threads
 **Symptom:** Tests timeout in GitHub Actions but complete locally.
 
 **Solution:** CI uses `continue-on-error: true` for lanes to prevent build failures. Check:
+
 - Artifact logs: `reports/threads_raw.log` or `reports/forks_raw.log`
 - Increase timeout in test file if needed:
   ```typescript
@@ -364,6 +395,7 @@ npx vitest run --pool=threads
 **Symptom:** Tests in `workerMode.spec.ts` show as skipped.
 
 **Solution:** Worker mode is gated off in CI (not yet production-ready). To run locally:
+
 ```bash
 MK_WORKER_EXPERIMENTAL=1 npm run test:pty
 ```
@@ -373,6 +405,7 @@ MK_WORKER_EXPERIMENTAL=1 npm run test:pty
 **Symptom:** `reports/summary.jsonl` or case files are empty or missing.
 
 **Solution:** Ensure Laminar reporter is installed:
+
 ```bash
 npm ci  # Clean install
 npm run build
@@ -382,6 +415,7 @@ npm run test:ci  # Should generate reports/
 ### Debug Techniques
 
 **Enable debug output:**
+
 ```bash
 # All debug output
 DEBUG=1 npm run test:ci
@@ -394,12 +428,14 @@ MK_DEBUG_LEVEL=trace npm run test:ci
 ```
 
 **Laminar debug mode:**
+
 ```bash
 # Run tests with Laminar debug logging
 LAMINAR_DEBUG=1 npm run test:ci
 ```
 
 **Check test event logs:**
+
 ```bash
 # View structured events for a specific test
 npm run logq -- case=kernel.spec/connect reports/kernel.spec/*.jsonl
@@ -412,6 +448,7 @@ npm run logq -- --around corr=abc123 --window 5 reports/**/*.jsonl
 ```
 
 **Generate repro commands:**
+
 ```bash
 # List all failures with reproduction commands
 npm run repro
@@ -424,30 +461,34 @@ npm run lam -- repro --bundle --case kernel.spec/connect_moves_data_1_1
 
 ### Test Execution Times (approximate)
 
-| Lane | Test Count | Duration | Pool |
-|------|-----------|----------|------|
-| Threads | ~30-40 tests | ~5-10s | threads (parallel) |
-| Forks (no gates) | ~10-15 tests | ~10-15s | forks (isolated) |
-| Forks (with MK_PROCESS_EXPERIMENTAL) | ~15-20 tests | ~15-20s | forks (isolated) |
+| Lane                                 | Test Count   | Duration | Pool               |
+| ------------------------------------ | ------------ | -------- | ------------------ |
+| Threads                              | ~30-40 tests | ~5-10s   | threads (parallel) |
+| Forks (no gates)                     | ~10-15 tests | ~10-15s  | forks (isolated)   |
+| Forks (with MK_PROCESS_EXPERIMENTAL) | ~15-20 tests | ~15-20s  | forks (isolated)   |
 
 ### Optimization Tips
 
 **1. Keep threads lane fast**
+
 - Avoid PTY, process spawning, or heavy I/O in threaded tests
 - Use mocks for external dependencies
 - Keep tests focused and isolated
 
 **2. Use forks lane for integration**
+
 - Real process spawning (node-pty)
 - Full lifecycle tests (up → run → down)
 - Tests that modify global state
 
 **3. Gate experimental features**
+
 - Use environment flags for unstable features
 - Skip expensive tests by default (opt-in with gate)
 - Keep CI builds fast and reliable
 
 **4. Leverage continue-on-error**
+
 - CI lanes use `continue-on-error: true` to prevent flake-induced build failures
 - Review artifacts to catch real issues
 - Use Laminar summaries to track trends
@@ -455,17 +496,20 @@ npm run lam -- repro --bundle --case kernel.spec/connect_moves_data_1_1
 ## Next Steps
 
 **For contributors:**
+
 - Run `npm run test:ci` before submitting PRs (threads lane)
 - Run `npm run test:pty` for PTY-related changes (forks lane)
 - Check `reports/summary.jsonl` for test results
 - Use `npm run repro` to debug failures
 
 **For CI/CD:**
+
 - Both lanes run in GitHub Actions on Node 20 and 24
 - Artifacts uploaded for each run (30-day retention)
 - Laminar summaries generated automatically
 
 **For AI agents:**
+
 - Test artifacts in `reports/` directory
 - Use `npm run lam -- logq` to query logs
 - Use `npm run lam -- digest` to analyze failures
diff --git a/docs/testing/laminar-integration.md b/docs/testing/laminar-integration.md
index bb7b873..0dd382a 100644
--- a/docs/testing/laminar-integration.md
+++ b/docs/testing/laminar-integration.md
@@ -43,11 +43,13 @@ This repo integrates Laminar in two ways:
   - Forks lane + summary/trends: `npm run test:pty:lam`
 
 Artifacts you’ll see:
+
 - `reports/summary.jsonl` — per-run ledger
 - `reports/index.json` — index manifest (deterministic mtime ≥ summary)
 - `reports/LAMINAR_SUMMARY.txt` — human-readable summary
 - `reports/LAMINAR_TRENDS.txt` — top recurring signals
 
 ## Notes
+
 - The repo also ships a minimal `lam` stub bin for packaging; use `npm run lam` for the full Laminar CLI.
 - See `docs/rfcs/stream-kernel/status.md` for implementation status.
diff --git a/docs/testing/process-mode-ci.md b/docs/testing/process-mode-ci.md
index 2cc6e70..34796e6 100644
--- a/docs/testing/process-mode-ci.md
+++ b/docs/testing/process-mode-ci.md
@@ -30,12 +30,14 @@ Process mode tests validate Unix domain socket adapters (`UnixPipeAdapter`, `Uni
 ## Test Coverage
 
 ### UnixPipeAdapter
+
 - ✅ Heavy writes with backpressure (800KB, 100 chunks)
 - ✅ Bidirectional heavy writes (50 chunks × 4KB per direction)
 - ✅ Graceful teardown during writes
 - ✅ Write error propagation
 
 ### UnixControlAdapter
+
 - ✅ Heartbeat timeout detection (2.5s window)
 - ✅ Heartbeat recovery after disruption
 - ✅ Graceful shutdown sequence
@@ -44,11 +46,13 @@ Process mode tests validate Unix domain socket adapters (`UnixPipeAdapter`, `Uni
 - ✅ Subscription error handling
 
 ### Combined Scenarios
+
 - ✅ Coordinated teardown of pipe + control adapters
 
 ## Enforcement Roadmap
 
 ### Phase 1: Stability Observation (Current)
+
 **Duration**: 2-4 weeks  
 **Goal**: Collect reliability data with new timeout/retry logic
 
@@ -57,11 +61,13 @@ Process mode tests validate Unix domain socket adapters (`UnixPipeAdapter`, `Uni
 - Track pass rate and failure patterns
 
 **Success Criteria**:
+
 - 95%+ pass rate over 50+ runs
 - No timeout-related failures with new limits
 - No socket binding race conditions
 
 ### Phase 2: Soft Enforcement
+
 **Duration**: 2 weeks  
 **Goal**: Enable in CI but allow failures
 
@@ -70,11 +76,12 @@ Process mode tests validate Unix domain socket adapters (`UnixPipeAdapter`, `Uni
 - Alert team on failures but don't block merges
 
 **Configuration**:
+
 ```yaml
 # .github/workflows/ci.yml (example)
 process-mode-tests:
   runs-on: ubuntu-latest
-  continue-on-error: true  # Soft fail
+  continue-on-error: true # Soft fail
   env:
     MK_PROCESS_EXPERIMENTAL: 1
   steps:
@@ -82,11 +89,13 @@ process-mode-tests:
 ```
 
 **Success Criteria**:
+
 - 98%+ pass rate in CI over 100+ runs
 - No environment-specific failures
 - Clear failure patterns (if any) are documented
 
 ### Phase 3: Hard Enforcement
+
 **Duration**: Permanent  
 **Goal**: Make process-mode tests required
 
@@ -96,6 +105,7 @@ process-mode-tests:
 - Update AGENTS.md with new required env var
 
 **Implementation**:
+
 ```typescript
 // Option A: Remove gate entirely
 describe('Process Mode: Unix Adapters under Load', () => {
@@ -110,6 +120,7 @@ describe.skipIf(skipProcessTests)('Process Mode...', () => {
 ```
 
 ### Phase 4: Expansion
+
 **Goal**: Add more process-mode scenarios
 
 - Multi-client scenarios (fan-out)
@@ -120,6 +131,7 @@ describe.skipIf(skipProcessTests)('Process Mode...', () => {
 ## Monitoring & Debugging
 
 ### Local Testing
+
 ```bash
 # Run process-mode tests
 MK_PROCESS_EXPERIMENTAL=1 npm test -- processUnix.spec.ts
@@ -134,16 +146,19 @@ MK_PROCESS_EXPERIMENTAL=1 npm test -- processUnix.spec.ts -t "should handle heav
 ### Debugging Failures
 
 **Timeout Failures**:
+
 - Check system load: `top` or `htop`
 - Verify tmpdir access: `ls -la /tmp/mkolbol-test-*`
 - Increase timeout temporarily to isolate issue
 
 **Connection Failures**:
+
 - Check socket cleanup: `lsof | grep mkolbol-test`
 - Verify no orphaned processes: `ps aux | grep node`
 - Check ulimit: `ulimit -n` (should be ≥1024)
 
 **Data Integrity Failures**:
+
 - Enable verbose logging in adapters
 - Check for partial writes or corruption
 - Verify buffer sizes match expectations
@@ -165,16 +180,17 @@ If Phase 3 fails or shows instability:
 
 ## Success Metrics
 
-| Metric | Phase 1 | Phase 2 | Phase 3 |
-|--------|---------|---------|---------|
-| Pass Rate | 95% | 98% | 99.5% |
-| Timeouts | <2% | <0.5% | <0.1% |
-| Retries | Any | ≤2 avg | ≤1 avg |
-| CI Runs | Manual | 100+ | All PRs |
+| Metric    | Phase 1 | Phase 2 | Phase 3 |
+| --------- | ------- | ------- | ------- |
+| Pass Rate | 95%     | 98%     | 99.5%   |
+| Timeouts  | <2%     | <0.5%   | <0.1%   |
+| Retries   | Any     | ≤2 avg  | ≤1 avg  |
+| CI Runs   | Manual  | 100+    | All PRs |
 
 ## Contact
 
 For questions or issues with process-mode tests:
+
 - Review this document and test implementation
 - Check recent CI logs for patterns
 - File issue with tag `area:process-mode` and logs attached
diff --git a/eslint.config.js b/eslint.config.js
index 8a8b601..275cd7e 100644
--- a/eslint.config.js
+++ b/eslint.config.js
@@ -8,8 +8,8 @@ export default [
       'archived/**',
       '**/*.d.ts',
       'examples/web-terminal/public/**',
-      'test-project/**'
-    ]
+      'test-project/**',
+    ],
   },
 
   // Base JS and TS recommendations
@@ -23,8 +23,8 @@ export default [
       sourceType: 'module',
       globals: {
         ...(await import('globals')).default.node,
-        ...(await import('globals')).default.es2021
-      }
+        ...(await import('globals')).default.es2021,
+      },
     },
     rules: {
       'no-console': 'off',
@@ -37,9 +37,9 @@ export default [
       '@typescript-eslint/no-explicit-any': 'off',
       '@typescript-eslint/no-unused-vars': [
         'warn',
-        { argsIgnorePattern: '^_', varsIgnorePattern: '^_', caughtErrorsIgnorePattern: '^_' }
-      ]
-    }
+        { argsIgnorePattern: '^_', varsIgnorePattern: '^_', caughtErrorsIgnorePattern: '^_' },
+      ],
+    },
   },
 
   // Tests, examples, scripts: be extra lenient
@@ -52,14 +52,14 @@ export default [
       '@typescript-eslint/no-unused-expressions': 'off',
       'no-misleading-character-class': 'off',
       'no-empty': 'off',
-      'no-unused-expressions': 'off'
-    }
+      'no-unused-expressions': 'off',
+    },
   },
   // File-specific tweaks
   {
     files: ['src/modules/ttyRenderer.ts'],
     rules: {
-      'no-control-regex': 'off'
-    }
-  }
+      'no-control-regex': 'off',
+    },
+  },
 ];
diff --git a/examples/ansi-parser-basic.yml b/examples/ansi-parser-basic.yml
index 0ac85e7..11f8991 100644
--- a/examples/ansi-parser-basic.yml
+++ b/examples/ansi-parser-basic.yml
@@ -4,18 +4,18 @@ nodes:
     params:
       periodMs: 2000
       message: "\x1b[1;32mGreen Bold\x1b[0m Normal \x1b[4mUnderline\x1b[0m"
-  
+
   - id: parser1
     module: AnsiParser
-  
+
   - id: console1
     module: ConsoleSink
     params:
-      prefix: "[parsed-events]"
+      prefix: '[parsed-events]'
 
 connections:
   - from: timer1.output
     to: parser1.input
-  
+
   - from: parser1.output
     to: console1.input
diff --git a/examples/ansi-parser-p3.ts b/examples/ansi-parser-p3.ts
index 0ce5aea..6b63163 100644
--- a/examples/ansi-parser-p3.ts
+++ b/examples/ansi-parser-p3.ts
@@ -1,4 +1,8 @@
-import { AnsiParser, type AnsiParserOptions, type AnsiParserEvent } from '../src/transforms/AnsiParser.js';
+import {
+  AnsiParser,
+  type AnsiParserOptions,
+  type AnsiParserEvent,
+} from '../src/transforms/AnsiParser.js';
 
 function withParser(options: AnsiParserOptions, fn: (parser: AnsiParser) => void): void {
   const parser = new AnsiParser(options);
@@ -48,4 +52,6 @@ withParser({ cols: 4, rows: 3 }, (parser) => {
   });
 });
 
-console.log('\nRun `npx vitest run --reporter=default tests/transforms/ansiParser.performance.spec.ts` to execute the lightweight performance guard.');
+console.log(
+  '\nRun `npx vitest run --reporter=default tests/transforms/ansiParser.performance.spec.ts` to execute the lightweight performance guard.',
+);
diff --git a/examples/ansi-parser-simple.ts b/examples/ansi-parser-simple.ts
index 977f3e1..96312e7 100644
--- a/examples/ansi-parser-simple.ts
+++ b/examples/ansi-parser-simple.ts
@@ -10,7 +10,7 @@ const output = new Writable({
   write: (events, _enc, cb) => {
     console.log('Parsed Events:', JSON.stringify(events, null, 2));
     cb();
-  }
+  },
 });
 
 kernel.connect(parser.outputPipe, output as any);
diff --git a/examples/configs/bad-connection-mismatch.yml b/examples/configs/bad-connection-mismatch.yml
index 2cbf589..e69de29 100644
--- a/examples/configs/bad-connection-mismatch.yml
+++ b/examples/configs/bad-connection-mismatch.yml
@@ -1,13 +0,0 @@
-# This file has a connection to a node that doesn't exist
-nodes:
-  - id: source
-    module: TimerSource
-    params:
-      periodMs: 1000
-
-  - id: sink
-    module: ConsoleSink
-
-connections:
-  - from: source.output
-    to: nonexistent.input  # This node doesn't exist
diff --git a/scripts/lam.ts b/scripts/lam.ts
index ec48361..cda7687 100644
--- a/scripts/lam.ts
+++ b/scripts/lam.ts
@@ -23,7 +23,6 @@ if (args.includes('--help') || args.includes('-h')) {
 
 if (args[0] === 'version' || args[0] === '--version' || args[0] === '-v') {
   try {
-    // eslint-disable-next-line @typescript-eslint/no-var-requires
     const pkg = require('../package.json');
     console.log(pkg.version || 'unknown');
   } catch {
diff --git a/src/config/loader.ts b/src/config/loader.ts
index 30a812c..5e46d3a 100644
--- a/src/config/loader.ts
+++ b/src/config/loader.ts
@@ -1,6 +1,6 @@
 import { readFileSync } from 'fs';
 import { parse as parseYaml } from 'yaml';
-import type { TopologyConfig, NodeConfig, ConnectionConfig } from './schema.js';
+import type { TopologyConfig } from './schema.js';
 
 export interface LoadConfigOptions {
   validate?: boolean;
diff --git a/src/init/scaffold.ts b/src/init/scaffold.ts
index f484dd2..f50eaed 100644
--- a/src/init/scaffold.ts
+++ b/src/init/scaffold.ts
@@ -1,5 +1,4 @@
 import * as fs from 'node:fs';
-import * as path from 'node:path';
 
 export interface ScaffoldOptions {
   template?: 'node-defaults' | 'go-defaults' | 'minimal';
diff --git a/src/mk/bootstrap.ts b/src/mk/bootstrap.ts
index aec702f..ff2905d 100644
--- a/src/mk/bootstrap.ts
+++ b/src/mk/bootstrap.ts
@@ -1,4 +1,4 @@
-import { mkdir, writeFile, copyFile, readFile, cp, readdir } from 'node:fs/promises';
+import { mkdir, writeFile, readFile, cp, readdir } from 'node:fs/promises';
 import { existsSync } from 'node:fs';
 import { join, resolve, dirname } from 'node:path';
 import { fileURLToPath } from 'node:url';
diff --git a/src/mk/build.ts b/src/mk/build.ts
index d707a02..246e9d3 100644
--- a/src/mk/build.ts
+++ b/src/mk/build.ts
@@ -21,7 +21,7 @@ interface BuildProvenance {
   bundleHash: string;
 }
 
-export async function buildHandler(args: string[]): Promise<number> {
+export async function buildHandler(_args: string[]): Promise<number> {
   const startTime = performance.now();
   
   try {
diff --git a/src/mk/ciPlan.ts b/src/mk/ciPlan.ts
index f43b375..f1cedd2 100644
--- a/src/mk/ciPlan.ts
+++ b/src/mk/ciPlan.ts
@@ -1,4 +1,4 @@
-import { createError, formatError } from './errors.js';
+import { formatError } from './errors.js';
 
 const EXIT_SUCCESS = 0;
 const EXIT_ERROR = 1;
diff --git a/src/mk/dev.ts b/src/mk/dev.ts
index 4160057..401b4bc 100644
--- a/src/mk/dev.ts
+++ b/src/mk/dev.ts
@@ -1,5 +1,5 @@
 import { watch, FSWatcher } from 'node:fs';
-import { resolve, dirname } from 'node:path';
+import { resolve } from 'node:path';
 import type { TopologyConfig } from '../config/schema.js';
 import type { Executor } from '../executor/Executor.js';
 
@@ -72,7 +72,7 @@ export class DevWatcher {
 
   private watchModule(nodeId: string, modulePath: string): void {
     try {
-      const watcher = watch(modulePath, (eventType, filename) => {
+      const watcher = watch(modulePath, (eventType, _filename) => {
         if (eventType === 'change') {
           this.handleFileChange(nodeId, modulePath);
         }
diff --git a/src/mk/doctor.ts b/src/mk/doctor.ts
index 403720b..a1827eb 100644
--- a/src/mk/doctor.ts
+++ b/src/mk/doctor.ts
@@ -12,7 +12,7 @@ export type CheckResult = {
 export type CheckSection = 'all' | 'toolchain' | 'environment';
 
 export async function runDoctorChecks(
-  verbose: boolean = false,
+  _verbose: boolean = false,
   section: CheckSection = 'all'
 ): Promise<CheckResult[]> {
   const results: CheckResult[] = [];
@@ -325,7 +325,7 @@ function checkMkVersionConsistency(): CheckResult {
         remediation: 'Run: npm run build',
       };
     }
-  } catch (error) {
+  } catch {
     return {
       name: 'mk version consistency',
       status: 'fail',
diff --git a/src/mk/fetch.ts b/src/mk/fetch.ts
index 09d9ed9..d2c6d8d 100644
--- a/src/mk/fetch.ts
+++ b/src/mk/fetch.ts
@@ -1,5 +1,5 @@
 import { createWriteStream, existsSync, createReadStream } from 'node:fs';
-import { mkdir, chmod, access, constants as fsConstants, readFile } from 'node:fs/promises';
+import { mkdir, access, constants as fsConstants, readFile } from 'node:fs/promises';
 import { dirname, join } from 'node:path';
 import { pipeline } from 'node:stream/promises';
 import { execSync } from 'node:child_process';
diff --git a/src/mk/logs.ts b/src/mk/logs.ts
index 9d20ca9..45305e0 100644
--- a/src/mk/logs.ts
+++ b/src/mk/logs.ts
@@ -27,7 +27,7 @@ const LEVEL_VALUES: Record<LogLevel, number> = {
   debug: 3,
 };
 
-function parseDebugLog(line: string): LogEntry | null {
+function _parseDebugLog(line: string): LogEntry | null {
   try {
     const timestampMatch = line.match(/^\[([\d-T:.Z]+)\]/);
     const levelMatch = line.match(/\[([A-Z]+)\]/);
@@ -56,7 +56,7 @@ function parseDebugLog(line: string): LogEntry | null {
         payload,
       };
     }
-  } catch (e) {
+  } catch {
     return null;
   }
   return null;
@@ -79,7 +79,7 @@ function parseJsonlLog(line: string): LogEntry | null {
         payload: data.payload,
       };
     }
-  } catch (e) {
+  } catch {
     return null;
   }
   return null;
@@ -113,7 +113,7 @@ function formatLogJson(entry: LogEntry): string {
   return JSON.stringify(entry);
 }
 
-async function tailDebugLogs(options: LogsOptions): Promise<void> {
+async function tailDebugLogs(_options: LogsOptions): Promise<void> {
   const debugLog = process.env.DEBUG === '1' || process.env.MK_DEBUG_MODULES;
   
   if (!debugLog) {
diff --git a/src/mk/options.ts b/src/mk/options.ts
index 996b35e..ac3cfb9 100644
--- a/src/mk/options.ts
+++ b/src/mk/options.ts
@@ -74,7 +74,7 @@ function loadOptionsFile(filePath: string, profile: string): Record<string, any>
     }
 
     return {};
-  } catch (err) {
+  } catch {
     return {};
   }
 }
diff --git a/src/mk/package.ts b/src/mk/package.ts
index 2d28f70..97da77d 100644
--- a/src/mk/package.ts
+++ b/src/mk/package.ts
@@ -6,11 +6,6 @@ import { promisify } from 'util';
 
 const execAsync = promisify(exec);
 
-interface CapsuleInfo {
-  filename: string;
-  size: number;
-  sha256: string;
-}
 
 function formatSize(bytes: number): string {
   if (bytes < 1024) return `${bytes}B`;
@@ -29,7 +24,7 @@ async function calculateFileHash(filepath: string): Promise<string> {
   return hash.digest('hex');
 }
 
-export async function packageHandler(args: string[]): Promise<number> {
+export async function packageHandler(_args: string[]): Promise<number> {
   const startTime = performance.now();
   
   try {
diff --git a/src/mk/selfInstall.ts b/src/mk/selfInstall.ts
index 9187968..72049c4 100644
--- a/src/mk/selfInstall.ts
+++ b/src/mk/selfInstall.ts
@@ -1,5 +1,5 @@
-import { existsSync, mkdirSync, writeFileSync, unlinkSync, readlinkSync, symlinkSync, copyFileSync, chmodSync, readdirSync, statSync } from 'node:fs';
-import { resolve, dirname, join, isAbsolute } from 'node:path';
+import { existsSync, mkdirSync, writeFileSync, unlinkSync, copyFileSync, chmodSync, statSync } from 'node:fs';
+import { resolve, dirname, isAbsolute } from 'node:path';
 import { fileURLToPath } from 'node:url';
 import { platform } from 'node:os';
 import { execSync } from 'node:child_process';
diff --git a/src/mk/trace.ts b/src/mk/trace.ts
index bbdac59..ca93400 100644
--- a/src/mk/trace.ts
+++ b/src/mk/trace.ts
@@ -186,8 +186,7 @@ export async function captureTrace(
   const unsubscribe = stateManager.subscribe((event) => {
     if (event.type === 'connected') {
       const connectionId = event.connection.id;
-      const startTime = Date.now();
-      
+
       collector.recordFlow(connectionId, 0);
     }
   });
diff --git a/src/modules/filesystem-sink.ts b/src/modules/filesystem-sink.ts
index 7205347..3ac5a41 100644
--- a/src/modules/filesystem-sink.ts
+++ b/src/modules/filesystem-sink.ts
@@ -1,4 +1,4 @@
-import { Writable, Transform } from 'stream';
+import { Transform } from 'stream';
 import { createWriteStream, WriteStream, fsync } from 'fs';
 import { mkdir } from 'fs/promises';
 import { dirname } from 'path';
diff --git a/src/parsers/ANSIParser.ts b/src/parsers/ANSIParser.ts
index fe41a69..069d49e 100644
--- a/src/parsers/ANSIParser.ts
+++ b/src/parsers/ANSIParser.ts
@@ -1,4 +1,4 @@
-import type { TerminalState, Cell, EscapeSequence } from '../types.js';
+import type { TerminalState, EscapeSequence } from '../types.js';
 
 export class ANSIParser {
   private state: TerminalState;
diff --git a/src/pipes/adapters/TCPPipe.ts b/src/pipes/adapters/TCPPipe.ts
index 73b825c..e027552 100644
--- a/src/pipes/adapters/TCPPipe.ts
+++ b/src/pipes/adapters/TCPPipe.ts
@@ -37,7 +37,7 @@ export class TCPPipeClient extends Duplex {
     this.socket.write(FrameCodec.encode(frame), cb);
   }
 
-  _read(): void {}
+  _read(_size?: number): void {}
 
   private handleData(chunk: Buffer): void {
     this.buffer = Buffer.concat([this.buffer, chunk]);
@@ -107,7 +107,7 @@ class TCPServerPipe extends Duplex {
     this.socket.write(FrameCodec.encode(FrameCodec.createDataFrame(chunk, this.sequenceId++)), cb);
   }
 
-  _read(): void {}
+  _read(_size?: number): void {}
 
   private handleData(chunk: Buffer): void {
     this.buffer = Buffer.concat([this.buffer, chunk]);
diff --git a/src/pipes/adapters/WebSocketPipe.ts b/src/pipes/adapters/WebSocketPipe.ts
index 0c93c5c..c6bc8d6 100644
--- a/src/pipes/adapters/WebSocketPipe.ts
+++ b/src/pipes/adapters/WebSocketPipe.ts
@@ -1,7 +1,6 @@
 import { Duplex } from 'stream';
 import WebSocket, { WebSocketServer } from 'ws';
 import { FrameCodec } from '../../net/frame.js';
-import type { Frame } from '../../net/transport.js';
 import { debug } from '../../debug/api.js';
 
 export interface WebSocketPipeOptions {
@@ -77,7 +76,7 @@ export class WebSocketPipeClient extends Duplex {
     }
   }
 
-  _read(size: number): void {
+  _read(_size: number): void {
     // Backpressure handled by WebSocket
   }
 
@@ -222,7 +221,7 @@ class WebSocketServerPipe extends Duplex {
     }
   }
 
-  _read(size: number): void {
+  _read(_size: number): void {
     // Backpressure handled by WebSocket
   }
 
diff --git a/src/pipes/adapters/WorkerPipe.ts b/src/pipes/adapters/WorkerPipe.ts
index e6d8d45..65b805b 100644
--- a/src/pipes/adapters/WorkerPipe.ts
+++ b/src/pipes/adapters/WorkerPipe.ts
@@ -55,7 +55,7 @@ class WorkerPipeDuplex extends Duplex {
     });
   }
 
-  _read(size: number): void {
+  _read(_size: number): void {
     this.port.postMessage({ type: 'resume' });
   }
 
diff --git a/src/transport/unix/UnixPipeAdapter.ts b/src/transport/unix/UnixPipeAdapter.ts
index ec715f6..6be9de4 100644
--- a/src/transport/unix/UnixPipeAdapter.ts
+++ b/src/transport/unix/UnixPipeAdapter.ts
@@ -43,7 +43,7 @@ class UnixPipeAdapterDuplex extends Duplex {
     });
   }
 
-  _read(size: number): void {
+  _read(_size: number): void {
     this.socket.resume();
   }
 
diff --git a/src/transport/worker/WorkerPipeAdapter.ts b/src/transport/worker/WorkerPipeAdapter.ts
index 705218b..3ec2f8c 100644
--- a/src/transport/worker/WorkerPipeAdapter.ts
+++ b/src/transport/worker/WorkerPipeAdapter.ts
@@ -60,7 +60,7 @@ class WorkerPipeAdapterDuplex extends Duplex {
     // Rely on _final() for end signalling; avoid duplicate 'end' frames here.
   }
 
-  _read(size: number): void {
+  _read(_size: number): void {
     this.port.postMessage({ type: 'resume' });
   }
 
diff --git a/src/wrappers/PTYServerWrapper.ts b/src/wrappers/PTYServerWrapper.ts
index 8a7eacf..2b03f0d 100644
--- a/src/wrappers/PTYServerWrapper.ts
+++ b/src/wrappers/PTYServerWrapper.ts
@@ -119,7 +119,7 @@ export class PTYServerWrapper extends ExternalServerWrapper {
     
     try {
       pty.kill('SIGKILL');
-    } catch (err) {
+    } catch {
     }
     
     debug.emit('pty', 'server.stopped', { servername: this.manifest.servername }, 'info');
