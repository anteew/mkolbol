diff --git a/examples/configs/http-logs-local-file.yml b/examples/configs/http-logs-local-file.yml
new file mode 100644
index 0000000..9ff00ef
--- /dev/null
+++ b/examples/configs/http-logs-local-file.yml
@@ -0,0 +1,30 @@
+nodes:
+  - id: web
+    module: ExternalProcess
+    params:
+      command: node
+      args:
+        - -e
+        - "require('http').createServer((req,res)=>{console.log(`[${new Date().toISOString()}] ${req.method} ${req.url}`);res.end('ok')}).listen(3000,()=>console.log('Server listening on http://localhost:3000'))"
+      ioMode: stdio
+      restart: never
+
+  - id: meter
+    module: PipeMeterTransform
+    params:
+      emitInterval: 1000
+
+  - id: file
+    module: FilesystemSink
+    params:
+      path: reports/http-logs.jsonl
+      format: jsonl
+      mode: append
+      fsync: auto
+
+connections:
+  - from: web.output
+    to: meter.input
+  
+  - from: meter.output
+    to: file.input
diff --git a/docs/devex/quickstart.md b/docs/devex/quickstart.md
index 7f14255..e29ea57 100644
--- a/docs/devex/quickstart.md
+++ b/docs/devex/quickstart.md
@@ -142,9 +142,10 @@ Coordinates: node:sink
 - Output → ConsoleSink (terminal console)
 - Users who want persistent logs can tee output: `… | tee reports/http-demo.log`
 
-**FilesystemSink (file output):**
-- Output → FilesystemSink (writes to `reports/http-logs.jsonl`)
+**FilesystemSink with PipeMeter (file output with metrics):**
+- Output → PipeMeter → FilesystemSink (writes to `reports/http-logs.jsonl`)
 - Use the ready-made config: `examples/configs/http-logs-local-file.yml`
+- Topology: ExternalProcess (HTTP server) → PipeMeterTransform → FilesystemSink (JSONL format)
 
 Run it:
 ```bash
@@ -153,9 +154,17 @@ node dist/scripts/mkctl.js run --file examples/configs/http-logs-local-file.yml
 # In another shell, hit the server to generate logs
 curl -s http://localhost:3000 >/dev/null
 curl -s http://localhost:3000/test >/dev/null
-ls -l reports/http-logs.jsonl
+cat reports/http-logs.jsonl
 ```
-- Node IDs stay the same (web, sink), so the documentation diff is minimal
+
+Expected output in `reports/http-logs.jsonl`:
+```jsonl
+{"ts":"2025-10-16T12:34:56.789Z","data":"Server listening on http://localhost:3000"}
+{"ts":"2025-10-16T12:34:57.123Z","data":"[2025-10-16T12:34:57.123Z] GET /"}
+{"ts":"2025-10-16T12:34:58.456Z","data":"[2025-10-16T12:34:58.456Z] GET /test"}
+```
+
+**PipeMeter** tracks throughput metrics (bytes/sec, messages/sec) for monitoring and debugging pipeline performance.
 
 ### FilesystemSink Format Options
 
diff --git a/tests/devex/acceptance/local-node-v1.md b/tests/devex/acceptance/local-node-v1.md
index 62a29a4..09b24d8 100644
--- a/tests/devex/acceptance/local-node-v1.md
+++ b/tests/devex/acceptance/local-node-v1.md
@@ -370,13 +370,13 @@ node dist/scripts/mkctl.js endpoints
 
 ---
 
-## FilesystemSink Walkthrough (End-to-End Logging)
+## FilesystemSink with PipeMeter Walkthrough (End-to-End Logging with Metrics)
 
-### Scenario: HTTP Logs to File
+### Scenario: HTTP Logs to File with Throughput Monitoring
 
-This scenario demonstrates the **complete FilesystemSink flow**: data flows from an HTTP server through a FilesystemSink module into a persistent log file, all coordinated by mkolbol's routing and I/O system.
+This scenario demonstrates the **complete FilesystemSink + PipeMeter flow**: data flows from an HTTP server through a PipeMeter transform (for metrics) and then to a FilesystemSink module into a persistent JSONL log file, all coordinated by mkolbol's routing and I/O system.
 
-**Prerequisites:** FilesystemSink module must be available (delivered in SB-MK-CONFIG-PROCESS-P1)
+**Prerequisites:** FilesystemSink and PipeMeterTransform modules must be available
 
 ### Configuration
 
@@ -394,23 +394,34 @@ nodes:
       ioMode: stdio
       restart: never
 
-  - id: sink
+  - id: meter
+    module: PipeMeterTransform
+    params:
+      emitInterval: 1000
+
+  - id: file
     module: FilesystemSink
     params:
-      path: ./logs/http-response.log
+      path: reports/http-logs.jsonl
+      format: jsonl
       mode: append
+      fsync: auto
 
 connections:
   - from: web.output
-    to: sink.input
+    to: meter.input
+  
+  - from: meter.output
+    to: file.input
 ```
 
-**Key Differences from ConsoleSink:**
+**Key Features:**
 
-- **`module: FilesystemSink`** - Writes to file instead of console
-- **`path: ./logs/http-response.log`** - Target file (created if it doesn't exist)
+- **PipeMeterTransform** - Measures bytes/sec and messages/sec flowing through the pipeline
+- **FilesystemSink with JSONL** - Structured log format with timestamps
+- **`format: jsonl`** - Each line is `{"ts": "...", "data": "..."}`
 - **`mode: append`** - Append to file (vs. `truncate` to overwrite)
-- No `prefix` parameter (file logging doesn't need visual prefixes)
+- **`fsync: auto`** - Automatic fsync policy for data durability
 
 ### Steps
 
@@ -433,10 +444,11 @@ Server listening on http://localhost:3000
 
 **What's Happening:**
 1. mkctl validates and loads the config
-2. Executor instantiates `web` (ExternalProcess) and `sink` (FilesystemSink)
-3. FilesystemSink creates `logs/` directory and opens `http-response.log` in append mode
+2. Executor instantiates `web` (ExternalProcess), `meter` (PipeMeterTransform), and `file` (FilesystemSink)
+3. FilesystemSink creates `reports/` directory and opens `http-logs.jsonl` in append mode
 4. ExternalProcess spawns HTTP server
-5. StateManager wires `web.output` → `sink.input`
+5. StateManager wires `web.output` → `meter.input` → `file.input`
+6. PipeMeter begins tracking throughput metrics (bytes/sec, messages/sec)
 
 #### Step 2: Generate HTTP Activity
 
@@ -457,9 +469,10 @@ done
 **What's Happening:**
 1. Each curl request reaches the HTTP server
 2. Server logs `[timestamp] GET /request-N` to stdout
-3. These logs flow through `web.output` → `sink.input` → FilesystemSink
-4. FilesystemSink writes each line to `logs/http-response.log`
-5. File grows with each request (append mode)
+3. These logs flow through `web.output` → `meter.input` → `meter.output` → `file.input`
+4. PipeMeter increments its message count and byte count for each chunk
+5. FilesystemSink wraps each line as JSONL: `{"ts": "...", "data": "..."}`
+6. File grows with each request (append mode)
 
 #### Step 3: Inspect the Log File (While Topology Runs)
 
@@ -467,16 +480,17 @@ In another terminal:
 
 ```bash
 # Terminal 3: Watch the log file grow
-tail -f logs/http-response.log
+tail -f reports/http-logs.jsonl
 ```
 
 **Expected Output (updates as requests arrive):**
-```
-[2025-10-17T04:15:23.456Z] GET /request-1
-[2025-10-17T04:15:23.957Z] GET /request-2
-[2025-10-17T04:15:24.458Z] GET /request-3
-[2025-10-17T04:15:24.959Z] GET /request-4
-[2025-10-17T04:15:25.460Z] GET /request-5
+```jsonl
+{"ts":"2025-10-17T04:15:23.456Z","data":"Server listening on http://localhost:3000"}
+{"ts":"2025-10-17T04:15:23.789Z","data":"[2025-10-17T04:15:23.789Z] GET /request-1"}
+{"ts":"2025-10-17T04:15:24.290Z","data":"[2025-10-17T04:15:24.290Z] GET /request-2"}
+{"ts":"2025-10-17T04:15:24.791Z","data":"[2025-10-17T04:15:24.791Z] GET /request-3"}
+{"ts":"2025-10-17T04:15:25.292Z","data":"[2025-10-17T04:15:25.292Z] GET /request-4"}
+{"ts":"2025-10-17T04:15:25.793Z","data":"[2025-10-17T04:15:25.793Z] GET /request-5"}
 ```
 
 **What's Happening:**
@@ -494,30 +508,34 @@ After the topology runs (10 seconds), the log file persists:
 # Logs are already written to disk
 
 # Terminal 2: Inspect final log file
-cat logs/http-response.log
+cat reports/http-logs.jsonl
 ```
 
 **Expected Output:**
-```
-[2025-10-17T04:15:23.456Z] GET /request-1
-[2025-10-17T04:15:23.957Z] GET /request-2
-[2025-10-17T04:15:24.458Z] GET /request-3
-[2025-10-17T04:15:24.959Z] GET /request-4
-[2025-10-17T04:15:25.460Z] GET /request-5
+```jsonl
+{"ts":"2025-10-17T04:15:23.456Z","data":"Server listening on http://localhost:3000"}
+{"ts":"2025-10-17T04:15:23.789Z","data":"[2025-10-17T04:15:23.789Z] GET /request-1"}
+{"ts":"2025-10-17T04:15:24.290Z","data":"[2025-10-17T04:15:24.290Z] GET /request-2"}
+{"ts":"2025-10-17T04:15:24.791Z","data":"[2025-10-17T04:15:24.791Z] GET /request-3"}
+{"ts":"2025-10-17T04:15:25.292Z","data":"[2025-10-17T04:15:25.292Z] GET /request-4"}
+{"ts":"2025-10-17T04:15:25.793Z","data":"[2025-10-17T04:15:25.793Z] GET /request-5"}
 ```
 
-**Key Insight:** Unlike ConsoleSink, FilesystemSink persists logs to disk. You can inspect them after the topology exits, archive them, upload to logging systems, etc.
+**Key Insight:** Unlike ConsoleSink, FilesystemSink persists logs to disk. JSONL format allows easy parsing with `jq` and other tools. PipeMeter tracks pipeline throughput for performance monitoring.
 
 ### Verification Checklist
 
-- [ ] **Directory created** - `logs/` directory exists after run starts
-- [ ] **File created** - `logs/http-response.log` is created (initially empty or appended to)
-- [ ] **Logs written** - Each HTTP request generates a log line in the file
-- [ ] **File format correct** - Logs are plain text, one line per request
+- [ ] **Directory created** - `reports/` directory exists after run starts
+- [ ] **File created** - `reports/http-logs.jsonl` is created (initially empty or appended to)
+- [ ] **PipeMeter instantiated** - `meter` node successfully created in topology
+- [ ] **Logs written** - Each HTTP request generates a JSONL line in the file
+- [ ] **File format correct** - Logs are JSONL format: `{"ts": "...", "data": "..."}`
+- [ ] **JSONL parseable** - Each line is valid JSON (verify with `jq`)
 - [ ] **Append mode works** - Running topology twice appends lines (doesn't truncate)
 - [ ] **Backpressure handled** - HTTP requests don't stall while logs are written
 - [ ] **Graceful shutdown** - FilesystemSink closes file handle cleanly at shutdown
 - [ ] **File integrity** - Log file is readable and contains all expected entries
+- [ ] **PipeMeter metrics** - Metrics can be queried via `meter.getMetrics()` (programmatic access)
 
 ### Comparison: ConsoleSink vs FilesystemSink
 
